<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.1.0"/>
    <title>pynever.strategies.conversion API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../strategies.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;pynever.strategies</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#AlternativeRepresentation">AlternativeRepresentation</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#AlternativeRepresentation.__init__">AlternativeRepresentation</a>
                        </li>
                        <li>
                                <a class="variable" href="#AlternativeRepresentation.identifier">identifier</a>
                        </li>
                        <li>
                                <a class="variable" href="#AlternativeRepresentation.up_to_date">up_to_date</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ONNXNetwork">ONNXNetwork</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ONNXNetwork.__init__">ONNXNetwork</a>
                        </li>
                        <li>
                                <a class="variable" href="#ONNXNetwork.onnx_network">onnx_network</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PyTorchNetwork">PyTorchNetwork</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PyTorchNetwork.__init__">PyTorchNetwork</a>
                        </li>
                        <li>
                                <a class="variable" href="#PyTorchNetwork.pytorch_network">pytorch_network</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ConversionStrategy">ConversionStrategy</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ConversionStrategy.from_neural_network">from_neural_network</a>
                        </li>
                        <li>
                                <a class="function" href="#ConversionStrategy.to_neural_network">to_neural_network</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ONNXConverter">ONNXConverter</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ONNXConverter.from_neural_network">from_neural_network</a>
                        </li>
                        <li>
                                <a class="function" href="#ONNXConverter.to_neural_network">to_neural_network</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PyTorchConverter">PyTorchConverter</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PyTorchConverter.from_neural_network">from_neural_network</a>
                        </li>
                        <li>
                                <a class="function" href="#PyTorchConverter.to_neural_network">to_neural_network</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="function" href="#load_network_path">load_network_path</a>
            </li>
            <li>
                    <a class="function" href="#save_network_path">save_network_path</a>
            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../../pynever.html">pynever</a><wbr>.<a href="./../strategies.html">strategies</a><wbr>.conversion    </h1>

                
                        <input id="mod-conversion-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-conversion-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">   1</span></a><span class="kn">import</span> <span class="nn">abc</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">   2</span></a><span class="kn">import</span> <span class="nn">copy</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">   3</span></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">   4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos">   5</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">   6</span></a><span class="kn">import</span> <span class="nn">onnx</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">   7</span></a><span class="kn">import</span> <span class="nn">onnx.numpy_helper</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">   8</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">   9</span></a>
</span><span id="L-10"><a href="#L-10"><span class="linenos">  10</span></a><span class="kn">import</span> <span class="nn">pynever.networks</span> <span class="k">as</span> <span class="nn">networks</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">  11</span></a><span class="kn">import</span> <span class="nn">pynever.nodes</span> <span class="k">as</span> <span class="nn">nodes</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">  12</span></a><span class="kn">import</span> <span class="nn">pynever.pytorch_layers</span> <span class="k">as</span> <span class="nn">pyt_l</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">  13</span></a>
</span><span id="L-14"><a href="#L-14"><span class="linenos">  14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos">  15</span></a><span class="k">class</span> <span class="nc">AlternativeRepresentation</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos">  16</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos">  17</span></a><span class="sd">    An abstract class used to represent an alternative representation for a neural network.</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos">  18</span></a>
</span><span id="L-19"><a href="#L-19"><span class="linenos">  19</span></a><span class="sd">    Attributes</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos">  20</span></a><span class="sd">    ----------</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos">  21</span></a><span class="sd">    identifier : str</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos">  22</span></a><span class="sd">        identifier for the alternative representation</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos">  23</span></a><span class="sd">    up_to_date : bool, optional</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos">  24</span></a><span class="sd">        flag which indicates if the alternative representation is up-to-date with respect</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos">  25</span></a><span class="sd">        to the internal representation of the network (optional: True).</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos">  26</span></a>
</span><span id="L-27"><a href="#L-27"><span class="linenos">  27</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos">  28</span></a>
</span><span id="L-29"><a href="#L-29"><span class="linenos">  29</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos">  30</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos">  31</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_to_date</span> <span class="o">=</span> <span class="n">up_to_date</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos">  32</span></a>
</span><span id="L-33"><a href="#L-33"><span class="linenos">  33</span></a>
</span><span id="L-34"><a href="#L-34"><span class="linenos">  34</span></a><span class="k">class</span> <span class="nc">ONNXNetwork</span><span class="p">(</span><span class="n">AlternativeRepresentation</span><span class="p">):</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos">  35</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos">  36</span></a><span class="sd">    A class used to represent a ONNX representation for a neural network.</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos">  37</span></a>
</span><span id="L-38"><a href="#L-38"><span class="linenos">  38</span></a><span class="sd">    Attributes</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos">  39</span></a><span class="sd">    ----------</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos">  40</span></a><span class="sd">    onnx_network : onnx.ModelProto</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos">  41</span></a><span class="sd">        Real ONNX network.</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos">  42</span></a>
</span><span id="L-43"><a href="#L-43"><span class="linenos">  43</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos">  44</span></a>
</span><span id="L-45"><a href="#L-45"><span class="linenos">  45</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos">  46</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos">  47</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">onnx_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">onnx_network</span><span class="p">)</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos">  48</span></a>
</span><span id="L-49"><a href="#L-49"><span class="linenos">  49</span></a>
</span><span id="L-50"><a href="#L-50"><span class="linenos">  50</span></a><span class="k">class</span> <span class="nc">PyTorchNetwork</span><span class="p">(</span><span class="n">AlternativeRepresentation</span><span class="p">):</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos">  51</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos">  52</span></a><span class="sd">    A class used to represent a PyTorch representation for a neural network.</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos">  53</span></a>
</span><span id="L-54"><a href="#L-54"><span class="linenos">  54</span></a><span class="sd">    Attributes</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos">  55</span></a><span class="sd">    ----------</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos">  56</span></a><span class="sd">        identifier for the alternative representation</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos">  57</span></a><span class="sd">    pytorch_network : torch.nn.Module</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos">  58</span></a><span class="sd">        Real PyTorch network.</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos">  59</span></a>
</span><span id="L-60"><a href="#L-60"><span class="linenos">  60</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos">  61</span></a>
</span><span id="L-62"><a href="#L-62"><span class="linenos">  62</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos">  63</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos">  64</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pytorch_network</span><span class="p">)</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos">  65</span></a>
</span><span id="L-66"><a href="#L-66"><span class="linenos">  66</span></a>
</span><span id="L-67"><a href="#L-67"><span class="linenos">  67</span></a><span class="k">class</span> <span class="nc">ConversionStrategy</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos">  68</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos">  69</span></a><span class="sd">    An abstract class used to represent a Conversion Strategy.</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos">  70</span></a>
</span><span id="L-71"><a href="#L-71"><span class="linenos">  71</span></a><span class="sd">    Methods</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos">  72</span></a><span class="sd">    ----------</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos">  73</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos">  74</span></a><span class="sd">        Convert the neural network of interest to an alternative representation determined in the concrete children.</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos">  75</span></a><span class="sd">    to_neural_network(AlternativeRepresentation)</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos">  76</span></a><span class="sd">        Convert the alternative representation of interest to our internal representation of a Neural Network.</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos">  77</span></a>
</span><span id="L-78"><a href="#L-78"><span class="linenos">  78</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos">  79</span></a>
</span><span id="L-80"><a href="#L-80"><span class="linenos">  80</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos">  81</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AlternativeRepresentation</span><span class="p">:</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos">  82</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-83"><a href="#L-83"><span class="linenos">  83</span></a><span class="sd">        Convert the neural network of interest to an alternative representation determined in the concrete children.</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos">  84</span></a>
</span><span id="L-85"><a href="#L-85"><span class="linenos">  85</span></a><span class="sd">        Parameters</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos">  86</span></a><span class="sd">        ----------</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos">  87</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos">  88</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos">  89</span></a>
</span><span id="L-90"><a href="#L-90"><span class="linenos">  90</span></a><span class="sd">        Returns</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos">  91</span></a><span class="sd">        ----------</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos">  92</span></a><span class="sd">        AlternativeRepresentation</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos">  93</span></a><span class="sd">            The alternative representation resulting from the conversion of the original network.</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos">  94</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos">  95</span></a>        <span class="k">pass</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos">  96</span></a>
</span><span id="L-97"><a href="#L-97"><span class="linenos">  97</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos">  98</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">AlternativeRepresentation</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos">  99</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos"> 100</span></a><span class="sd">        Convert the alternative representation of interest to the internal one.</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos"> 101</span></a>
</span><span id="L-102"><a href="#L-102"><span class="linenos"> 102</span></a><span class="sd">        Parameters</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos"> 103</span></a><span class="sd">        ----------</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos"> 104</span></a><span class="sd">        alt_rep : AlternativeRepresentation</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos"> 105</span></a><span class="sd">            The Alternative Representation to convert.</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos"> 106</span></a>
</span><span id="L-107"><a href="#L-107"><span class="linenos"> 107</span></a><span class="sd">        Returns</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos"> 108</span></a><span class="sd">        ----------</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos"> 109</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos"> 110</span></a><span class="sd">            The Neural Network resulting from the conversion of Alternative Representation.</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos"> 111</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos"> 112</span></a>        <span class="k">pass</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos"> 113</span></a>
</span><span id="L-114"><a href="#L-114"><span class="linenos"> 114</span></a>
</span><span id="L-115"><a href="#L-115"><span class="linenos"> 115</span></a><span class="k">class</span> <span class="nc">ONNXConverter</span><span class="p">(</span><span class="n">ConversionStrategy</span><span class="p">):</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos"> 116</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos"> 117</span></a><span class="sd">    A class used to represent the conversion strategy for ONNX models.</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos"> 118</span></a>
</span><span id="L-119"><a href="#L-119"><span class="linenos"> 119</span></a><span class="sd">    Methods</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos"> 120</span></a><span class="sd">    ----------</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos"> 121</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos"> 122</span></a><span class="sd">        Convert the neural network of interest to a ONNXNetwork model.</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos"> 123</span></a><span class="sd">    to_neural_network(ONNXNetwork)</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos"> 124</span></a><span class="sd">        Convert the ONNXNetwork of interest to our internal representation of a Neural Network.</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos"> 125</span></a>
</span><span id="L-126"><a href="#L-126"><span class="linenos"> 126</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos"> 127</span></a>
</span><span id="L-128"><a href="#L-128"><span class="linenos"> 128</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-129"><a href="#L-129"><span class="linenos"> 129</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_relu</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos"> 130</span></a>
</span><span id="L-131"><a href="#L-131"><span class="linenos"> 131</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos"> 132</span></a>            <span class="s1">&#39;Relu&#39;</span><span class="p">,</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos"> 133</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos"> 134</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos"> 135</span></a>        <span class="p">)</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos"> 136</span></a>
</span><span id="L-137"><a href="#L-137"><span class="linenos"> 137</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos"> 138</span></a>
</span><span id="L-139"><a href="#L-139"><span class="linenos"> 139</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos"> 140</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_elu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos"> 141</span></a>                       <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos"> 142</span></a>
</span><span id="L-143"><a href="#L-143"><span class="linenos"> 143</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-144"><a href="#L-144"><span class="linenos"> 144</span></a>            <span class="s1">&#39;Elu&#39;</span><span class="p">,</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos"> 145</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos"> 146</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos"> 147</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos"> 148</span></a>        <span class="p">)</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos"> 149</span></a>
</span><span id="L-150"><a href="#L-150"><span class="linenos"> 150</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos"> 151</span></a>
</span><span id="L-152"><a href="#L-152"><span class="linenos"> 152</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos"> 153</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_leakyrelu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos"> 154</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos"> 155</span></a>
</span><span id="L-156"><a href="#L-156"><span class="linenos"> 156</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-157"><a href="#L-157"><span class="linenos"> 157</span></a>            <span class="s1">&#39;LeakyRelu&#39;</span><span class="p">,</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos"> 158</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos"> 159</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos"> 160</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">negative_slope</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos"> 161</span></a>        <span class="p">)</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos"> 162</span></a>
</span><span id="L-163"><a href="#L-163"><span class="linenos"> 163</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-164"><a href="#L-164"><span class="linenos"> 164</span></a>
</span><span id="L-165"><a href="#L-165"><span class="linenos"> 165</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos"> 166</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_celu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos"> 167</span></a>                        <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos"> 168</span></a>
</span><span id="L-169"><a href="#L-169"><span class="linenos"> 169</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos"> 170</span></a>            <span class="s1">&#39;Celu&#39;</span><span class="p">,</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos"> 171</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos"> 172</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos"> 173</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos"> 174</span></a>        <span class="p">)</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos"> 175</span></a>
</span><span id="L-176"><a href="#L-176"><span class="linenos"> 176</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos"> 177</span></a>
</span><span id="L-178"><a href="#L-178"><span class="linenos"> 178</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos"> 179</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_sigmoid</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos"> 180</span></a>
</span><span id="L-181"><a href="#L-181"><span class="linenos"> 181</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos"> 182</span></a>            <span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos"> 183</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos"> 184</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos"> 185</span></a>        <span class="p">)</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos"> 186</span></a>
</span><span id="L-187"><a href="#L-187"><span class="linenos"> 187</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos"> 188</span></a>
</span><span id="L-189"><a href="#L-189"><span class="linenos"> 189</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos"> 190</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_tanh</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos"> 191</span></a>
</span><span id="L-192"><a href="#L-192"><span class="linenos"> 192</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos"> 193</span></a>            <span class="s1">&#39;Tanh&#39;</span><span class="p">,</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos"> 194</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos"> 195</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos"> 196</span></a>        <span class="p">)</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos"> 197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos"> 198</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos"> 199</span></a>
</span><span id="L-200"><a href="#L-200"><span class="linenos"> 200</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-201"><a href="#L-201"><span class="linenos"> 201</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_linear</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos"> 202</span></a>                          <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos"> 203</span></a>
</span><span id="L-204"><a href="#L-204"><span class="linenos"> 204</span></a>        <span class="n">input_weight</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_weight&quot;</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos"> 205</span></a>
</span><span id="L-206"><a href="#L-206"><span class="linenos"> 206</span></a>        <span class="n">weight_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_weight</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos"> 207</span></a>                                                               <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos"> 208</span></a>                                                                <span class="n">current_node</span><span class="o">.</span><span class="n">in_features</span><span class="p">])</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos"> 209</span></a>
</span><span id="L-210"><a href="#L-210"><span class="linenos"> 210</span></a>        <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">)</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos"> 211</span></a>
</span><span id="L-212"><a href="#L-212"><span class="linenos"> 212</span></a>        <span class="k">if</span> <span class="n">current_node</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos"> 213</span></a>            <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos"> 214</span></a>            <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos"> 215</span></a>                                                                 <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">out_features</span><span class="p">])</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos"> 216</span></a>            <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos"> 217</span></a>
</span><span id="L-218"><a href="#L-218"><span class="linenos"> 218</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos"> 219</span></a>                <span class="s1">&#39;Gemm&#39;</span><span class="p">,</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos"> 220</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">],</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos"> 221</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos"> 222</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos"> 223</span></a>                <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos"> 224</span></a>                <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos"> 225</span></a>                <span class="n">transB</span><span class="o">=</span><span class="mi">0</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos"> 226</span></a>            <span class="p">)</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos"> 227</span></a>
</span><span id="L-228"><a href="#L-228"><span class="linenos"> 228</span></a>            <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos"> 229</span></a>            <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos"> 230</span></a>
</span><span id="L-231"><a href="#L-231"><span class="linenos"> 231</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos"> 232</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos"> 233</span></a>                <span class="s1">&#39;Gemm&#39;</span><span class="p">,</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos"> 234</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">],</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos"> 235</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos"> 236</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos"> 237</span></a>                <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos"> 238</span></a>                <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos"> 239</span></a>                <span class="n">transB</span><span class="o">=</span><span class="mi">0</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos"> 240</span></a>            <span class="p">)</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos"> 241</span></a>
</span><span id="L-242"><a href="#L-242"><span class="linenos"> 242</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_value_info</span><span class="p">)</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos"> 243</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">)</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos"> 244</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos"> 245</span></a>
</span><span id="L-246"><a href="#L-246"><span class="linenos"> 246</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos"> 247</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_batchnorm</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos"> 248</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos"> 249</span></a>
</span><span id="L-250"><a href="#L-250"><span class="linenos"> 250</span></a>        <span class="n">input_scale</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>
</span><span id="L-251"><a href="#L-251"><span class="linenos"> 251</span></a>        <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos"> 252</span></a>        <span class="n">input_mean</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos"> 253</span></a>        <span class="n">input_var</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_var&quot;</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos"> 254</span></a>
</span><span id="L-255"><a href="#L-255"><span class="linenos"> 255</span></a>        <span class="n">scale_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_scale</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos"> 256</span></a>                                                              <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos"> 257</span></a>        <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos"> 258</span></a>                                                             <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="L-259"><a href="#L-259"><span class="linenos"> 259</span></a>        <span class="n">mean_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_mean</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos"> 260</span></a>                                                             <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos"> 261</span></a>        <span class="n">var_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_var</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos"> 262</span></a>                                                            <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos"> 263</span></a>
</span><span id="L-264"><a href="#L-264"><span class="linenos"> 264</span></a>        <span class="n">scale_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">)</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos"> 265</span></a>        <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="L-266"><a href="#L-266"><span class="linenos"> 266</span></a>        <span class="n">mean_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">running_mean</span><span class="p">,</span> <span class="n">input_mean</span><span class="p">)</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos"> 267</span></a>        <span class="n">var_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">running_var</span><span class="p">,</span> <span class="n">input_var</span><span class="p">)</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos"> 268</span></a>
</span><span id="L-269"><a href="#L-269"><span class="linenos"> 269</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos"> 270</span></a>            <span class="s1">&#39;BatchNormalization&#39;</span><span class="p">,</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos"> 271</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">input_mean</span><span class="p">,</span> <span class="n">input_var</span><span class="p">],</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos"> 272</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-273"><a href="#L-273"><span class="linenos"> 273</span></a>            <span class="n">epsilon</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos"> 274</span></a>            <span class="n">momentum</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos"> 275</span></a>            <span class="n">training_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos"> 276</span></a>        <span class="p">)</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos"> 277</span></a>
</span><span id="L-278"><a href="#L-278"><span class="linenos"> 278</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_value_info</span><span class="p">)</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos"> 279</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos"> 280</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_value_info</span><span class="p">)</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos"> 281</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var_value_info</span><span class="p">)</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos"> 282</span></a>
</span><span id="L-283"><a href="#L-283"><span class="linenos"> 283</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_tensor</span><span class="p">)</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos"> 284</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos"> 285</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_tensor</span><span class="p">)</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos"> 286</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var_tensor</span><span class="p">)</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos"> 287</span></a>
</span><span id="L-288"><a href="#L-288"><span class="linenos"> 288</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos"> 289</span></a>
</span><span id="L-290"><a href="#L-290"><span class="linenos"> 290</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos"> 291</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_conv</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos"> 292</span></a>                        <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-293"><a href="#L-293"><span class="linenos"> 293</span></a>
</span><span id="L-294"><a href="#L-294"><span class="linenos"> 294</span></a>        <span class="n">weight_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos"> 295</span></a>        <span class="n">input_weight</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_weight&quot;</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos"> 296</span></a>
</span><span id="L-297"><a href="#L-297"><span class="linenos"> 297</span></a>        <span class="n">weight_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_weight</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos"> 298</span></a>                                                               <span class="n">weight_size</span><span class="p">)</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos"> 299</span></a>
</span><span id="L-300"><a href="#L-300"><span class="linenos"> 300</span></a>        <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">)</span>
</span><span id="L-301"><a href="#L-301"><span class="linenos"> 301</span></a>
</span><span id="L-302"><a href="#L-302"><span class="linenos"> 302</span></a>        <span class="k">if</span> <span class="n">current_node</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos"> 303</span></a>
</span><span id="L-304"><a href="#L-304"><span class="linenos"> 304</span></a>            <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos"> 305</span></a>            <span class="n">bias_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos"> 306</span></a>
</span><span id="L-307"><a href="#L-307"><span class="linenos"> 307</span></a>            <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-308"><a href="#L-308"><span class="linenos"> 308</span></a>                                                                 <span class="n">bias_size</span><span class="p">)</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos"> 309</span></a>            <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos"> 310</span></a>
</span><span id="L-311"><a href="#L-311"><span class="linenos"> 311</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos"> 312</span></a>                <span class="s1">&#39;Conv&#39;</span><span class="p">,</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos"> 313</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">],</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos"> 314</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos"> 315</span></a>                <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos"> 316</span></a>                <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos"> 317</span></a>                <span class="n">dilations</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">),</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos"> 318</span></a>                <span class="n">groups</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos"> 319</span></a>                <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos"> 320</span></a>            <span class="p">)</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos"> 321</span></a>
</span><span id="L-322"><a href="#L-322"><span class="linenos"> 322</span></a>            <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos"> 323</span></a>            <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos"> 324</span></a>
</span><span id="L-325"><a href="#L-325"><span class="linenos"> 325</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos"> 326</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos"> 327</span></a>                <span class="s1">&#39;Conv&#39;</span><span class="p">,</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos"> 328</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">],</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos"> 329</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos"> 330</span></a>                <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos"> 331</span></a>                <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos"> 332</span></a>                <span class="n">dilations</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">),</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos"> 333</span></a>                <span class="n">groups</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos"> 334</span></a>                <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos"> 335</span></a>            <span class="p">)</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos"> 336</span></a>
</span><span id="L-337"><a href="#L-337"><span class="linenos"> 337</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_value_info</span><span class="p">)</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos"> 338</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">)</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos"> 339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos"> 340</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos"> 341</span></a>
</span><span id="L-342"><a href="#L-342"><span class="linenos"> 342</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos"> 343</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_averagepool</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos"> 344</span></a>                               <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos"> 345</span></a>
</span><span id="L-346"><a href="#L-346"><span class="linenos"> 346</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos"> 347</span></a>            <span class="s1">&#39;AveragePool&#39;</span><span class="p">,</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos"> 348</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos"> 349</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos"> 350</span></a>            <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">),</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos"> 351</span></a>            <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">),</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos"> 352</span></a>            <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos"> 353</span></a>            <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos"> 354</span></a>            <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos"> 355</span></a>        <span class="p">)</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos"> 356</span></a>
</span><span id="L-357"><a href="#L-357"><span class="linenos"> 357</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos"> 358</span></a>
</span><span id="L-359"><a href="#L-359"><span class="linenos"> 359</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos"> 360</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_maxpool</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos"> 361</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos"> 362</span></a>
</span><span id="L-363"><a href="#L-363"><span class="linenos"> 363</span></a>        <span class="c1"># N.B. we do not support the attribute storage_order of ONNX</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos"> 364</span></a>        <span class="c1"># ONNX does not support the return_indices parameters</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos"> 365</span></a>
</span><span id="L-366"><a href="#L-366"><span class="linenos"> 366</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos"> 367</span></a>            <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos"> 368</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos"> 369</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos"> 370</span></a>            <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">),</span>
</span><span id="L-371"><a href="#L-371"><span class="linenos"> 371</span></a>            <span class="n">dilations</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos"> 372</span></a>            <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos"> 373</span></a>            <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos"> 374</span></a>            <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos"> 375</span></a>        <span class="p">)</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos"> 376</span></a>
</span><span id="L-377"><a href="#L-377"><span class="linenos"> 377</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos"> 378</span></a>
</span><span id="L-379"><a href="#L-379"><span class="linenos"> 379</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos"> 380</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_lrn</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos"> 381</span></a>                       <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos"> 382</span></a>
</span><span id="L-383"><a href="#L-383"><span class="linenos"> 383</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos"> 384</span></a>            <span class="s1">&#39;LRN&#39;</span><span class="p">,</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos"> 385</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos"> 386</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos"> 387</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos"> 388</span></a>            <span class="n">beta</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos"> 389</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos"> 390</span></a>            <span class="n">size</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">size</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos"> 391</span></a>        <span class="p">)</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos"> 392</span></a>
</span><span id="L-393"><a href="#L-393"><span class="linenos"> 393</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos"> 394</span></a>
</span><span id="L-395"><a href="#L-395"><span class="linenos"> 395</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos"> 396</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_softmax</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos"> 397</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos"> 398</span></a>
</span><span id="L-399"><a href="#L-399"><span class="linenos"> 399</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the axis by 1</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos"> 400</span></a>        <span class="c1"># when we pass to the onnx representation.</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos"> 401</span></a>        <span class="n">temp_axis</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos"> 402</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos"> 403</span></a>            <span class="s1">&#39;Softmax&#39;</span><span class="p">,</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos"> 404</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos"> 405</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos"> 406</span></a>            <span class="n">axis</span><span class="o">=</span><span class="n">temp_axis</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos"> 407</span></a>        <span class="p">)</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos"> 408</span></a>
</span><span id="L-409"><a href="#L-409"><span class="linenos"> 409</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos"> 410</span></a>
</span><span id="L-411"><a href="#L-411"><span class="linenos"> 411</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos"> 412</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_unsqueeze</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos"> 413</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos"> 414</span></a>
</span><span id="L-415"><a href="#L-415"><span class="linenos"> 415</span></a>        <span class="n">axes_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">axes</span><span class="p">)]</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos"> 416</span></a>        <span class="n">input_axes</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_axes&quot;</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos"> 417</span></a>
</span><span id="L-418"><a href="#L-418"><span class="linenos"> 418</span></a>        <span class="n">axes_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_axes</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos"> 419</span></a>                                                             <span class="n">axes_size</span><span class="p">)</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos"> 420</span></a>
</span><span id="L-421"><a href="#L-421"><span class="linenos"> 421</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale all the axes</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos"> 422</span></a>        <span class="c1"># by 1 when we pass to the onnx representation.</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos"> 423</span></a>        <span class="n">temp_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axes</span><span class="p">]</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos"> 424</span></a>        <span class="n">axes_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temp_axes</span><span class="p">),</span> <span class="n">input_axes</span><span class="p">)</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos"> 425</span></a>
</span><span id="L-426"><a href="#L-426"><span class="linenos"> 426</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos"> 427</span></a>            <span class="s1">&#39;Unsqueeze&#39;</span><span class="p">,</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos"> 428</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_axes</span><span class="p">],</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos"> 429</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">]</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos"> 430</span></a>        <span class="p">)</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos"> 431</span></a>
</span><span id="L-432"><a href="#L-432"><span class="linenos"> 432</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axes_value_info</span><span class="p">)</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos"> 433</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axes_tensor</span><span class="p">)</span>
</span><span id="L-434"><a href="#L-434"><span class="linenos"> 434</span></a>
</span><span id="L-435"><a href="#L-435"><span class="linenos"> 435</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos"> 436</span></a>
</span><span id="L-437"><a href="#L-437"><span class="linenos"> 437</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos"> 438</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_reshape</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-439"><a href="#L-439"><span class="linenos"> 439</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos"> 440</span></a>
</span><span id="L-441"><a href="#L-441"><span class="linenos"> 441</span></a>        <span class="c1"># Need to add the batch dimension to the shape</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos"> 442</span></a>        <span class="n">temp_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos"> 443</span></a>        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos"> 444</span></a>            <span class="n">temp_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos"> 445</span></a>        <span class="n">shape_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos"> 446</span></a>        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_shape&quot;</span>
</span><span id="L-447"><a href="#L-447"><span class="linenos"> 447</span></a>
</span><span id="L-448"><a href="#L-448"><span class="linenos"> 448</span></a>        <span class="n">shape_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos"> 449</span></a>                                                              <span class="n">shape_size</span><span class="p">)</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos"> 450</span></a>
</span><span id="L-451"><a href="#L-451"><span class="linenos"> 451</span></a>        <span class="n">shape_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temp_shape</span><span class="p">),</span> <span class="n">input_shape</span><span class="p">)</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos"> 452</span></a>
</span><span id="L-453"><a href="#L-453"><span class="linenos"> 453</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos"> 454</span></a>            <span class="s1">&#39;Reshape&#39;</span><span class="p">,</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos"> 455</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">],</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos"> 456</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos"> 457</span></a>            <span class="n">allow_zero</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">allow_zero</span><span class="p">)</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos"> 458</span></a>        <span class="p">)</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos"> 459</span></a>
</span><span id="L-460"><a href="#L-460"><span class="linenos"> 460</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_value_info</span><span class="p">)</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos"> 461</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_tensor</span><span class="p">)</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos"> 462</span></a>
</span><span id="L-463"><a href="#L-463"><span class="linenos"> 463</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos"> 464</span></a>
</span><span id="L-465"><a href="#L-465"><span class="linenos"> 465</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos"> 466</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_flatten</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos"> 467</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos"> 468</span></a>
</span><span id="L-469"><a href="#L-469"><span class="linenos"> 469</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the axis by 1</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos"> 470</span></a>        <span class="c1"># when we pass to the onnx representation.</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos"> 471</span></a>        <span class="n">temp_axis</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos"> 472</span></a>
</span><span id="L-473"><a href="#L-473"><span class="linenos"> 473</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos"> 474</span></a>            <span class="s1">&#39;Flatten&#39;</span><span class="p">,</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos"> 475</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-476"><a href="#L-476"><span class="linenos"> 476</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos"> 477</span></a>            <span class="n">axis</span><span class="o">=</span><span class="n">temp_axis</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos"> 478</span></a>        <span class="p">)</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos"> 479</span></a>
</span><span id="L-480"><a href="#L-480"><span class="linenos"> 480</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos"> 481</span></a>
</span><span id="L-482"><a href="#L-482"><span class="linenos"> 482</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos"> 483</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_dropout</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos"> 484</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos"> 485</span></a>
</span><span id="L-486"><a href="#L-486"><span class="linenos"> 486</span></a>        <span class="c1"># N.B. we do not support the seed attribute and the training_mode input.</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos"> 487</span></a>
</span><span id="L-488"><a href="#L-488"><span class="linenos"> 488</span></a>        <span class="n">ratio_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos"> 489</span></a>        <span class="n">input_ratio</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_ratio&quot;</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos"> 490</span></a>
</span><span id="L-491"><a href="#L-491"><span class="linenos"> 491</span></a>        <span class="n">ratio_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_ratio</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos"> 492</span></a>                                                              <span class="n">ratio_size</span><span class="p">)</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos"> 493</span></a>
</span><span id="L-494"><a href="#L-494"><span class="linenos"> 494</span></a>        <span class="n">ratio_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">current_node</span><span class="o">.</span><span class="n">p</span><span class="p">]),</span> <span class="n">input_ratio</span><span class="p">)</span>
</span><span id="L-495"><a href="#L-495"><span class="linenos"> 495</span></a>
</span><span id="L-496"><a href="#L-496"><span class="linenos"> 496</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos"> 497</span></a>            <span class="s1">&#39;Dropout&#39;</span><span class="p">,</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos"> 498</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_ratio</span><span class="p">],</span>
</span><span id="L-499"><a href="#L-499"><span class="linenos"> 499</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">]</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos"> 500</span></a>        <span class="p">)</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos"> 501</span></a>
</span><span id="L-502"><a href="#L-502"><span class="linenos"> 502</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio_value_info</span><span class="p">)</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos"> 503</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio_tensor</span><span class="p">)</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos"> 504</span></a>
</span><span id="L-505"><a href="#L-505"><span class="linenos"> 505</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos"> 506</span></a>
</span><span id="L-507"><a href="#L-507"><span class="linenos"> 507</span></a>    <span class="nd">@staticmethod</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos"> 508</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_transpose</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos"> 509</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos"> 510</span></a>
</span><span id="L-511"><a href="#L-511"><span class="linenos"> 511</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the perm by 1</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos"> 512</span></a>        <span class="c1"># and add the 0 dimension when we pass to the onnx representation.</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos"> 513</span></a>        <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos"> 514</span></a>        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">perm</span><span class="p">:</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos"> 515</span></a>            <span class="n">perm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos"> 516</span></a>
</span><span id="L-517"><a href="#L-517"><span class="linenos"> 517</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos"> 518</span></a>            <span class="s1">&#39;Transpose&#39;</span><span class="p">,</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos"> 519</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos"> 520</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos"> 521</span></a>            <span class="n">perm</span><span class="o">=</span><span class="n">perm</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos"> 522</span></a>        <span class="p">)</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos"> 523</span></a>
</span><span id="L-524"><a href="#L-524"><span class="linenos"> 524</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos"> 525</span></a>
</span><span id="L-526"><a href="#L-526"><span class="linenos"> 526</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ONNXNetwork</span><span class="p">:</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos"> 527</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos"> 528</span></a><span class="sd">        Convert the neural network of interest to a ONNX representation.</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos"> 529</span></a>
</span><span id="L-530"><a href="#L-530"><span class="linenos"> 530</span></a><span class="sd">        Parameters</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos"> 531</span></a><span class="sd">        ----------</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos"> 532</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos"> 533</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="L-534"><a href="#L-534"><span class="linenos"> 534</span></a>
</span><span id="L-535"><a href="#L-535"><span class="linenos"> 535</span></a><span class="sd">        Returns</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos"> 536</span></a><span class="sd">        ----------</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos"> 537</span></a><span class="sd">        ONNXNetwork</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos"> 538</span></a><span class="sd">            The ONNX representation resulting from the conversion of the original network.</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos"> 539</span></a>
</span><span id="L-540"><a href="#L-540"><span class="linenos"> 540</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos"> 541</span></a>
</span><span id="L-542"><a href="#L-542"><span class="linenos"> 542</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-543"><a href="#L-543"><span class="linenos"> 543</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos"> 544</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos"> 545</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos"> 546</span></a>
</span><span id="L-547"><a href="#L-547"><span class="linenos"> 547</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-548"><a href="#L-548"><span class="linenos"> 548</span></a>
</span><span id="L-549"><a href="#L-549"><span class="linenos"> 549</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos"> 550</span></a>
</span><span id="L-551"><a href="#L-551"><span class="linenos"> 551</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos"> 552</span></a>
</span><span id="L-553"><a href="#L-553"><span class="linenos"> 553</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos"> 554</span></a>
</span><span id="L-555"><a href="#L-555"><span class="linenos"> 555</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">):</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos"> 556</span></a>                            <span class="n">pytorch_cv</span> <span class="o">=</span> <span class="n">PyTorchConverter</span><span class="p">()</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos"> 557</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">pytorch_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos"> 558</span></a>
</span><span id="L-559"><a href="#L-559"><span class="linenos"> 559</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos"> 560</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-561"><a href="#L-561"><span class="linenos"> 561</span></a>                        <span class="k">break</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos"> 562</span></a>
</span><span id="L-563"><a href="#L-563"><span class="linenos"> 563</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos"> 564</span></a>
</span><span id="L-565"><a href="#L-565"><span class="linenos"> 565</span></a>                <span class="n">current_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos"> 566</span></a>                <span class="n">previous_output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos"> 567</span></a>                <span class="n">input_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos"> 568</span></a>                <span class="n">output_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos"> 569</span></a>                <span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos"> 570</span></a>                <span class="n">onnx_nodes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos"> 571</span></a>
</span><span id="L-572"><a href="#L-572"><span class="linenos"> 572</span></a>                <span class="k">while</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos"> 573</span></a>
</span><span id="L-574"><a href="#L-574"><span class="linenos"> 574</span></a>                    <span class="n">current_node</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos"> 575</span></a>                    <span class="n">current_input</span> <span class="o">=</span> <span class="n">previous_output</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos"> 576</span></a>                    <span class="n">current_output</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos"> 577</span></a>
</span><span id="L-578"><a href="#L-578"><span class="linenos"> 578</span></a>                    <span class="n">input_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos"> 579</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">in_dim</span><span class="p">:</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos"> 580</span></a>                        <span class="n">input_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos"> 581</span></a>
</span><span id="L-582"><a href="#L-582"><span class="linenos"> 582</span></a>                    <span class="n">output_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos"> 583</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">out_dim</span><span class="p">:</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos"> 584</span></a>                        <span class="n">output_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos"> 585</span></a>
</span><span id="L-586"><a href="#L-586"><span class="linenos"> 586</span></a>                    <span class="n">input_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos"> 587</span></a>                                                                          <span class="n">input_dim</span><span class="p">)</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos"> 588</span></a>                    <span class="n">output_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_output</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="L-589"><a href="#L-589"><span class="linenos"> 589</span></a>                                                                           <span class="n">output_dim</span><span class="p">)</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos"> 590</span></a>
</span><span id="L-591"><a href="#L-591"><span class="linenos"> 591</span></a>                    <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_value_info</span><span class="p">)</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos"> 592</span></a>                    <span class="n">output_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_value_info</span><span class="p">)</span>
</span><span id="L-593"><a href="#L-593"><span class="linenos"> 593</span></a>
</span><span id="L-594"><a href="#L-594"><span class="linenos"> 594</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos"> 595</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_relu</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos"> 596</span></a>
</span><span id="L-597"><a href="#L-597"><span class="linenos"> 597</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos"> 598</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_elu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos"> 599</span></a>
</span><span id="L-600"><a href="#L-600"><span class="linenos"> 600</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos"> 601</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_leakyrelu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos"> 602</span></a>
</span><span id="L-603"><a href="#L-603"><span class="linenos"> 603</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos"> 604</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_celu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos"> 605</span></a>
</span><span id="L-606"><a href="#L-606"><span class="linenos"> 606</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="L-607"><a href="#L-607"><span class="linenos"> 607</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_sigmoid</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos"> 608</span></a>
</span><span id="L-609"><a href="#L-609"><span class="linenos"> 609</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="L-610"><a href="#L-610"><span class="linenos"> 610</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_tanh</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-611"><a href="#L-611"><span class="linenos"> 611</span></a>
</span><span id="L-612"><a href="#L-612"><span class="linenos"> 612</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="L-613"><a href="#L-613"><span class="linenos"> 613</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_linear</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos"> 614</span></a>                                               <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos"> 615</span></a>
</span><span id="L-616"><a href="#L-616"><span class="linenos"> 616</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos"> 617</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_batchnorm</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos"> 618</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos"> 619</span></a>
</span><span id="L-620"><a href="#L-620"><span class="linenos"> 620</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos"> 621</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_conv</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos"> 622</span></a>                                             <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos"> 623</span></a>
</span><span id="L-624"><a href="#L-624"><span class="linenos"> 624</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos"> 625</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_averagepool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos"> 626</span></a>
</span><span id="L-627"><a href="#L-627"><span class="linenos"> 627</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos"> 628</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_maxpool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos"> 629</span></a>
</span><span id="L-630"><a href="#L-630"><span class="linenos"> 630</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos"> 631</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_lrn</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-632"><a href="#L-632"><span class="linenos"> 632</span></a>
</span><span id="L-633"><a href="#L-633"><span class="linenos"> 633</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos"> 634</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_softmax</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos"> 635</span></a>
</span><span id="L-636"><a href="#L-636"><span class="linenos"> 636</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos"> 637</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_unsqueeze</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos"> 638</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos"> 639</span></a>
</span><span id="L-640"><a href="#L-640"><span class="linenos"> 640</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="L-641"><a href="#L-641"><span class="linenos"> 641</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_reshape</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos"> 642</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos"> 643</span></a>
</span><span id="L-644"><a href="#L-644"><span class="linenos"> 644</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos"> 645</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_flatten</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos"> 646</span></a>
</span><span id="L-647"><a href="#L-647"><span class="linenos"> 647</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos"> 648</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_dropout</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos"> 649</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos"> 650</span></a>
</span><span id="L-651"><a href="#L-651"><span class="linenos"> 651</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">):</span>
</span><span id="L-652"><a href="#L-652"><span class="linenos"> 652</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_transpose</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="L-653"><a href="#L-653"><span class="linenos"> 653</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos"> 654</span></a>
</span><span id="L-655"><a href="#L-655"><span class="linenos"> 655</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos"> 656</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos"> 657</span></a>
</span><span id="L-658"><a href="#L-658"><span class="linenos"> 658</span></a>                    <span class="n">previous_output</span> <span class="o">=</span> <span class="n">current_output</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos"> 659</span></a>
</span><span id="L-660"><a href="#L-660"><span class="linenos"> 660</span></a>                <span class="n">onnx_graph</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos"> 661</span></a>                    <span class="n">nodes</span><span class="o">=</span><span class="n">onnx_nodes</span><span class="p">,</span>
</span><span id="L-662"><a href="#L-662"><span class="linenos"> 662</span></a>                    <span class="n">name</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos"> 663</span></a>                    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos"> 664</span></a>                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output_info</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos"> 665</span></a>                    <span class="n">initializer</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos"> 666</span></a>                    <span class="n">value_info</span><span class="o">=</span><span class="n">input_info</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos"> 667</span></a>                <span class="p">)</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos"> 668</span></a>
</span><span id="L-669"><a href="#L-669"><span class="linenos"> 669</span></a>                <span class="n">onnx_network</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">onnx_graph</span><span class="p">)</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos"> 670</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">ONNXNetwork</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">)</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos"> 671</span></a>
</span><span id="L-672"><a href="#L-672"><span class="linenos"> 672</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos"> 673</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos"> 674</span></a>
</span><span id="L-675"><a href="#L-675"><span class="linenos"> 675</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos"> 676</span></a>
</span><span id="L-677"><a href="#L-677"><span class="linenos"> 677</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos"> 678</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos"> 679</span></a><span class="sd">        Convert the ONNX representation of interest to the internal one.</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos"> 680</span></a>
</span><span id="L-681"><a href="#L-681"><span class="linenos"> 681</span></a><span class="sd">        Parameters</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos"> 682</span></a><span class="sd">        ----------</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos"> 683</span></a><span class="sd">        alt_rep : ONNXNetwork</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos"> 684</span></a><span class="sd">            The ONNX Representation to convert.</span>
</span><span id="L-685"><a href="#L-685"><span class="linenos"> 685</span></a>
</span><span id="L-686"><a href="#L-686"><span class="linenos"> 686</span></a><span class="sd">        Returns</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos"> 687</span></a><span class="sd">        ----------</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos"> 688</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos"> 689</span></a><span class="sd">            The Neural Network resulting from the conversion of ONNX Representation.</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos"> 690</span></a>
</span><span id="L-691"><a href="#L-691"><span class="linenos"> 691</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos"> 692</span></a>
</span><span id="L-693"><a href="#L-693"><span class="linenos"> 693</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos"> 694</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos"> 695</span></a>
</span><span id="L-696"><a href="#L-696"><span class="linenos"> 696</span></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-697"><a href="#L-697"><span class="linenos"> 697</span></a>        <span class="k">for</span> <span class="n">initializer</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">:</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos"> 698</span></a>            <span class="n">parameters</span><span class="p">[</span><span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos"> 699</span></a>
</span><span id="L-700"><a href="#L-700"><span class="linenos"> 700</span></a>        <span class="n">shape_info</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos"> 701</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos"> 702</span></a>            <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos"> 703</span></a>            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">i</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos"> 704</span></a>                <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dim</span><span class="o">.</span><span class="n">dim_value</span><span class="p">)</span>
</span><span id="L-705"><a href="#L-705"><span class="linenos"> 705</span></a>            <span class="n">shape_info</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos"> 706</span></a>
</span><span id="L-707"><a href="#L-707"><span class="linenos"> 707</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos"> 708</span></a>        <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos"> 709</span></a>        <span class="k">if</span> <span class="n">in_dim</span> <span class="o">==</span> <span class="p">():</span>
</span><span id="L-710"><a href="#L-710"><span class="linenos"> 710</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos"> 711</span></a>
</span><span id="L-712"><a href="#L-712"><span class="linenos"> 712</span></a>        <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos"> 713</span></a>        <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-714"><a href="#L-714"><span class="linenos"> 714</span></a>
</span><span id="L-715"><a href="#L-715"><span class="linenos"> 715</span></a>        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos"> 716</span></a>
</span><span id="L-717"><a href="#L-717"><span class="linenos"> 717</span></a>            <span class="k">if</span> <span class="n">matmul_found</span><span class="p">:</span>
</span><span id="L-718"><a href="#L-718"><span class="linenos"> 718</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Add&quot;</span><span class="p">:</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos"> 719</span></a>
</span><span id="L-720"><a href="#L-720"><span class="linenos"> 720</span></a>                    <span class="c1"># We assume that the bias is always the second element of node.input</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos"> 721</span></a>
</span><span id="L-722"><a href="#L-722"><span class="linenos"> 722</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="L-723"><a href="#L-723"><span class="linenos"> 723</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos"> 724</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
</span><span id="L-725"><a href="#L-725"><span class="linenos"> 725</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos"> 726</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos"> 727</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos"> 728</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="L-729"><a href="#L-729"><span class="linenos"> 729</span></a>                    <span class="k">continue</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos"> 730</span></a>
</span><span id="L-731"><a href="#L-731"><span class="linenos"> 731</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos"> 732</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos"> 733</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</span><span id="L-734"><a href="#L-734"><span class="linenos"> 734</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos"> 735</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos"> 736</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos"> 737</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="L-738"><a href="#L-738"><span class="linenos"> 738</span></a>
</span><span id="L-739"><a href="#L-739"><span class="linenos"> 739</span></a>            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">:</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos"> 740</span></a>
</span><span id="L-741"><a href="#L-741"><span class="linenos"> 741</span></a>                <span class="c1"># If the weight is the second parameter we need to transpose it</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos"> 742</span></a>
</span><span id="L-743"><a href="#L-743"><span class="linenos"> 743</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="L-744"><a href="#L-744"><span class="linenos"> 744</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span><span id="L-745"><a href="#L-745"><span class="linenos"> 745</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos"> 746</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos"> 747</span></a>
</span><span id="L-748"><a href="#L-748"><span class="linenos"> 748</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos"> 749</span></a>                <span class="n">temp_fc</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos"> 750</span></a>                <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos"> 751</span></a>                <span class="k">continue</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos"> 752</span></a>
</span><span id="L-753"><a href="#L-753"><span class="linenos"> 753</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Relu&quot;</span><span class="p">:</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos"> 754</span></a>
</span><span id="L-755"><a href="#L-755"><span class="linenos"> 755</span></a>                <span class="c1"># We assume that the real input of the node is always the first element of node.input</span>
</span><span id="L-756"><a href="#L-756"><span class="linenos"> 756</span></a>                <span class="c1"># and the first element of the shape is the batch placeholder</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos"> 757</span></a>
</span><span id="L-758"><a href="#L-758"><span class="linenos"> 758</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="L-759"><a href="#L-759"><span class="linenos"> 759</span></a>
</span><span id="L-760"><a href="#L-760"><span class="linenos"> 760</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Elu&quot;</span><span class="p">:</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos"> 761</span></a>
</span><span id="L-762"><a href="#L-762"><span class="linenos"> 762</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos"> 763</span></a>
</span><span id="L-764"><a href="#L-764"><span class="linenos"> 764</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos"> 765</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos"> 766</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-767"><a href="#L-767"><span class="linenos"> 767</span></a>
</span><span id="L-768"><a href="#L-768"><span class="linenos"> 768</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos"> 769</span></a>
</span><span id="L-770"><a href="#L-770"><span class="linenos"> 770</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LeakyRelu&quot;</span><span class="p">:</span>
</span><span id="L-771"><a href="#L-771"><span class="linenos"> 771</span></a>
</span><span id="L-772"><a href="#L-772"><span class="linenos"> 772</span></a>                <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos"> 773</span></a>
</span><span id="L-774"><a href="#L-774"><span class="linenos"> 774</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos"> 775</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="L-776"><a href="#L-776"><span class="linenos"> 776</span></a>                        <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos"> 777</span></a>
</span><span id="L-778"><a href="#L-778"><span class="linenos"> 778</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">))</span>
</span><span id="L-779"><a href="#L-779"><span class="linenos"> 779</span></a>
</span><span id="L-780"><a href="#L-780"><span class="linenos"> 780</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Celu&quot;</span><span class="p">:</span>
</span><span id="L-781"><a href="#L-781"><span class="linenos"> 781</span></a>
</span><span id="L-782"><a href="#L-782"><span class="linenos"> 782</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos"> 783</span></a>
</span><span id="L-784"><a href="#L-784"><span class="linenos"> 784</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos"> 785</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos"> 786</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-787"><a href="#L-787"><span class="linenos"> 787</span></a>
</span><span id="L-788"><a href="#L-788"><span class="linenos"> 788</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos"> 789</span></a>
</span><span id="L-790"><a href="#L-790"><span class="linenos"> 790</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos"> 791</span></a>
</span><span id="L-792"><a href="#L-792"><span class="linenos"> 792</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="L-793"><a href="#L-793"><span class="linenos"> 793</span></a>
</span><span id="L-794"><a href="#L-794"><span class="linenos"> 794</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Tanh&quot;</span><span class="p">:</span>
</span><span id="L-795"><a href="#L-795"><span class="linenos"> 795</span></a>
</span><span id="L-796"><a href="#L-796"><span class="linenos"> 796</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos"> 797</span></a>
</span><span id="L-798"><a href="#L-798"><span class="linenos"> 798</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Gemm&quot;</span><span class="p">:</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos"> 799</span></a>                <span class="c1"># We assume that the weight tensor is always the second element of node.input and the bias tensor</span>
</span><span id="L-800"><a href="#L-800"><span class="linenos"> 800</span></a>                <span class="c1"># is always the third.</span>
</span><span id="L-801"><a href="#L-801"><span class="linenos"> 801</span></a>                <span class="c1"># N.B: We do not support the attributes transA and transB,</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos"> 802</span></a>                <span class="c1"># therefore we need to transpose the weight vector.</span>
</span><span id="L-803"><a href="#L-803"><span class="linenos"> 803</span></a>                <span class="c1"># TODO: Can we support transA and transB in some way?</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos"> 804</span></a>
</span><span id="L-805"><a href="#L-805"><span class="linenos"> 805</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos"> 806</span></a>                    <span class="k">if</span> <span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transA&#39;</span> <span class="ow">or</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transB&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-807"><a href="#L-807"><span class="linenos"> 807</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos"> 808</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos"> 809</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="L-810"><a href="#L-810"><span class="linenos"> 810</span></a>
</span><span id="L-811"><a href="#L-811"><span class="linenos"> 811</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos"> 812</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos"> 813</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-814"><a href="#L-814"><span class="linenos"> 814</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos"> 815</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos"> 816</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos"> 817</span></a>
</span><span id="L-818"><a href="#L-818"><span class="linenos"> 818</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-819"><a href="#L-819"><span class="linenos"> 819</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos"> 820</span></a>                                                          <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">))</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos"> 821</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;BatchNormalization&quot;</span><span class="p">:</span>
</span><span id="L-822"><a href="#L-822"><span class="linenos"> 822</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos"> 823</span></a>                <span class="c1"># is always the second, the bias tensor is always the third, the running_mean always the fourth</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos"> 824</span></a>                <span class="c1"># and the running_var always the fifth.</span>
</span><span id="L-825"><a href="#L-825"><span class="linenos"> 825</span></a>
</span><span id="L-826"><a href="#L-826"><span class="linenos"> 826</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos"> 827</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos"> 828</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos"> 829</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">4</span><span class="p">]]</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos"> 830</span></a>
</span><span id="L-831"><a href="#L-831"><span class="linenos"> 831</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-05</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos"> 832</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos"> 833</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-834"><a href="#L-834"><span class="linenos"> 834</span></a>
</span><span id="L-835"><a href="#L-835"><span class="linenos"> 835</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos"> 836</span></a>                        <span class="n">eps</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-837"><a href="#L-837"><span class="linenos"> 837</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span>
</span><span id="L-838"><a href="#L-838"><span class="linenos"> 838</span></a>                        <span class="n">momentum</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-839"><a href="#L-839"><span class="linenos"> 839</span></a>
</span><span id="L-840"><a href="#L-840"><span class="linenos"> 840</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="L-841"><a href="#L-841"><span class="linenos"> 841</span></a>                                                     <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">))</span>
</span><span id="L-842"><a href="#L-842"><span class="linenos"> 842</span></a>
</span><span id="L-843"><a href="#L-843"><span class="linenos"> 843</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span><span class="p">:</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos"> 844</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="L-845"><a href="#L-845"><span class="linenos"> 845</span></a>                <span class="c1"># is always the second and the bias tensor is always the third.</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos"> 846</span></a>
</span><span id="L-847"><a href="#L-847"><span class="linenos"> 847</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos"> 848</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-849"><a href="#L-849"><span class="linenos"> 849</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos"> 850</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-851"><a href="#L-851"><span class="linenos"> 851</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-852"><a href="#L-852"><span class="linenos"> 852</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-853"><a href="#L-853"><span class="linenos"> 853</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos"> 854</span></a>
</span><span id="L-855"><a href="#L-855"><span class="linenos"> 855</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos"> 856</span></a>
</span><span id="L-857"><a href="#L-857"><span class="linenos"> 857</span></a>                <span class="c1"># TODO: at present we do not support auto_pad and implicit kernel_shape.</span>
</span><span id="L-858"><a href="#L-858"><span class="linenos"> 858</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="L-859"><a href="#L-859"><span class="linenos"> 859</span></a>                <span class="c1"># We need to exclude the first axis (channels) from the following quantities.</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos"> 860</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-861"><a href="#L-861"><span class="linenos"> 861</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-862"><a href="#L-862"><span class="linenos"> 862</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos"> 863</span></a>
</span><span id="L-864"><a href="#L-864"><span class="linenos"> 864</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-865"><a href="#L-865"><span class="linenos"> 865</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="L-866"><a href="#L-866"><span class="linenos"> 866</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-867"><a href="#L-867"><span class="linenos"> 867</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;groups&#39;</span><span class="p">:</span>
</span><span id="L-868"><a href="#L-868"><span class="linenos"> 868</span></a>                        <span class="n">groups</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="L-869"><a href="#L-869"><span class="linenos"> 869</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="L-870"><a href="#L-870"><span class="linenos"> 870</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos"> 871</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="L-872"><a href="#L-872"><span class="linenos"> 872</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-873"><a href="#L-873"><span class="linenos"> 873</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="L-874"><a href="#L-874"><span class="linenos"> 874</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos"> 875</span></a>
</span><span id="L-876"><a href="#L-876"><span class="linenos"> 876</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span>
</span><span id="L-877"><a href="#L-877"><span class="linenos"> 877</span></a>                                                <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
</span><span id="L-878"><a href="#L-878"><span class="linenos"> 878</span></a>
</span><span id="L-879"><a href="#L-879"><span class="linenos"> 879</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;AveragePool&quot;</span><span class="p">:</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos"> 880</span></a>
</span><span id="L-881"><a href="#L-881"><span class="linenos"> 881</span></a>                <span class="c1"># TODO: at present we do not support auto_pad.</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos"> 882</span></a>
</span><span id="L-883"><a href="#L-883"><span class="linenos"> 883</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-884"><a href="#L-884"><span class="linenos"> 884</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-885"><a href="#L-885"><span class="linenos"> 885</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos"> 886</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos"> 887</span></a>
</span><span id="L-888"><a href="#L-888"><span class="linenos"> 888</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-889"><a href="#L-889"><span class="linenos"> 889</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos"> 890</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-891"><a href="#L-891"><span class="linenos"> 891</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;count_include_pad&#39;</span><span class="p">:</span>
</span><span id="L-892"><a href="#L-892"><span class="linenos"> 892</span></a>                        <span class="n">count_include_pad</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-893"><a href="#L-893"><span class="linenos"> 893</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="L-894"><a href="#L-894"><span class="linenos"> 894</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-895"><a href="#L-895"><span class="linenos"> 895</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="L-896"><a href="#L-896"><span class="linenos"> 896</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos"> 897</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="L-898"><a href="#L-898"><span class="linenos"> 898</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-899"><a href="#L-899"><span class="linenos"> 899</span></a>
</span><span id="L-900"><a href="#L-900"><span class="linenos"> 900</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos"> 901</span></a>                                                       <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">))</span>
</span><span id="L-902"><a href="#L-902"><span class="linenos"> 902</span></a>
</span><span id="L-903"><a href="#L-903"><span class="linenos"> 903</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MaxPool&quot;</span><span class="p">:</span>
</span><span id="L-904"><a href="#L-904"><span class="linenos"> 904</span></a>
</span><span id="L-905"><a href="#L-905"><span class="linenos"> 905</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-906"><a href="#L-906"><span class="linenos"> 906</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos"> 907</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-908"><a href="#L-908"><span class="linenos"> 908</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos"> 909</span></a>
</span><span id="L-910"><a href="#L-910"><span class="linenos"> 910</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-911"><a href="#L-911"><span class="linenos"> 911</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos"> 912</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos"> 913</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos"> 914</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-915"><a href="#L-915"><span class="linenos"> 915</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="L-916"><a href="#L-916"><span class="linenos"> 916</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-917"><a href="#L-917"><span class="linenos"> 917</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos"> 918</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-919"><a href="#L-919"><span class="linenos"> 919</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos"> 920</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="L-921"><a href="#L-921"><span class="linenos"> 921</span></a>
</span><span id="L-922"><a href="#L-922"><span class="linenos"> 922</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-923"><a href="#L-923"><span class="linenos"> 923</span></a>                                                   <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">))</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos"> 924</span></a>
</span><span id="L-925"><a href="#L-925"><span class="linenos"> 925</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LRN&quot;</span><span class="p">:</span>
</span><span id="L-926"><a href="#L-926"><span class="linenos"> 926</span></a>
</span><span id="L-927"><a href="#L-927"><span class="linenos"> 927</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos"> 928</span></a>                <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.75</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos"> 929</span></a>                <span class="n">k</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-930"><a href="#L-930"><span class="linenos"> 930</span></a>
</span><span id="L-931"><a href="#L-931"><span class="linenos"> 931</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-932"><a href="#L-932"><span class="linenos"> 932</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="L-933"><a href="#L-933"><span class="linenos"> 933</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-934"><a href="#L-934"><span class="linenos"> 934</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;beta&#39;</span><span class="p">:</span>
</span><span id="L-935"><a href="#L-935"><span class="linenos"> 935</span></a>                        <span class="n">beta</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-936"><a href="#L-936"><span class="linenos"> 936</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;bias&#39;</span><span class="p">:</span>
</span><span id="L-937"><a href="#L-937"><span class="linenos"> 937</span></a>                        <span class="n">k</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="L-938"><a href="#L-938"><span class="linenos"> 938</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span>
</span><span id="L-939"><a href="#L-939"><span class="linenos"> 939</span></a>                        <span class="n">size</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="L-940"><a href="#L-940"><span class="linenos"> 940</span></a>
</span><span id="L-941"><a href="#L-941"><span class="linenos"> 941</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
</span><span id="L-942"><a href="#L-942"><span class="linenos"> 942</span></a>
</span><span id="L-943"><a href="#L-943"><span class="linenos"> 943</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Softmax&quot;</span><span class="p">:</span>
</span><span id="L-944"><a href="#L-944"><span class="linenos"> 944</span></a>
</span><span id="L-945"><a href="#L-945"><span class="linenos"> 945</span></a>                <span class="c1"># Since the ONNX representation consider the batch dimension we need to scale the axis by 1</span>
</span><span id="L-946"><a href="#L-946"><span class="linenos"> 946</span></a>                <span class="c1"># when we pass to our representation.</span>
</span><span id="L-947"><a href="#L-947"><span class="linenos"> 947</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="L-948"><a href="#L-948"><span class="linenos"> 948</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-949"><a href="#L-949"><span class="linenos"> 949</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="L-950"><a href="#L-950"><span class="linenos"> 950</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-951"><a href="#L-951"><span class="linenos"> 951</span></a>
</span><span id="L-952"><a href="#L-952"><span class="linenos"> 952</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="L-953"><a href="#L-953"><span class="linenos"> 953</span></a>
</span><span id="L-954"><a href="#L-954"><span class="linenos"> 954</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Unsqueeze&quot;</span><span class="p">:</span>
</span><span id="L-955"><a href="#L-955"><span class="linenos"> 955</span></a>
</span><span id="L-956"><a href="#L-956"><span class="linenos"> 956</span></a>                <span class="n">temp_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="L-957"><a href="#L-957"><span class="linenos"> 957</span></a>                <span class="c1"># Since our representation do not consider the batch dimension we need to scale all the axes</span>
</span><span id="L-958"><a href="#L-958"><span class="linenos"> 958</span></a>                <span class="c1"># by 1 when we pass to the onnx representation.</span>
</span><span id="L-959"><a href="#L-959"><span class="linenos"> 959</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">temp_axes</span><span class="p">])</span>
</span><span id="L-960"><a href="#L-960"><span class="linenos"> 960</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
</span><span id="L-961"><a href="#L-961"><span class="linenos"> 961</span></a>
</span><span id="L-962"><a href="#L-962"><span class="linenos"> 962</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Reshape&quot;</span><span class="p">:</span>
</span><span id="L-963"><a href="#L-963"><span class="linenos"> 963</span></a>
</span><span id="L-964"><a href="#L-964"><span class="linenos"> 964</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="L-965"><a href="#L-965"><span class="linenos"> 965</span></a>                <span class="c1"># We need to eliminate the first dimension corresponding to the batch dimension</span>
</span><span id="L-966"><a href="#L-966"><span class="linenos"> 966</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-967"><a href="#L-967"><span class="linenos"> 967</span></a>                <span class="n">allow_zero</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-968"><a href="#L-968"><span class="linenos"> 968</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-969"><a href="#L-969"><span class="linenos"> 969</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;allowzero&#39;</span><span class="p">:</span>
</span><span id="L-970"><a href="#L-970"><span class="linenos"> 970</span></a>                        <span class="n">allow_zero</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="L-971"><a href="#L-971"><span class="linenos"> 971</span></a>
</span><span id="L-972"><a href="#L-972"><span class="linenos"> 972</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">allow_zero</span><span class="p">))</span>
</span><span id="L-973"><a href="#L-973"><span class="linenos"> 973</span></a>
</span><span id="L-974"><a href="#L-974"><span class="linenos"> 974</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Flatten&quot;</span><span class="p">:</span>
</span><span id="L-975"><a href="#L-975"><span class="linenos"> 975</span></a>
</span><span id="L-976"><a href="#L-976"><span class="linenos"> 976</span></a>                <span class="c1"># We need to scale the axis value since our representation does not have the batch dimension</span>
</span><span id="L-977"><a href="#L-977"><span class="linenos"> 977</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-978"><a href="#L-978"><span class="linenos"> 978</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-979"><a href="#L-979"><span class="linenos"> 979</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="L-980"><a href="#L-980"><span class="linenos"> 980</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="L-981"><a href="#L-981"><span class="linenos"> 981</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="L-982"><a href="#L-982"><span class="linenos"> 982</span></a>
</span><span id="L-983"><a href="#L-983"><span class="linenos"> 983</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Dropout&quot;</span><span class="p">:</span>
</span><span id="L-984"><a href="#L-984"><span class="linenos"> 984</span></a>
</span><span id="L-985"><a href="#L-985"><span class="linenos"> 985</span></a>                <span class="n">ratio</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-986"><a href="#L-986"><span class="linenos"> 986</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">ratio</span><span class="p">))</span>
</span><span id="L-987"><a href="#L-987"><span class="linenos"> 987</span></a>
</span><span id="L-988"><a href="#L-988"><span class="linenos"> 988</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Transpose&quot;</span><span class="p">:</span>
</span><span id="L-989"><a href="#L-989"><span class="linenos"> 989</span></a>
</span><span id="L-990"><a href="#L-990"><span class="linenos"> 990</span></a>                <span class="n">perm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-991"><a href="#L-991"><span class="linenos"> 991</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="L-992"><a href="#L-992"><span class="linenos"> 992</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;perm&#39;</span><span class="p">:</span>
</span><span id="L-993"><a href="#L-993"><span class="linenos"> 993</span></a>                        <span class="c1"># Must manage batch dimension</span>
</span><span id="L-994"><a href="#L-994"><span class="linenos"> 994</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">):</span>
</span><span id="L-995"><a href="#L-995"><span class="linenos"> 995</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">))]</span>
</span><span id="L-996"><a href="#L-996"><span class="linenos"> 996</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-997"><a href="#L-997"><span class="linenos"> 997</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">ints</span>
</span><span id="L-998"><a href="#L-998"><span class="linenos"> 998</span></a>
</span><span id="L-999"><a href="#L-999"><span class="linenos"> 999</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">perm</span><span class="p">))</span>
</span><span id="L-1000"><a href="#L-1000"><span class="linenos">1000</span></a>
</span><span id="L-1001"><a href="#L-1001"><span class="linenos">1001</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1002"><a href="#L-1002"><span class="linenos">1002</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-1003"><a href="#L-1003"><span class="linenos">1003</span></a>
</span><span id="L-1004"><a href="#L-1004"><span class="linenos">1004</span></a>            <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-1005"><a href="#L-1005"><span class="linenos">1005</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="L-1006"><a href="#L-1006"><span class="linenos">1006</span></a>
</span><span id="L-1007"><a href="#L-1007"><span class="linenos">1007</span></a>        <span class="k">return</span> <span class="n">network</span>
</span><span id="L-1008"><a href="#L-1008"><span class="linenos">1008</span></a>
</span><span id="L-1009"><a href="#L-1009"><span class="linenos">1009</span></a>
</span><span id="L-1010"><a href="#L-1010"><span class="linenos">1010</span></a><span class="k">class</span> <span class="nc">PyTorchConverter</span><span class="p">(</span><span class="n">ConversionStrategy</span><span class="p">):</span>
</span><span id="L-1011"><a href="#L-1011"><span class="linenos">1011</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1012"><a href="#L-1012"><span class="linenos">1012</span></a><span class="sd">    A class used to represent the conversion strategy for PyTorch models.</span>
</span><span id="L-1013"><a href="#L-1013"><span class="linenos">1013</span></a>
</span><span id="L-1014"><a href="#L-1014"><span class="linenos">1014</span></a><span class="sd">    Methods</span>
</span><span id="L-1015"><a href="#L-1015"><span class="linenos">1015</span></a><span class="sd">    ----------</span>
</span><span id="L-1016"><a href="#L-1016"><span class="linenos">1016</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="L-1017"><a href="#L-1017"><span class="linenos">1017</span></a><span class="sd">        Convert the neural network of interest to a PyTorchNetwork model.</span>
</span><span id="L-1018"><a href="#L-1018"><span class="linenos">1018</span></a><span class="sd">    to_neural_network(PyTorchNetwork)</span>
</span><span id="L-1019"><a href="#L-1019"><span class="linenos">1019</span></a><span class="sd">        Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.</span>
</span><span id="L-1020"><a href="#L-1020"><span class="linenos">1020</span></a>
</span><span id="L-1021"><a href="#L-1021"><span class="linenos">1021</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1022"><a href="#L-1022"><span class="linenos">1022</span></a>
</span><span id="L-1023"><a href="#L-1023"><span class="linenos">1023</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PyTorchNetwork</span><span class="p">:</span>
</span><span id="L-1024"><a href="#L-1024"><span class="linenos">1024</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1025"><a href="#L-1025"><span class="linenos">1025</span></a><span class="sd">        Convert the neural network of interest to a PyTorch representation.</span>
</span><span id="L-1026"><a href="#L-1026"><span class="linenos">1026</span></a>
</span><span id="L-1027"><a href="#L-1027"><span class="linenos">1027</span></a><span class="sd">        Parameters</span>
</span><span id="L-1028"><a href="#L-1028"><span class="linenos">1028</span></a><span class="sd">        ----------</span>
</span><span id="L-1029"><a href="#L-1029"><span class="linenos">1029</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="L-1030"><a href="#L-1030"><span class="linenos">1030</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="L-1031"><a href="#L-1031"><span class="linenos">1031</span></a>
</span><span id="L-1032"><a href="#L-1032"><span class="linenos">1032</span></a><span class="sd">        Returns</span>
</span><span id="L-1033"><a href="#L-1033"><span class="linenos">1033</span></a><span class="sd">        ----------</span>
</span><span id="L-1034"><a href="#L-1034"><span class="linenos">1034</span></a><span class="sd">        PyTorchNetwork</span>
</span><span id="L-1035"><a href="#L-1035"><span class="linenos">1035</span></a><span class="sd">            The PyTorch representation resulting from the conversion of the original network.</span>
</span><span id="L-1036"><a href="#L-1036"><span class="linenos">1036</span></a>
</span><span id="L-1037"><a href="#L-1037"><span class="linenos">1037</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1038"><a href="#L-1038"><span class="linenos">1038</span></a>
</span><span id="L-1039"><a href="#L-1039"><span class="linenos">1039</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1040"><a href="#L-1040"><span class="linenos">1040</span></a>        <span class="n">pytorch_network</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1041"><a href="#L-1041"><span class="linenos">1041</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="L-1042"><a href="#L-1042"><span class="linenos">1042</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-1043"><a href="#L-1043"><span class="linenos">1043</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="L-1044"><a href="#L-1044"><span class="linenos">1044</span></a>
</span><span id="L-1045"><a href="#L-1045"><span class="linenos">1045</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1046"><a href="#L-1046"><span class="linenos">1046</span></a>
</span><span id="L-1047"><a href="#L-1047"><span class="linenos">1047</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-1048"><a href="#L-1048"><span class="linenos">1048</span></a>
</span><span id="L-1049"><a href="#L-1049"><span class="linenos">1049</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="L-1050"><a href="#L-1050"><span class="linenos">1050</span></a>
</span><span id="L-1051"><a href="#L-1051"><span class="linenos">1051</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="L-1052"><a href="#L-1052"><span class="linenos">1052</span></a>
</span><span id="L-1053"><a href="#L-1053"><span class="linenos">1053</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">):</span>
</span><span id="L-1054"><a href="#L-1054"><span class="linenos">1054</span></a>                            <span class="n">onnx_cv</span> <span class="o">=</span> <span class="n">ONNXConverter</span><span class="p">()</span>
</span><span id="L-1055"><a href="#L-1055"><span class="linenos">1055</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">onnx_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="L-1056"><a href="#L-1056"><span class="linenos">1056</span></a>
</span><span id="L-1057"><a href="#L-1057"><span class="linenos">1057</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1058"><a href="#L-1058"><span class="linenos">1058</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-1059"><a href="#L-1059"><span class="linenos">1059</span></a>                        <span class="k">break</span>
</span><span id="L-1060"><a href="#L-1060"><span class="linenos">1060</span></a>
</span><span id="L-1061"><a href="#L-1061"><span class="linenos">1061</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="L-1062"><a href="#L-1062"><span class="linenos">1062</span></a>                <span class="n">pytorch_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-1063"><a href="#L-1063"><span class="linenos">1063</span></a>                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
</span><span id="L-1064"><a href="#L-1064"><span class="linenos">1064</span></a>
</span><span id="L-1065"><a href="#L-1065"><span class="linenos">1065</span></a>                    <span class="n">new_layer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1066"><a href="#L-1066"><span class="linenos">1066</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="L-1067"><a href="#L-1067"><span class="linenos">1067</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="L-1068"><a href="#L-1068"><span class="linenos">1068</span></a>
</span><span id="L-1069"><a href="#L-1069"><span class="linenos">1069</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="L-1070"><a href="#L-1070"><span class="linenos">1070</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="L-1071"><a href="#L-1071"><span class="linenos">1071</span></a>
</span><span id="L-1072"><a href="#L-1072"><span class="linenos">1072</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="L-1073"><a href="#L-1073"><span class="linenos">1073</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="L-1074"><a href="#L-1074"><span class="linenos">1074</span></a>
</span><span id="L-1075"><a href="#L-1075"><span class="linenos">1075</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="L-1076"><a href="#L-1076"><span class="linenos">1076</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="L-1077"><a href="#L-1077"><span class="linenos">1077</span></a>
</span><span id="L-1078"><a href="#L-1078"><span class="linenos">1078</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="L-1079"><a href="#L-1079"><span class="linenos">1079</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="L-1080"><a href="#L-1080"><span class="linenos">1080</span></a>
</span><span id="L-1081"><a href="#L-1081"><span class="linenos">1081</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="L-1082"><a href="#L-1082"><span class="linenos">1082</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="L-1083"><a href="#L-1083"><span class="linenos">1083</span></a>
</span><span id="L-1084"><a href="#L-1084"><span class="linenos">1084</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="L-1085"><a href="#L-1085"><span class="linenos">1085</span></a>
</span><span id="L-1086"><a href="#L-1086"><span class="linenos">1086</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1087"><a href="#L-1087"><span class="linenos">1087</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1088"><a href="#L-1088"><span class="linenos">1088</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1089"><a href="#L-1089"><span class="linenos">1089</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1090"><a href="#L-1090"><span class="linenos">1090</span></a>
</span><span id="L-1091"><a href="#L-1091"><span class="linenos">1091</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1092"><a href="#L-1092"><span class="linenos">1092</span></a>                                                 <span class="n">in_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span>
</span><span id="L-1093"><a href="#L-1093"><span class="linenos">1093</span></a>                                                 <span class="n">bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="L-1094"><a href="#L-1094"><span class="linenos">1094</span></a>
</span><span id="L-1095"><a href="#L-1095"><span class="linenos">1095</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-1096"><a href="#L-1096"><span class="linenos">1096</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight</span>
</span><span id="L-1097"><a href="#L-1097"><span class="linenos">1097</span></a>
</span><span id="L-1098"><a href="#L-1098"><span class="linenos">1098</span></a>                        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
</span><span id="L-1099"><a href="#L-1099"><span class="linenos">1099</span></a>                            <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="L-1100"><a href="#L-1100"><span class="linenos">1100</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">bias</span>
</span><span id="L-1101"><a href="#L-1101"><span class="linenos">1101</span></a>
</span><span id="L-1102"><a href="#L-1102"><span class="linenos">1102</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="L-1103"><a href="#L-1103"><span class="linenos">1103</span></a>
</span><span id="L-1104"><a href="#L-1104"><span class="linenos">1104</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-1105"><a href="#L-1105"><span class="linenos">1105</span></a>
</span><span id="L-1106"><a href="#L-1106"><span class="linenos">1106</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1107"><a href="#L-1107"><span class="linenos">1107</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="L-1108"><a href="#L-1108"><span class="linenos">1108</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="L-1109"><a href="#L-1109"><span class="linenos">1109</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="L-1110"><a href="#L-1110"><span class="linenos">1110</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="L-1111"><a href="#L-1111"><span class="linenos">1111</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="L-1112"><a href="#L-1112"><span class="linenos">1112</span></a>
</span><span id="L-1113"><a href="#L-1113"><span class="linenos">1113</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1114"><a href="#L-1114"><span class="linenos">1114</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="L-1115"><a href="#L-1115"><span class="linenos">1115</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="L-1116"><a href="#L-1116"><span class="linenos">1116</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="L-1117"><a href="#L-1117"><span class="linenos">1117</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="L-1118"><a href="#L-1118"><span class="linenos">1118</span></a>
</span><span id="L-1119"><a href="#L-1119"><span class="linenos">1119</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="L-1120"><a href="#L-1120"><span class="linenos">1120</span></a>
</span><span id="L-1121"><a href="#L-1121"><span class="linenos">1121</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1122"><a href="#L-1122"><span class="linenos">1122</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="L-1123"><a href="#L-1123"><span class="linenos">1123</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="L-1124"><a href="#L-1124"><span class="linenos">1124</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="L-1125"><a href="#L-1125"><span class="linenos">1125</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="L-1126"><a href="#L-1126"><span class="linenos">1126</span></a>
</span><span id="L-1127"><a href="#L-1127"><span class="linenos">1127</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1128"><a href="#L-1128"><span class="linenos">1128</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support batchnorm layer for input with more than&quot;</span>
</span><span id="L-1129"><a href="#L-1129"><span class="linenos">1129</span></a>                                            <span class="s2">&quot;4 or less than 1 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="L-1130"><a href="#L-1130"><span class="linenos">1130</span></a>
</span><span id="L-1131"><a href="#L-1131"><span class="linenos">1131</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-1132"><a href="#L-1132"><span class="linenos">1132</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="L-1133"><a href="#L-1133"><span class="linenos">1133</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span>
</span><span id="L-1134"><a href="#L-1134"><span class="linenos">1134</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_var</span><span class="p">)</span>
</span><span id="L-1135"><a href="#L-1135"><span class="linenos">1135</span></a>
</span><span id="L-1136"><a href="#L-1136"><span class="linenos">1136</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="L-1137"><a href="#L-1137"><span class="linenos">1137</span></a>
</span><span id="L-1138"><a href="#L-1138"><span class="linenos">1138</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="L-1139"><a href="#L-1139"><span class="linenos">1139</span></a>                        <span class="c1"># symmetric. Padding mode is not supported in our representation therefore we let it be</span>
</span><span id="L-1140"><a href="#L-1140"><span class="linenos">1140</span></a>                        <span class="c1"># set to the default value.</span>
</span><span id="L-1141"><a href="#L-1141"><span class="linenos">1141</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="L-1142"><a href="#L-1142"><span class="linenos">1142</span></a>
</span><span id="L-1143"><a href="#L-1143"><span class="linenos">1143</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-1144"><a href="#L-1144"><span class="linenos">1144</span></a>
</span><span id="L-1145"><a href="#L-1145"><span class="linenos">1145</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1146"><a href="#L-1146"><span class="linenos">1146</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="L-1147"><a href="#L-1147"><span class="linenos">1147</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="L-1148"><a href="#L-1148"><span class="linenos">1148</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="L-1149"><a href="#L-1149"><span class="linenos">1149</span></a>
</span><span id="L-1150"><a href="#L-1150"><span class="linenos">1150</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="L-1151"><a href="#L-1151"><span class="linenos">1151</span></a>
</span><span id="L-1152"><a href="#L-1152"><span class="linenos">1152</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1153"><a href="#L-1153"><span class="linenos">1153</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="L-1154"><a href="#L-1154"><span class="linenos">1154</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="L-1155"><a href="#L-1155"><span class="linenos">1155</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="L-1156"><a href="#L-1156"><span class="linenos">1156</span></a>
</span><span id="L-1157"><a href="#L-1157"><span class="linenos">1157</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="L-1158"><a href="#L-1158"><span class="linenos">1158</span></a>
</span><span id="L-1159"><a href="#L-1159"><span class="linenos">1159</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1160"><a href="#L-1160"><span class="linenos">1160</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="L-1161"><a href="#L-1161"><span class="linenos">1161</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="L-1162"><a href="#L-1162"><span class="linenos">1162</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="L-1163"><a href="#L-1163"><span class="linenos">1163</span></a>
</span><span id="L-1164"><a href="#L-1164"><span class="linenos">1164</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1165"><a href="#L-1165"><span class="linenos">1165</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="L-1166"><a href="#L-1166"><span class="linenos">1166</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="L-1167"><a href="#L-1167"><span class="linenos">1167</span></a>
</span><span id="L-1168"><a href="#L-1168"><span class="linenos">1168</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="L-1169"><a href="#L-1169"><span class="linenos">1169</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="L-1170"><a href="#L-1170"><span class="linenos">1170</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="L-1171"><a href="#L-1171"><span class="linenos">1171</span></a>
</span><span id="L-1172"><a href="#L-1172"><span class="linenos">1172</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="L-1173"><a href="#L-1173"><span class="linenos">1173</span></a>
</span><span id="L-1174"><a href="#L-1174"><span class="linenos">1174</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="L-1175"><a href="#L-1175"><span class="linenos">1175</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="L-1176"><a href="#L-1176"><span class="linenos">1176</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="L-1177"><a href="#L-1177"><span class="linenos">1177</span></a>
</span><span id="L-1178"><a href="#L-1178"><span class="linenos">1178</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-1179"><a href="#L-1179"><span class="linenos">1179</span></a>
</span><span id="L-1180"><a href="#L-1180"><span class="linenos">1180</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1181"><a href="#L-1181"><span class="linenos">1181</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1182"><a href="#L-1182"><span class="linenos">1182</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="L-1183"><a href="#L-1183"><span class="linenos">1183</span></a>
</span><span id="L-1184"><a href="#L-1184"><span class="linenos">1184</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="L-1185"><a href="#L-1185"><span class="linenos">1185</span></a>
</span><span id="L-1186"><a href="#L-1186"><span class="linenos">1186</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1187"><a href="#L-1187"><span class="linenos">1187</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1188"><a href="#L-1188"><span class="linenos">1188</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="L-1189"><a href="#L-1189"><span class="linenos">1189</span></a>
</span><span id="L-1190"><a href="#L-1190"><span class="linenos">1190</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="L-1191"><a href="#L-1191"><span class="linenos">1191</span></a>
</span><span id="L-1192"><a href="#L-1192"><span class="linenos">1192</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1193"><a href="#L-1193"><span class="linenos">1193</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1194"><a href="#L-1194"><span class="linenos">1194</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="L-1195"><a href="#L-1195"><span class="linenos">1195</span></a>
</span><span id="L-1196"><a href="#L-1196"><span class="linenos">1196</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1197"><a href="#L-1197"><span class="linenos">1197</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support AvgPool layer for input with more than&quot;</span>
</span><span id="L-1198"><a href="#L-1198"><span class="linenos">1198</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="L-1199"><a href="#L-1199"><span class="linenos">1199</span></a>
</span><span id="L-1200"><a href="#L-1200"><span class="linenos">1200</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="L-1201"><a href="#L-1201"><span class="linenos">1201</span></a>
</span><span id="L-1202"><a href="#L-1202"><span class="linenos">1202</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="L-1203"><a href="#L-1203"><span class="linenos">1203</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="L-1204"><a href="#L-1204"><span class="linenos">1204</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="L-1205"><a href="#L-1205"><span class="linenos">1205</span></a>
</span><span id="L-1206"><a href="#L-1206"><span class="linenos">1206</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="L-1207"><a href="#L-1207"><span class="linenos">1207</span></a>
</span><span id="L-1208"><a href="#L-1208"><span class="linenos">1208</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1209"><a href="#L-1209"><span class="linenos">1209</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1210"><a href="#L-1210"><span class="linenos">1210</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="L-1211"><a href="#L-1211"><span class="linenos">1211</span></a>
</span><span id="L-1212"><a href="#L-1212"><span class="linenos">1212</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="L-1213"><a href="#L-1213"><span class="linenos">1213</span></a>
</span><span id="L-1214"><a href="#L-1214"><span class="linenos">1214</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1215"><a href="#L-1215"><span class="linenos">1215</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1216"><a href="#L-1216"><span class="linenos">1216</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="L-1217"><a href="#L-1217"><span class="linenos">1217</span></a>
</span><span id="L-1218"><a href="#L-1218"><span class="linenos">1218</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="L-1219"><a href="#L-1219"><span class="linenos">1219</span></a>
</span><span id="L-1220"><a href="#L-1220"><span class="linenos">1220</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1221"><a href="#L-1221"><span class="linenos">1221</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1222"><a href="#L-1222"><span class="linenos">1222</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="L-1223"><a href="#L-1223"><span class="linenos">1223</span></a>
</span><span id="L-1224"><a href="#L-1224"><span class="linenos">1224</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1225"><a href="#L-1225"><span class="linenos">1225</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="L-1226"><a href="#L-1226"><span class="linenos">1226</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="L-1227"><a href="#L-1227"><span class="linenos">1227</span></a>
</span><span id="L-1228"><a href="#L-1228"><span class="linenos">1228</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="L-1229"><a href="#L-1229"><span class="linenos">1229</span></a>
</span><span id="L-1230"><a href="#L-1230"><span class="linenos">1230</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="L-1231"><a href="#L-1231"><span class="linenos">1231</span></a>                                                            <span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="L-1232"><a href="#L-1232"><span class="linenos">1232</span></a>
</span><span id="L-1233"><a href="#L-1233"><span class="linenos">1233</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="L-1234"><a href="#L-1234"><span class="linenos">1234</span></a>
</span><span id="L-1235"><a href="#L-1235"><span class="linenos">1235</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="L-1236"><a href="#L-1236"><span class="linenos">1236</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-1237"><a href="#L-1237"><span class="linenos">1237</span></a>
</span><span id="L-1238"><a href="#L-1238"><span class="linenos">1238</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="L-1239"><a href="#L-1239"><span class="linenos">1239</span></a>
</span><span id="L-1240"><a href="#L-1240"><span class="linenos">1240</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to scale</span>
</span><span id="L-1241"><a href="#L-1241"><span class="linenos">1241</span></a>                        <span class="c1"># the axes values.</span>
</span><span id="L-1242"><a href="#L-1242"><span class="linenos">1242</span></a>                        <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="L-1243"><a href="#L-1243"><span class="linenos">1243</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="L-1244"><a href="#L-1244"><span class="linenos">1244</span></a>
</span><span id="L-1245"><a href="#L-1245"><span class="linenos">1245</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="L-1246"><a href="#L-1246"><span class="linenos">1246</span></a>
</span><span id="L-1247"><a href="#L-1247"><span class="linenos">1247</span></a>                        <span class="c1"># Pytorch does not support the allow_zero attribute and the corresponding reshape with 0</span>
</span><span id="L-1248"><a href="#L-1248"><span class="linenos">1248</span></a>                        <span class="c1"># dimensions.</span>
</span><span id="L-1249"><a href="#L-1249"><span class="linenos">1249</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">allow_zero</span><span class="p">:</span>
</span><span id="L-1250"><a href="#L-1250"><span class="linenos">1250</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;allow_zero not supported by pytorch&quot;</span><span class="p">)</span>
</span><span id="L-1251"><a href="#L-1251"><span class="linenos">1251</span></a>
</span><span id="L-1252"><a href="#L-1252"><span class="linenos">1252</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to add it to</span>
</span><span id="L-1253"><a href="#L-1253"><span class="linenos">1253</span></a>                        <span class="c1"># the shape.</span>
</span><span id="L-1254"><a href="#L-1254"><span class="linenos">1254</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1255"><a href="#L-1255"><span class="linenos">1255</span></a>                        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="L-1256"><a href="#L-1256"><span class="linenos">1256</span></a>                            <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-1257"><a href="#L-1257"><span class="linenos">1257</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="L-1258"><a href="#L-1258"><span class="linenos">1258</span></a>
</span><span id="L-1259"><a href="#L-1259"><span class="linenos">1259</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="L-1260"><a href="#L-1260"><span class="linenos">1260</span></a>
</span><span id="L-1261"><a href="#L-1261"><span class="linenos">1261</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="L-1262"><a href="#L-1262"><span class="linenos">1262</span></a>
</span><span id="L-1263"><a href="#L-1263"><span class="linenos">1263</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="L-1264"><a href="#L-1264"><span class="linenos">1264</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-1265"><a href="#L-1265"><span class="linenos">1265</span></a>
</span><span id="L-1266"><a href="#L-1266"><span class="linenos">1266</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="L-1267"><a href="#L-1267"><span class="linenos">1267</span></a>
</span><span id="L-1268"><a href="#L-1268"><span class="linenos">1268</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="L-1269"><a href="#L-1269"><span class="linenos">1269</span></a>
</span><span id="L-1270"><a href="#L-1270"><span class="linenos">1270</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="L-1271"><a href="#L-1271"><span class="linenos">1271</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-1272"><a href="#L-1272"><span class="linenos">1272</span></a>
</span><span id="L-1273"><a href="#L-1273"><span class="linenos">1273</span></a>                    <span class="k">if</span> <span class="n">new_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1274"><a href="#L-1274"><span class="linenos">1274</span></a>                        <span class="n">pytorch_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_layer</span><span class="p">)</span>
</span><span id="L-1275"><a href="#L-1275"><span class="linenos">1275</span></a>
</span><span id="L-1276"><a href="#L-1276"><span class="linenos">1276</span></a>                <span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span><span class="p">,</span> <span class="n">pytorch_layers</span><span class="p">)</span>
</span><span id="L-1277"><a href="#L-1277"><span class="linenos">1277</span></a>
</span><span id="L-1278"><a href="#L-1278"><span class="linenos">1278</span></a>            <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pytorch_network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1279"><a href="#L-1279"><span class="linenos">1279</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: network to convert is not valid, the alternative representation is None&quot;</span><span class="p">)</span>
</span><span id="L-1280"><a href="#L-1280"><span class="linenos">1280</span></a>
</span><span id="L-1281"><a href="#L-1281"><span class="linenos">1281</span></a>            <span class="n">identifier</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="L-1282"><a href="#L-1282"><span class="linenos">1282</span></a>            <span class="n">alt_net</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="o">=</span><span class="n">identifier</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="o">=</span><span class="n">pytorch_network</span><span class="p">)</span>
</span><span id="L-1283"><a href="#L-1283"><span class="linenos">1283</span></a>
</span><span id="L-1284"><a href="#L-1284"><span class="linenos">1284</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span><span id="L-1285"><a href="#L-1285"><span class="linenos">1285</span></a>
</span><span id="L-1286"><a href="#L-1286"><span class="linenos">1286</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="L-1287"><a href="#L-1287"><span class="linenos">1287</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1288"><a href="#L-1288"><span class="linenos">1288</span></a><span class="sd">        Convert the PyTorch representation of interest to the internal one.</span>
</span><span id="L-1289"><a href="#L-1289"><span class="linenos">1289</span></a>
</span><span id="L-1290"><a href="#L-1290"><span class="linenos">1290</span></a><span class="sd">        Parameters</span>
</span><span id="L-1291"><a href="#L-1291"><span class="linenos">1291</span></a><span class="sd">        ----------</span>
</span><span id="L-1292"><a href="#L-1292"><span class="linenos">1292</span></a><span class="sd">        alt_rep : PyTorchNetwork</span>
</span><span id="L-1293"><a href="#L-1293"><span class="linenos">1293</span></a><span class="sd">            The PyTorch Representation to convert.</span>
</span><span id="L-1294"><a href="#L-1294"><span class="linenos">1294</span></a>
</span><span id="L-1295"><a href="#L-1295"><span class="linenos">1295</span></a><span class="sd">        Returns</span>
</span><span id="L-1296"><a href="#L-1296"><span class="linenos">1296</span></a><span class="sd">        ----------</span>
</span><span id="L-1297"><a href="#L-1297"><span class="linenos">1297</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="L-1298"><a href="#L-1298"><span class="linenos">1298</span></a><span class="sd">            The Neural Network resulting from the conversion of PyTorch Representation.</span>
</span><span id="L-1299"><a href="#L-1299"><span class="linenos">1299</span></a>
</span><span id="L-1300"><a href="#L-1300"><span class="linenos">1300</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-1301"><a href="#L-1301"><span class="linenos">1301</span></a>
</span><span id="L-1302"><a href="#L-1302"><span class="linenos">1302</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="L-1303"><a href="#L-1303"><span class="linenos">1303</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="s1">&#39;input_id&#39;</span><span class="p">):</span>
</span><span id="L-1304"><a href="#L-1304"><span class="linenos">1304</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="L-1305"><a href="#L-1305"><span class="linenos">1305</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-1306"><a href="#L-1306"><span class="linenos">1306</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span>
</span><span id="L-1307"><a href="#L-1307"><span class="linenos">1307</span></a>
</span><span id="L-1308"><a href="#L-1308"><span class="linenos">1308</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">input_id</span><span class="p">)</span>
</span><span id="L-1309"><a href="#L-1309"><span class="linenos">1309</span></a>
</span><span id="L-1310"><a href="#L-1310"><span class="linenos">1310</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-1311"><a href="#L-1311"><span class="linenos">1311</span></a>        <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="L-1312"><a href="#L-1312"><span class="linenos">1312</span></a>
</span><span id="L-1313"><a href="#L-1313"><span class="linenos">1313</span></a>        <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1314"><a href="#L-1314"><span class="linenos">1314</span></a>
</span><span id="L-1315"><a href="#L-1315"><span class="linenos">1315</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span><span id="L-1316"><a href="#L-1316"><span class="linenos">1316</span></a>
</span><span id="L-1317"><a href="#L-1317"><span class="linenos">1317</span></a>            <span class="c1"># Control input</span>
</span><span id="L-1318"><a href="#L-1318"><span class="linenos">1318</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;in_dim&#39;</span><span class="p">):</span>
</span><span id="L-1319"><a href="#L-1319"><span class="linenos">1319</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span>
</span><span id="L-1320"><a href="#L-1320"><span class="linenos">1320</span></a>
</span><span id="L-1321"><a href="#L-1321"><span class="linenos">1321</span></a>            <span class="k">if</span> <span class="n">layer_in_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="L-1322"><a href="#L-1322"><span class="linenos">1322</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Please provide input dimension for the network:&#39;</span><span class="p">)</span>
</span><span id="L-1323"><a href="#L-1323"><span class="linenos">1323</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="nb">input</span><span class="p">()</span>
</span><span id="L-1324"><a href="#L-1324"><span class="linenos">1324</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_in_dim</span><span class="p">,)</span>
</span><span id="L-1325"><a href="#L-1325"><span class="linenos">1325</span></a>
</span><span id="L-1326"><a href="#L-1326"><span class="linenos">1326</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;identifier&#39;</span><span class="p">):</span>
</span><span id="L-1327"><a href="#L-1327"><span class="linenos">1327</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="L-1328"><a href="#L-1328"><span class="linenos">1328</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1329"><a href="#L-1329"><span class="linenos">1329</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Layer</span><span class="si">{</span><span class="n">node_index</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="L-1330"><a href="#L-1330"><span class="linenos">1330</span></a>
</span><span id="L-1331"><a href="#L-1331"><span class="linenos">1331</span></a>            <span class="c1"># Read node</span>
</span><span id="L-1332"><a href="#L-1332"><span class="linenos">1332</span></a>            <span class="n">new_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1333"><a href="#L-1333"><span class="linenos">1333</span></a>
</span><span id="L-1334"><a href="#L-1334"><span class="linenos">1334</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
</span><span id="L-1335"><a href="#L-1335"><span class="linenos">1335</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="L-1336"><a href="#L-1336"><span class="linenos">1336</span></a>
</span><span id="L-1337"><a href="#L-1337"><span class="linenos">1337</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">):</span>
</span><span id="L-1338"><a href="#L-1338"><span class="linenos">1338</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="L-1339"><a href="#L-1339"><span class="linenos">1339</span></a>
</span><span id="L-1340"><a href="#L-1340"><span class="linenos">1340</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">):</span>
</span><span id="L-1341"><a href="#L-1341"><span class="linenos">1341</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="L-1342"><a href="#L-1342"><span class="linenos">1342</span></a>
</span><span id="L-1343"><a href="#L-1343"><span class="linenos">1343</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">):</span>
</span><span id="L-1344"><a href="#L-1344"><span class="linenos">1344</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="L-1345"><a href="#L-1345"><span class="linenos">1345</span></a>
</span><span id="L-1346"><a href="#L-1346"><span class="linenos">1346</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">):</span>
</span><span id="L-1347"><a href="#L-1347"><span class="linenos">1347</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="L-1348"><a href="#L-1348"><span class="linenos">1348</span></a>
</span><span id="L-1349"><a href="#L-1349"><span class="linenos">1349</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">):</span>
</span><span id="L-1350"><a href="#L-1350"><span class="linenos">1350</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
</span><span id="L-1351"><a href="#L-1351"><span class="linenos">1351</span></a>
</span><span id="L-1352"><a href="#L-1352"><span class="linenos">1352</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
</span><span id="L-1353"><a href="#L-1353"><span class="linenos">1353</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_features</span>
</span><span id="L-1354"><a href="#L-1354"><span class="linenos">1354</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1355"><a href="#L-1355"><span class="linenos">1355</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1356"><a href="#L-1356"><span class="linenos">1356</span></a>                <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1357"><a href="#L-1357"><span class="linenos">1357</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1358"><a href="#L-1358"><span class="linenos">1358</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1359"><a href="#L-1359"><span class="linenos">1359</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1360"><a href="#L-1360"><span class="linenos">1360</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">)</span>
</span><span id="L-1361"><a href="#L-1361"><span class="linenos">1361</span></a>
</span><span id="L-1362"><a href="#L-1362"><span class="linenos">1362</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="L-1363"><a href="#L-1363"><span class="linenos">1363</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">):</span>
</span><span id="L-1364"><a href="#L-1364"><span class="linenos">1364</span></a>
</span><span id="L-1365"><a href="#L-1365"><span class="linenos">1365</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">eps</span>
</span><span id="L-1366"><a href="#L-1366"><span class="linenos">1366</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">momentum</span>
</span><span id="L-1367"><a href="#L-1367"><span class="linenos">1367</span></a>                <span class="n">track_running_stats</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">track_running_stats</span>
</span><span id="L-1368"><a href="#L-1368"><span class="linenos">1368</span></a>                <span class="n">affine</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">affine</span>
</span><span id="L-1369"><a href="#L-1369"><span class="linenos">1369</span></a>
</span><span id="L-1370"><a href="#L-1370"><span class="linenos">1370</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1371"><a href="#L-1371"><span class="linenos">1371</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1372"><a href="#L-1372"><span class="linenos">1372</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1373"><a href="#L-1373"><span class="linenos">1373</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1374"><a href="#L-1374"><span class="linenos">1374</span></a>
</span><span id="L-1375"><a href="#L-1375"><span class="linenos">1375</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="L-1376"><a href="#L-1376"><span class="linenos">1376</span></a>                                               <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">affine</span><span class="p">,</span>
</span><span id="L-1377"><a href="#L-1377"><span class="linenos">1377</span></a>                                               <span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="L-1378"><a href="#L-1378"><span class="linenos">1378</span></a>
</span><span id="L-1379"><a href="#L-1379"><span class="linenos">1379</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
</span><span id="L-1380"><a href="#L-1380"><span class="linenos">1380</span></a>
</span><span id="L-1381"><a href="#L-1381"><span class="linenos">1381</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_channels</span>
</span><span id="L-1382"><a href="#L-1382"><span class="linenos">1382</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="L-1383"><a href="#L-1383"><span class="linenos">1383</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="L-1384"><a href="#L-1384"><span class="linenos">1384</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-1385"><a href="#L-1385"><span class="linenos">1385</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="L-1386"><a href="#L-1386"><span class="linenos">1386</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-1387"><a href="#L-1387"><span class="linenos">1387</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="L-1388"><a href="#L-1388"><span class="linenos">1388</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="L-1389"><a href="#L-1389"><span class="linenos">1389</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">groups</span>
</span><span id="L-1390"><a href="#L-1390"><span class="linenos">1390</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1391"><a href="#L-1391"><span class="linenos">1391</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1392"><a href="#L-1392"><span class="linenos">1392</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-1393"><a href="#L-1393"><span class="linenos">1393</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-1394"><a href="#L-1394"><span class="linenos">1394</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-1395"><a href="#L-1395"><span class="linenos">1395</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-1396"><a href="#L-1396"><span class="linenos">1396</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="L-1397"><a href="#L-1397"><span class="linenos">1397</span></a>
</span><span id="L-1398"><a href="#L-1398"><span class="linenos">1398</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
</span><span id="L-1399"><a href="#L-1399"><span class="linenos">1399</span></a>                                          <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
</span><span id="L-1400"><a href="#L-1400"><span class="linenos">1400</span></a>
</span><span id="L-1401"><a href="#L-1401"><span class="linenos">1401</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="L-1402"><a href="#L-1402"><span class="linenos">1402</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">):</span>
</span><span id="L-1403"><a href="#L-1403"><span class="linenos">1403</span></a>
</span><span id="L-1404"><a href="#L-1404"><span class="linenos">1404</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="L-1405"><a href="#L-1405"><span class="linenos">1405</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-1406"><a href="#L-1406"><span class="linenos">1406</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="L-1407"><a href="#L-1407"><span class="linenos">1407</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-1408"><a href="#L-1408"><span class="linenos">1408</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="L-1409"><a href="#L-1409"><span class="linenos">1409</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="L-1410"><a href="#L-1410"><span class="linenos">1410</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="L-1411"><a href="#L-1411"><span class="linenos">1411</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">count_include_pad</span>
</span><span id="L-1412"><a href="#L-1412"><span class="linenos">1412</span></a>
</span><span id="L-1413"><a href="#L-1413"><span class="linenos">1413</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="L-1414"><a href="#L-1414"><span class="linenos">1414</span></a>                                                 <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="L-1415"><a href="#L-1415"><span class="linenos">1415</span></a>
</span><span id="L-1416"><a href="#L-1416"><span class="linenos">1416</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="L-1417"><a href="#L-1417"><span class="linenos">1417</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">):</span>
</span><span id="L-1418"><a href="#L-1418"><span class="linenos">1418</span></a>
</span><span id="L-1419"><a href="#L-1419"><span class="linenos">1419</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="L-1420"><a href="#L-1420"><span class="linenos">1420</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="L-1421"><a href="#L-1421"><span class="linenos">1421</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="L-1422"><a href="#L-1422"><span class="linenos">1422</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="L-1423"><a href="#L-1423"><span class="linenos">1423</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="L-1424"><a href="#L-1424"><span class="linenos">1424</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="L-1425"><a href="#L-1425"><span class="linenos">1425</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="L-1426"><a href="#L-1426"><span class="linenos">1426</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="L-1427"><a href="#L-1427"><span class="linenos">1427</span></a>                <span class="n">return_indices</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">return_indices</span>
</span><span id="L-1428"><a href="#L-1428"><span class="linenos">1428</span></a>
</span><span id="L-1429"><a href="#L-1429"><span class="linenos">1429</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span>
</span><span id="L-1430"><a href="#L-1430"><span class="linenos">1430</span></a>                                             <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">return_indices</span><span class="p">)</span>
</span><span id="L-1431"><a href="#L-1431"><span class="linenos">1431</span></a>
</span><span id="L-1432"><a href="#L-1432"><span class="linenos">1432</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">):</span>
</span><span id="L-1433"><a href="#L-1433"><span class="linenos">1433</span></a>
</span><span id="L-1434"><a href="#L-1434"><span class="linenos">1434</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="L-1435"><a href="#L-1435"><span class="linenos">1435</span></a>
</span><span id="L-1436"><a href="#L-1436"><span class="linenos">1436</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">):</span>
</span><span id="L-1437"><a href="#L-1437"><span class="linenos">1437</span></a>
</span><span id="L-1438"><a href="#L-1438"><span class="linenos">1438</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-1439"><a href="#L-1439"><span class="linenos">1439</span></a>
</span><span id="L-1440"><a href="#L-1440"><span class="linenos">1440</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">):</span>
</span><span id="L-1441"><a href="#L-1441"><span class="linenos">1441</span></a>
</span><span id="L-1442"><a href="#L-1442"><span class="linenos">1442</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="L-1443"><a href="#L-1443"><span class="linenos">1443</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="L-1444"><a href="#L-1444"><span class="linenos">1444</span></a>
</span><span id="L-1445"><a href="#L-1445"><span class="linenos">1445</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">):</span>
</span><span id="L-1446"><a href="#L-1446"><span class="linenos">1446</span></a>
</span><span id="L-1447"><a href="#L-1447"><span class="linenos">1447</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-1448"><a href="#L-1448"><span class="linenos">1448</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="L-1449"><a href="#L-1449"><span class="linenos">1449</span></a>
</span><span id="L-1450"><a href="#L-1450"><span class="linenos">1450</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">):</span>
</span><span id="L-1451"><a href="#L-1451"><span class="linenos">1451</span></a>
</span><span id="L-1452"><a href="#L-1452"><span class="linenos">1452</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="L-1453"><a href="#L-1453"><span class="linenos">1453</span></a>
</span><span id="L-1454"><a href="#L-1454"><span class="linenos">1454</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">):</span>
</span><span id="L-1455"><a href="#L-1455"><span class="linenos">1455</span></a>
</span><span id="L-1456"><a href="#L-1456"><span class="linenos">1456</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="L-1457"><a href="#L-1457"><span class="linenos">1457</span></a>
</span><span id="L-1458"><a href="#L-1458"><span class="linenos">1458</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="L-1459"><a href="#L-1459"><span class="linenos">1459</span></a>                <span class="k">pass</span>
</span><span id="L-1460"><a href="#L-1460"><span class="linenos">1460</span></a>
</span><span id="L-1461"><a href="#L-1461"><span class="linenos">1461</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-1462"><a href="#L-1462"><span class="linenos">1462</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="L-1463"><a href="#L-1463"><span class="linenos">1463</span></a>
</span><span id="L-1464"><a href="#L-1464"><span class="linenos">1464</span></a>            <span class="k">if</span> <span class="n">new_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1465"><a href="#L-1465"><span class="linenos">1465</span></a>                <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="L-1466"><a href="#L-1466"><span class="linenos">1466</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
</span><span id="L-1467"><a href="#L-1467"><span class="linenos">1467</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="L-1468"><a href="#L-1468"><span class="linenos">1468</span></a>
</span><span id="L-1469"><a href="#L-1469"><span class="linenos">1469</span></a>        <span class="k">return</span> <span class="n">network</span>
</span><span id="L-1470"><a href="#L-1470"><span class="linenos">1470</span></a>
</span><span id="L-1471"><a href="#L-1471"><span class="linenos">1471</span></a>
</span><span id="L-1472"><a href="#L-1472"><span class="linenos">1472</span></a><span class="k">def</span> <span class="nf">load_network_path</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AlternativeRepresentation</span><span class="p">]:</span>
</span><span id="L-1473"><a href="#L-1473"><span class="linenos">1473</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1474"><a href="#L-1474"><span class="linenos">1474</span></a><span class="sd">    Method to load a network from a path in an Alternative Representation.</span>
</span><span id="L-1475"><a href="#L-1475"><span class="linenos">1475</span></a>
</span><span id="L-1476"><a href="#L-1476"><span class="linenos">1476</span></a><span class="sd">    Parameters</span>
</span><span id="L-1477"><a href="#L-1477"><span class="linenos">1477</span></a><span class="sd">    ----------</span>
</span><span id="L-1478"><a href="#L-1478"><span class="linenos">1478</span></a><span class="sd">    path : str</span>
</span><span id="L-1479"><a href="#L-1479"><span class="linenos">1479</span></a><span class="sd">        Path to the network.</span>
</span><span id="L-1480"><a href="#L-1480"><span class="linenos">1480</span></a>
</span><span id="L-1481"><a href="#L-1481"><span class="linenos">1481</span></a><span class="sd">    Returns</span>
</span><span id="L-1482"><a href="#L-1482"><span class="linenos">1482</span></a><span class="sd">    -------</span>
</span><span id="L-1483"><a href="#L-1483"><span class="linenos">1483</span></a><span class="sd">    Optional[AlternativeRepresentation]</span>
</span><span id="L-1484"><a href="#L-1484"><span class="linenos">1484</span></a><span class="sd">        The AlternativeRepresentation object if the network is supported, None otherwise.</span>
</span><span id="L-1485"><a href="#L-1485"><span class="linenos">1485</span></a>
</span><span id="L-1486"><a href="#L-1486"><span class="linenos">1486</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1487"><a href="#L-1487"><span class="linenos">1487</span></a>
</span><span id="L-1488"><a href="#L-1488"><span class="linenos">1488</span></a>    <span class="n">extension</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-1489"><a href="#L-1489"><span class="linenos">1489</span></a>    <span class="n">net_id</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;.</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
</span><span id="L-1490"><a href="#L-1490"><span class="linenos">1490</span></a>
</span><span id="L-1491"><a href="#L-1491"><span class="linenos">1491</span></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="s1">&#39;pth&#39;</span><span class="p">]:</span>
</span><span id="L-1492"><a href="#L-1492"><span class="linenos">1492</span></a>        <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span><span id="L-1493"><a href="#L-1493"><span class="linenos">1493</span></a>        <span class="k">return</span> <span class="n">PyTorchNetwork</span><span class="p">(</span><span class="n">net_id</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-1494"><a href="#L-1494"><span class="linenos">1494</span></a>    <span class="k">elif</span> <span class="n">extension</span> <span class="o">==</span> <span class="s1">&#39;onnx&#39;</span><span class="p">:</span>
</span><span id="L-1495"><a href="#L-1495"><span class="linenos">1495</span></a>        <span class="n">model_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span><span id="L-1496"><a href="#L-1496"><span class="linenos">1496</span></a>        <span class="k">return</span> <span class="n">ONNXNetwork</span><span class="p">(</span><span class="n">net_id</span><span class="p">,</span> <span class="n">model_proto</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="L-1497"><a href="#L-1497"><span class="linenos">1497</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="L-1498"><a href="#L-1498"><span class="linenos">1498</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span><span id="L-1499"><a href="#L-1499"><span class="linenos">1499</span></a>
</span><span id="L-1500"><a href="#L-1500"><span class="linenos">1500</span></a>
</span><span id="L-1501"><a href="#L-1501"><span class="linenos">1501</span></a><span class="k">def</span> <span class="nf">save_network_path</span><span class="p">(</span><span class="n">network</span><span class="p">:</span> <span class="n">AlternativeRepresentation</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-1502"><a href="#L-1502"><span class="linenos">1502</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-1503"><a href="#L-1503"><span class="linenos">1503</span></a><span class="sd">    Method to save a network to file from an AlternativeRepresentation</span>
</span><span id="L-1504"><a href="#L-1504"><span class="linenos">1504</span></a>
</span><span id="L-1505"><a href="#L-1505"><span class="linenos">1505</span></a><span class="sd">    Parameters</span>
</span><span id="L-1506"><a href="#L-1506"><span class="linenos">1506</span></a><span class="sd">    ----------</span>
</span><span id="L-1507"><a href="#L-1507"><span class="linenos">1507</span></a><span class="sd">    network : AlternativeRepresentation</span>
</span><span id="L-1508"><a href="#L-1508"><span class="linenos">1508</span></a><span class="sd">        The network to save.</span>
</span><span id="L-1509"><a href="#L-1509"><span class="linenos">1509</span></a><span class="sd">    path : str</span>
</span><span id="L-1510"><a href="#L-1510"><span class="linenos">1510</span></a><span class="sd">        Path to save the network.</span>
</span><span id="L-1511"><a href="#L-1511"><span class="linenos">1511</span></a>
</span><span id="L-1512"><a href="#L-1512"><span class="linenos">1512</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-1513"><a href="#L-1513"><span class="linenos">1513</span></a>
</span><span id="L-1514"><a href="#L-1514"><span class="linenos">1514</span></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">):</span>
</span><span id="L-1515"><a href="#L-1515"><span class="linenos">1515</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</span><span id="L-1516"><a href="#L-1516"><span class="linenos">1516</span></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">):</span>
</span><span id="L-1517"><a href="#L-1517"><span class="linenos">1517</span></a>        <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">onnx_network</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="AlternativeRepresentation">
                            <input id="AlternativeRepresentation-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AlternativeRepresentation</span><wbr>(<span class="base">abc.ABC</span>):

                <label class="view-source-button" for="AlternativeRepresentation-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AlternativeRepresentation"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AlternativeRepresentation-16"><a href="#AlternativeRepresentation-16"><span class="linenos">16</span></a><span class="k">class</span> <span class="nc">AlternativeRepresentation</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</span><span id="AlternativeRepresentation-17"><a href="#AlternativeRepresentation-17"><span class="linenos">17</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="AlternativeRepresentation-18"><a href="#AlternativeRepresentation-18"><span class="linenos">18</span></a><span class="sd">    An abstract class used to represent an alternative representation for a neural network.</span>
</span><span id="AlternativeRepresentation-19"><a href="#AlternativeRepresentation-19"><span class="linenos">19</span></a>
</span><span id="AlternativeRepresentation-20"><a href="#AlternativeRepresentation-20"><span class="linenos">20</span></a><span class="sd">    Attributes</span>
</span><span id="AlternativeRepresentation-21"><a href="#AlternativeRepresentation-21"><span class="linenos">21</span></a><span class="sd">    ----------</span>
</span><span id="AlternativeRepresentation-22"><a href="#AlternativeRepresentation-22"><span class="linenos">22</span></a><span class="sd">    identifier : str</span>
</span><span id="AlternativeRepresentation-23"><a href="#AlternativeRepresentation-23"><span class="linenos">23</span></a><span class="sd">        identifier for the alternative representation</span>
</span><span id="AlternativeRepresentation-24"><a href="#AlternativeRepresentation-24"><span class="linenos">24</span></a><span class="sd">    up_to_date : bool, optional</span>
</span><span id="AlternativeRepresentation-25"><a href="#AlternativeRepresentation-25"><span class="linenos">25</span></a><span class="sd">        flag which indicates if the alternative representation is up-to-date with respect</span>
</span><span id="AlternativeRepresentation-26"><a href="#AlternativeRepresentation-26"><span class="linenos">26</span></a><span class="sd">        to the internal representation of the network (optional: True).</span>
</span><span id="AlternativeRepresentation-27"><a href="#AlternativeRepresentation-27"><span class="linenos">27</span></a>
</span><span id="AlternativeRepresentation-28"><a href="#AlternativeRepresentation-28"><span class="linenos">28</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="AlternativeRepresentation-29"><a href="#AlternativeRepresentation-29"><span class="linenos">29</span></a>
</span><span id="AlternativeRepresentation-30"><a href="#AlternativeRepresentation-30"><span class="linenos">30</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="AlternativeRepresentation-31"><a href="#AlternativeRepresentation-31"><span class="linenos">31</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span>
</span><span id="AlternativeRepresentation-32"><a href="#AlternativeRepresentation-32"><span class="linenos">32</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_to_date</span> <span class="o">=</span> <span class="n">up_to_date</span>
</span></pre></div>


            <div class="docstring"><p>An abstract class used to represent an alternative representation for a neural network.</p>

<h2 id="attributes">Attributes</h2>

<p>identifier : str
    identifier for the alternative representation
up_to_date : bool, optional
    flag which indicates if the alternative representation is up-to-date with respect
    to the internal representation of the network (optional: True).</p>
</div>


                            <div id="AlternativeRepresentation.__init__" class="classattr">
                                        <input id="AlternativeRepresentation.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">AlternativeRepresentation</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="AlternativeRepresentation.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AlternativeRepresentation.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AlternativeRepresentation.__init__-30"><a href="#AlternativeRepresentation.__init__-30"><span class="linenos">30</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="AlternativeRepresentation.__init__-31"><a href="#AlternativeRepresentation.__init__-31"><span class="linenos">31</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">identifier</span> <span class="o">=</span> <span class="n">identifier</span>
</span><span id="AlternativeRepresentation.__init__-32"><a href="#AlternativeRepresentation.__init__-32"><span class="linenos">32</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">up_to_date</span> <span class="o">=</span> <span class="n">up_to_date</span>
</span></pre></div>


    

                            </div>
                            <div id="AlternativeRepresentation.identifier" class="classattr">
                                <div class="attr variable">
            <span class="name">identifier</span>

        
    </div>
    <a class="headerlink" href="#AlternativeRepresentation.identifier"></a>
    
    

                            </div>
                            <div id="AlternativeRepresentation.up_to_date" class="classattr">
                                <div class="attr variable">
            <span class="name">up_to_date</span>

        
    </div>
    <a class="headerlink" href="#AlternativeRepresentation.up_to_date"></a>
    
    

                            </div>
                </section>
                <section id="ONNXNetwork">
                            <input id="ONNXNetwork-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ONNXNetwork</span><wbr>(<span class="base"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span>):

                <label class="view-source-button" for="ONNXNetwork-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXNetwork"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXNetwork-35"><a href="#ONNXNetwork-35"><span class="linenos">35</span></a><span class="k">class</span> <span class="nc">ONNXNetwork</span><span class="p">(</span><span class="n">AlternativeRepresentation</span><span class="p">):</span>
</span><span id="ONNXNetwork-36"><a href="#ONNXNetwork-36"><span class="linenos">36</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXNetwork-37"><a href="#ONNXNetwork-37"><span class="linenos">37</span></a><span class="sd">    A class used to represent a ONNX representation for a neural network.</span>
</span><span id="ONNXNetwork-38"><a href="#ONNXNetwork-38"><span class="linenos">38</span></a>
</span><span id="ONNXNetwork-39"><a href="#ONNXNetwork-39"><span class="linenos">39</span></a><span class="sd">    Attributes</span>
</span><span id="ONNXNetwork-40"><a href="#ONNXNetwork-40"><span class="linenos">40</span></a><span class="sd">    ----------</span>
</span><span id="ONNXNetwork-41"><a href="#ONNXNetwork-41"><span class="linenos">41</span></a><span class="sd">    onnx_network : onnx.ModelProto</span>
</span><span id="ONNXNetwork-42"><a href="#ONNXNetwork-42"><span class="linenos">42</span></a><span class="sd">        Real ONNX network.</span>
</span><span id="ONNXNetwork-43"><a href="#ONNXNetwork-43"><span class="linenos">43</span></a>
</span><span id="ONNXNetwork-44"><a href="#ONNXNetwork-44"><span class="linenos">44</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ONNXNetwork-45"><a href="#ONNXNetwork-45"><span class="linenos">45</span></a>
</span><span id="ONNXNetwork-46"><a href="#ONNXNetwork-46"><span class="linenos">46</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ONNXNetwork-47"><a href="#ONNXNetwork-47"><span class="linenos">47</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="ONNXNetwork-48"><a href="#ONNXNetwork-48"><span class="linenos">48</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">onnx_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">onnx_network</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class used to represent a ONNX representation for a neural network.</p>

<h2 id="attributes">Attributes</h2>

<p>onnx_network : onnx.ModelProto
    Real ONNX network.</p>
</div>


                            <div id="ONNXNetwork.__init__" class="classattr">
                                        <input id="ONNXNetwork.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ONNXNetwork</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">onnx_network</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">onnx_ml_pb2</span><span class="o">.</span><span class="n">ModelProto</span>,</span><span class="param">	<span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="ONNXNetwork.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXNetwork.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXNetwork.__init__-46"><a href="#ONNXNetwork.__init__-46"><span class="linenos">46</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="ONNXNetwork.__init__-47"><a href="#ONNXNetwork.__init__-47"><span class="linenos">47</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="ONNXNetwork.__init__-48"><a href="#ONNXNetwork.__init__-48"><span class="linenos">48</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">onnx_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">onnx_network</span><span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="ONNXNetwork.onnx_network" class="classattr">
                                <div class="attr variable">
            <span class="name">onnx_network</span>

        
    </div>
    <a class="headerlink" href="#ONNXNetwork.onnx_network"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#AlternativeRepresentation">AlternativeRepresentation</a></dt>
                                <dd id="ONNXNetwork.identifier" class="variable"><a href="#AlternativeRepresentation.identifier">identifier</a></dd>
                <dd id="ONNXNetwork.up_to_date" class="variable"><a href="#AlternativeRepresentation.up_to_date">up_to_date</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PyTorchNetwork">
                            <input id="PyTorchNetwork-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PyTorchNetwork</span><wbr>(<span class="base"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span>):

                <label class="view-source-button" for="PyTorchNetwork-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PyTorchNetwork"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PyTorchNetwork-51"><a href="#PyTorchNetwork-51"><span class="linenos">51</span></a><span class="k">class</span> <span class="nc">PyTorchNetwork</span><span class="p">(</span><span class="n">AlternativeRepresentation</span><span class="p">):</span>
</span><span id="PyTorchNetwork-52"><a href="#PyTorchNetwork-52"><span class="linenos">52</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchNetwork-53"><a href="#PyTorchNetwork-53"><span class="linenos">53</span></a><span class="sd">    A class used to represent a PyTorch representation for a neural network.</span>
</span><span id="PyTorchNetwork-54"><a href="#PyTorchNetwork-54"><span class="linenos">54</span></a>
</span><span id="PyTorchNetwork-55"><a href="#PyTorchNetwork-55"><span class="linenos">55</span></a><span class="sd">    Attributes</span>
</span><span id="PyTorchNetwork-56"><a href="#PyTorchNetwork-56"><span class="linenos">56</span></a><span class="sd">    ----------</span>
</span><span id="PyTorchNetwork-57"><a href="#PyTorchNetwork-57"><span class="linenos">57</span></a><span class="sd">        identifier for the alternative representation</span>
</span><span id="PyTorchNetwork-58"><a href="#PyTorchNetwork-58"><span class="linenos">58</span></a><span class="sd">    pytorch_network : torch.nn.Module</span>
</span><span id="PyTorchNetwork-59"><a href="#PyTorchNetwork-59"><span class="linenos">59</span></a><span class="sd">        Real PyTorch network.</span>
</span><span id="PyTorchNetwork-60"><a href="#PyTorchNetwork-60"><span class="linenos">60</span></a>
</span><span id="PyTorchNetwork-61"><a href="#PyTorchNetwork-61"><span class="linenos">61</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PyTorchNetwork-62"><a href="#PyTorchNetwork-62"><span class="linenos">62</span></a>
</span><span id="PyTorchNetwork-63"><a href="#PyTorchNetwork-63"><span class="linenos">63</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="PyTorchNetwork-64"><a href="#PyTorchNetwork-64"><span class="linenos">64</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="PyTorchNetwork-65"><a href="#PyTorchNetwork-65"><span class="linenos">65</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pytorch_network</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>A class used to represent a PyTorch representation for a neural network.</p>

<h2 id="attributes">Attributes</h2>

<pre><code>identifier for the alternative representation
</code></pre>

<p>pytorch_network : torch.nn.Module
    Real PyTorch network.</p>
</div>


                            <div id="PyTorchNetwork.__init__" class="classattr">
                                        <input id="PyTorchNetwork.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PyTorchNetwork</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">pytorch_network</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span>,</span><span class="param">	<span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="PyTorchNetwork.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PyTorchNetwork.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PyTorchNetwork.__init__-63"><a href="#PyTorchNetwork.__init__-63"><span class="linenos">63</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">identifier</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span><span id="PyTorchNetwork.__init__-64"><a href="#PyTorchNetwork.__init__-64"><span class="linenos">64</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">up_to_date</span><span class="p">)</span>
</span><span id="PyTorchNetwork.__init__-65"><a href="#PyTorchNetwork.__init__-65"><span class="linenos">65</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">pytorch_network</span><span class="p">)</span>
</span></pre></div>


    

                            </div>
                            <div id="PyTorchNetwork.pytorch_network" class="classattr">
                                <div class="attr variable">
            <span class="name">pytorch_network</span>

        
    </div>
    <a class="headerlink" href="#PyTorchNetwork.pytorch_network"></a>
    
    

                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#AlternativeRepresentation">AlternativeRepresentation</a></dt>
                                <dd id="PyTorchNetwork.identifier" class="variable"><a href="#AlternativeRepresentation.identifier">identifier</a></dd>
                <dd id="PyTorchNetwork.up_to_date" class="variable"><a href="#AlternativeRepresentation.up_to_date">up_to_date</a></dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ConversionStrategy">
                            <input id="ConversionStrategy-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ConversionStrategy</span><wbr>(<span class="base">abc.ABC</span>):

                <label class="view-source-button" for="ConversionStrategy-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ConversionStrategy"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ConversionStrategy-68"><a href="#ConversionStrategy-68"><span class="linenos"> 68</span></a><span class="k">class</span> <span class="nc">ConversionStrategy</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</span><span id="ConversionStrategy-69"><a href="#ConversionStrategy-69"><span class="linenos"> 69</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-70"><a href="#ConversionStrategy-70"><span class="linenos"> 70</span></a><span class="sd">    An abstract class used to represent a Conversion Strategy.</span>
</span><span id="ConversionStrategy-71"><a href="#ConversionStrategy-71"><span class="linenos"> 71</span></a>
</span><span id="ConversionStrategy-72"><a href="#ConversionStrategy-72"><span class="linenos"> 72</span></a><span class="sd">    Methods</span>
</span><span id="ConversionStrategy-73"><a href="#ConversionStrategy-73"><span class="linenos"> 73</span></a><span class="sd">    ----------</span>
</span><span id="ConversionStrategy-74"><a href="#ConversionStrategy-74"><span class="linenos"> 74</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="ConversionStrategy-75"><a href="#ConversionStrategy-75"><span class="linenos"> 75</span></a><span class="sd">        Convert the neural network of interest to an alternative representation determined in the concrete children.</span>
</span><span id="ConversionStrategy-76"><a href="#ConversionStrategy-76"><span class="linenos"> 76</span></a><span class="sd">    to_neural_network(AlternativeRepresentation)</span>
</span><span id="ConversionStrategy-77"><a href="#ConversionStrategy-77"><span class="linenos"> 77</span></a><span class="sd">        Convert the alternative representation of interest to our internal representation of a Neural Network.</span>
</span><span id="ConversionStrategy-78"><a href="#ConversionStrategy-78"><span class="linenos"> 78</span></a>
</span><span id="ConversionStrategy-79"><a href="#ConversionStrategy-79"><span class="linenos"> 79</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-80"><a href="#ConversionStrategy-80"><span class="linenos"> 80</span></a>
</span><span id="ConversionStrategy-81"><a href="#ConversionStrategy-81"><span class="linenos"> 81</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="ConversionStrategy-82"><a href="#ConversionStrategy-82"><span class="linenos"> 82</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AlternativeRepresentation</span><span class="p">:</span>
</span><span id="ConversionStrategy-83"><a href="#ConversionStrategy-83"><span class="linenos"> 83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-84"><a href="#ConversionStrategy-84"><span class="linenos"> 84</span></a><span class="sd">        Convert the neural network of interest to an alternative representation determined in the concrete children.</span>
</span><span id="ConversionStrategy-85"><a href="#ConversionStrategy-85"><span class="linenos"> 85</span></a>
</span><span id="ConversionStrategy-86"><a href="#ConversionStrategy-86"><span class="linenos"> 86</span></a><span class="sd">        Parameters</span>
</span><span id="ConversionStrategy-87"><a href="#ConversionStrategy-87"><span class="linenos"> 87</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy-88"><a href="#ConversionStrategy-88"><span class="linenos"> 88</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="ConversionStrategy-89"><a href="#ConversionStrategy-89"><span class="linenos"> 89</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="ConversionStrategy-90"><a href="#ConversionStrategy-90"><span class="linenos"> 90</span></a>
</span><span id="ConversionStrategy-91"><a href="#ConversionStrategy-91"><span class="linenos"> 91</span></a><span class="sd">        Returns</span>
</span><span id="ConversionStrategy-92"><a href="#ConversionStrategy-92"><span class="linenos"> 92</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy-93"><a href="#ConversionStrategy-93"><span class="linenos"> 93</span></a><span class="sd">        AlternativeRepresentation</span>
</span><span id="ConversionStrategy-94"><a href="#ConversionStrategy-94"><span class="linenos"> 94</span></a><span class="sd">            The alternative representation resulting from the conversion of the original network.</span>
</span><span id="ConversionStrategy-95"><a href="#ConversionStrategy-95"><span class="linenos"> 95</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-96"><a href="#ConversionStrategy-96"><span class="linenos"> 96</span></a>        <span class="k">pass</span>
</span><span id="ConversionStrategy-97"><a href="#ConversionStrategy-97"><span class="linenos"> 97</span></a>
</span><span id="ConversionStrategy-98"><a href="#ConversionStrategy-98"><span class="linenos"> 98</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="ConversionStrategy-99"><a href="#ConversionStrategy-99"><span class="linenos"> 99</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">AlternativeRepresentation</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="ConversionStrategy-100"><a href="#ConversionStrategy-100"><span class="linenos">100</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-101"><a href="#ConversionStrategy-101"><span class="linenos">101</span></a><span class="sd">        Convert the alternative representation of interest to the internal one.</span>
</span><span id="ConversionStrategy-102"><a href="#ConversionStrategy-102"><span class="linenos">102</span></a>
</span><span id="ConversionStrategy-103"><a href="#ConversionStrategy-103"><span class="linenos">103</span></a><span class="sd">        Parameters</span>
</span><span id="ConversionStrategy-104"><a href="#ConversionStrategy-104"><span class="linenos">104</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy-105"><a href="#ConversionStrategy-105"><span class="linenos">105</span></a><span class="sd">        alt_rep : AlternativeRepresentation</span>
</span><span id="ConversionStrategy-106"><a href="#ConversionStrategy-106"><span class="linenos">106</span></a><span class="sd">            The Alternative Representation to convert.</span>
</span><span id="ConversionStrategy-107"><a href="#ConversionStrategy-107"><span class="linenos">107</span></a>
</span><span id="ConversionStrategy-108"><a href="#ConversionStrategy-108"><span class="linenos">108</span></a><span class="sd">        Returns</span>
</span><span id="ConversionStrategy-109"><a href="#ConversionStrategy-109"><span class="linenos">109</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy-110"><a href="#ConversionStrategy-110"><span class="linenos">110</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="ConversionStrategy-111"><a href="#ConversionStrategy-111"><span class="linenos">111</span></a><span class="sd">            The Neural Network resulting from the conversion of Alternative Representation.</span>
</span><span id="ConversionStrategy-112"><a href="#ConversionStrategy-112"><span class="linenos">112</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ConversionStrategy-113"><a href="#ConversionStrategy-113"><span class="linenos">113</span></a>        <span class="k">pass</span>
</span></pre></div>


            <div class="docstring"><p>An abstract class used to represent a Conversion Strategy.</p>

<h2 id="methods">Methods</h2>

<p>from_neural_network(NeuralNetwork)
    Convert the neural network of interest to an alternative representation determined in the concrete children.
to_neural_network(AlternativeRepresentation)
    Convert the alternative representation of interest to our internal representation of a Neural Network.</p>
</div>


                            <div id="ConversionStrategy.from_neural_network" class="classattr">
                                        <input id="ConversionStrategy.from_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">from_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">network</span><span class="p">:</span> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span></span><span class="return-annotation">) -> <span class="n"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span>:</span></span>

                <label class="view-source-button" for="ConversionStrategy.from_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ConversionStrategy.from_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ConversionStrategy.from_neural_network-81"><a href="#ConversionStrategy.from_neural_network-81"><span class="linenos">81</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="ConversionStrategy.from_neural_network-82"><a href="#ConversionStrategy.from_neural_network-82"><span class="linenos">82</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AlternativeRepresentation</span><span class="p">:</span>
</span><span id="ConversionStrategy.from_neural_network-83"><a href="#ConversionStrategy.from_neural_network-83"><span class="linenos">83</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ConversionStrategy.from_neural_network-84"><a href="#ConversionStrategy.from_neural_network-84"><span class="linenos">84</span></a><span class="sd">        Convert the neural network of interest to an alternative representation determined in the concrete children.</span>
</span><span id="ConversionStrategy.from_neural_network-85"><a href="#ConversionStrategy.from_neural_network-85"><span class="linenos">85</span></a>
</span><span id="ConversionStrategy.from_neural_network-86"><a href="#ConversionStrategy.from_neural_network-86"><span class="linenos">86</span></a><span class="sd">        Parameters</span>
</span><span id="ConversionStrategy.from_neural_network-87"><a href="#ConversionStrategy.from_neural_network-87"><span class="linenos">87</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy.from_neural_network-88"><a href="#ConversionStrategy.from_neural_network-88"><span class="linenos">88</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="ConversionStrategy.from_neural_network-89"><a href="#ConversionStrategy.from_neural_network-89"><span class="linenos">89</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="ConversionStrategy.from_neural_network-90"><a href="#ConversionStrategy.from_neural_network-90"><span class="linenos">90</span></a>
</span><span id="ConversionStrategy.from_neural_network-91"><a href="#ConversionStrategy.from_neural_network-91"><span class="linenos">91</span></a><span class="sd">        Returns</span>
</span><span id="ConversionStrategy.from_neural_network-92"><a href="#ConversionStrategy.from_neural_network-92"><span class="linenos">92</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy.from_neural_network-93"><a href="#ConversionStrategy.from_neural_network-93"><span class="linenos">93</span></a><span class="sd">        AlternativeRepresentation</span>
</span><span id="ConversionStrategy.from_neural_network-94"><a href="#ConversionStrategy.from_neural_network-94"><span class="linenos">94</span></a><span class="sd">            The alternative representation resulting from the conversion of the original network.</span>
</span><span id="ConversionStrategy.from_neural_network-95"><a href="#ConversionStrategy.from_neural_network-95"><span class="linenos">95</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ConversionStrategy.from_neural_network-96"><a href="#ConversionStrategy.from_neural_network-96"><span class="linenos">96</span></a>        <span class="k">pass</span>
</span></pre></div>


            <div class="docstring"><p>Convert the neural network of interest to an alternative representation determined in the concrete children.</p>

<h2 id="parameters">Parameters</h2>

<p>network : NeuralNetwork
    The neural network to convert.</p>

<h2 id="returns">Returns</h2>

<p>AlternativeRepresentation
    The alternative representation resulting from the conversion of the original network.</p>
</div>


                            </div>
                            <div id="ConversionStrategy.to_neural_network" class="classattr">
                                        <input id="ConversionStrategy.to_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@abc.abstractmethod</div>

        <span class="def">def</span>
        <span class="name">to_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">alt_rep</span><span class="p">:</span> <span class="n"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span></span><span class="return-annotation">) -> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span>:</span></span>

                <label class="view-source-button" for="ConversionStrategy.to_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ConversionStrategy.to_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ConversionStrategy.to_neural_network-98"><a href="#ConversionStrategy.to_neural_network-98"><span class="linenos"> 98</span></a>    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
</span><span id="ConversionStrategy.to_neural_network-99"><a href="#ConversionStrategy.to_neural_network-99"><span class="linenos"> 99</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">AlternativeRepresentation</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="ConversionStrategy.to_neural_network-100"><a href="#ConversionStrategy.to_neural_network-100"><span class="linenos">100</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ConversionStrategy.to_neural_network-101"><a href="#ConversionStrategy.to_neural_network-101"><span class="linenos">101</span></a><span class="sd">        Convert the alternative representation of interest to the internal one.</span>
</span><span id="ConversionStrategy.to_neural_network-102"><a href="#ConversionStrategy.to_neural_network-102"><span class="linenos">102</span></a>
</span><span id="ConversionStrategy.to_neural_network-103"><a href="#ConversionStrategy.to_neural_network-103"><span class="linenos">103</span></a><span class="sd">        Parameters</span>
</span><span id="ConversionStrategy.to_neural_network-104"><a href="#ConversionStrategy.to_neural_network-104"><span class="linenos">104</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy.to_neural_network-105"><a href="#ConversionStrategy.to_neural_network-105"><span class="linenos">105</span></a><span class="sd">        alt_rep : AlternativeRepresentation</span>
</span><span id="ConversionStrategy.to_neural_network-106"><a href="#ConversionStrategy.to_neural_network-106"><span class="linenos">106</span></a><span class="sd">            The Alternative Representation to convert.</span>
</span><span id="ConversionStrategy.to_neural_network-107"><a href="#ConversionStrategy.to_neural_network-107"><span class="linenos">107</span></a>
</span><span id="ConversionStrategy.to_neural_network-108"><a href="#ConversionStrategy.to_neural_network-108"><span class="linenos">108</span></a><span class="sd">        Returns</span>
</span><span id="ConversionStrategy.to_neural_network-109"><a href="#ConversionStrategy.to_neural_network-109"><span class="linenos">109</span></a><span class="sd">        ----------</span>
</span><span id="ConversionStrategy.to_neural_network-110"><a href="#ConversionStrategy.to_neural_network-110"><span class="linenos">110</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="ConversionStrategy.to_neural_network-111"><a href="#ConversionStrategy.to_neural_network-111"><span class="linenos">111</span></a><span class="sd">            The Neural Network resulting from the conversion of Alternative Representation.</span>
</span><span id="ConversionStrategy.to_neural_network-112"><a href="#ConversionStrategy.to_neural_network-112"><span class="linenos">112</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ConversionStrategy.to_neural_network-113"><a href="#ConversionStrategy.to_neural_network-113"><span class="linenos">113</span></a>        <span class="k">pass</span>
</span></pre></div>


            <div class="docstring"><p>Convert the alternative representation of interest to the internal one.</p>

<h2 id="parameters">Parameters</h2>

<p>alt_rep : AlternativeRepresentation
    The Alternative Representation to convert.</p>

<h2 id="returns">Returns</h2>

<p>NeuralNetwork
    The Neural Network resulting from the conversion of Alternative Representation.</p>
</div>


                            </div>
                </section>
                <section id="ONNXConverter">
                            <input id="ONNXConverter-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ONNXConverter</span><wbr>(<span class="base"><a href="#ConversionStrategy">ConversionStrategy</a></span>):

                <label class="view-source-button" for="ONNXConverter-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXConverter"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXConverter-116"><a href="#ONNXConverter-116"><span class="linenos"> 116</span></a><span class="k">class</span> <span class="nc">ONNXConverter</span><span class="p">(</span><span class="n">ConversionStrategy</span><span class="p">):</span>
</span><span id="ONNXConverter-117"><a href="#ONNXConverter-117"><span class="linenos"> 117</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXConverter-118"><a href="#ONNXConverter-118"><span class="linenos"> 118</span></a><span class="sd">    A class used to represent the conversion strategy for ONNX models.</span>
</span><span id="ONNXConverter-119"><a href="#ONNXConverter-119"><span class="linenos"> 119</span></a>
</span><span id="ONNXConverter-120"><a href="#ONNXConverter-120"><span class="linenos"> 120</span></a><span class="sd">    Methods</span>
</span><span id="ONNXConverter-121"><a href="#ONNXConverter-121"><span class="linenos"> 121</span></a><span class="sd">    ----------</span>
</span><span id="ONNXConverter-122"><a href="#ONNXConverter-122"><span class="linenos"> 122</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="ONNXConverter-123"><a href="#ONNXConverter-123"><span class="linenos"> 123</span></a><span class="sd">        Convert the neural network of interest to a ONNXNetwork model.</span>
</span><span id="ONNXConverter-124"><a href="#ONNXConverter-124"><span class="linenos"> 124</span></a><span class="sd">    to_neural_network(ONNXNetwork)</span>
</span><span id="ONNXConverter-125"><a href="#ONNXConverter-125"><span class="linenos"> 125</span></a><span class="sd">        Convert the ONNXNetwork of interest to our internal representation of a Neural Network.</span>
</span><span id="ONNXConverter-126"><a href="#ONNXConverter-126"><span class="linenos"> 126</span></a>
</span><span id="ONNXConverter-127"><a href="#ONNXConverter-127"><span class="linenos"> 127</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ONNXConverter-128"><a href="#ONNXConverter-128"><span class="linenos"> 128</span></a>
</span><span id="ONNXConverter-129"><a href="#ONNXConverter-129"><span class="linenos"> 129</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-130"><a href="#ONNXConverter-130"><span class="linenos"> 130</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_relu</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-131"><a href="#ONNXConverter-131"><span class="linenos"> 131</span></a>
</span><span id="ONNXConverter-132"><a href="#ONNXConverter-132"><span class="linenos"> 132</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-133"><a href="#ONNXConverter-133"><span class="linenos"> 133</span></a>            <span class="s1">&#39;Relu&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-134"><a href="#ONNXConverter-134"><span class="linenos"> 134</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-135"><a href="#ONNXConverter-135"><span class="linenos"> 135</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-136"><a href="#ONNXConverter-136"><span class="linenos"> 136</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-137"><a href="#ONNXConverter-137"><span class="linenos"> 137</span></a>
</span><span id="ONNXConverter-138"><a href="#ONNXConverter-138"><span class="linenos"> 138</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-139"><a href="#ONNXConverter-139"><span class="linenos"> 139</span></a>
</span><span id="ONNXConverter-140"><a href="#ONNXConverter-140"><span class="linenos"> 140</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-141"><a href="#ONNXConverter-141"><span class="linenos"> 141</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_elu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-142"><a href="#ONNXConverter-142"><span class="linenos"> 142</span></a>                       <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-143"><a href="#ONNXConverter-143"><span class="linenos"> 143</span></a>
</span><span id="ONNXConverter-144"><a href="#ONNXConverter-144"><span class="linenos"> 144</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-145"><a href="#ONNXConverter-145"><span class="linenos"> 145</span></a>            <span class="s1">&#39;Elu&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-146"><a href="#ONNXConverter-146"><span class="linenos"> 146</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-147"><a href="#ONNXConverter-147"><span class="linenos"> 147</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-148"><a href="#ONNXConverter-148"><span class="linenos"> 148</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="ONNXConverter-149"><a href="#ONNXConverter-149"><span class="linenos"> 149</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-150"><a href="#ONNXConverter-150"><span class="linenos"> 150</span></a>
</span><span id="ONNXConverter-151"><a href="#ONNXConverter-151"><span class="linenos"> 151</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-152"><a href="#ONNXConverter-152"><span class="linenos"> 152</span></a>
</span><span id="ONNXConverter-153"><a href="#ONNXConverter-153"><span class="linenos"> 153</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-154"><a href="#ONNXConverter-154"><span class="linenos"> 154</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_leakyrelu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-155"><a href="#ONNXConverter-155"><span class="linenos"> 155</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-156"><a href="#ONNXConverter-156"><span class="linenos"> 156</span></a>
</span><span id="ONNXConverter-157"><a href="#ONNXConverter-157"><span class="linenos"> 157</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-158"><a href="#ONNXConverter-158"><span class="linenos"> 158</span></a>            <span class="s1">&#39;LeakyRelu&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-159"><a href="#ONNXConverter-159"><span class="linenos"> 159</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-160"><a href="#ONNXConverter-160"><span class="linenos"> 160</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-161"><a href="#ONNXConverter-161"><span class="linenos"> 161</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">negative_slope</span>
</span><span id="ONNXConverter-162"><a href="#ONNXConverter-162"><span class="linenos"> 162</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-163"><a href="#ONNXConverter-163"><span class="linenos"> 163</span></a>
</span><span id="ONNXConverter-164"><a href="#ONNXConverter-164"><span class="linenos"> 164</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-165"><a href="#ONNXConverter-165"><span class="linenos"> 165</span></a>
</span><span id="ONNXConverter-166"><a href="#ONNXConverter-166"><span class="linenos"> 166</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-167"><a href="#ONNXConverter-167"><span class="linenos"> 167</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_celu</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-168"><a href="#ONNXConverter-168"><span class="linenos"> 168</span></a>                        <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-169"><a href="#ONNXConverter-169"><span class="linenos"> 169</span></a>
</span><span id="ONNXConverter-170"><a href="#ONNXConverter-170"><span class="linenos"> 170</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-171"><a href="#ONNXConverter-171"><span class="linenos"> 171</span></a>            <span class="s1">&#39;Celu&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-172"><a href="#ONNXConverter-172"><span class="linenos"> 172</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-173"><a href="#ONNXConverter-173"><span class="linenos"> 173</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-174"><a href="#ONNXConverter-174"><span class="linenos"> 174</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span>
</span><span id="ONNXConverter-175"><a href="#ONNXConverter-175"><span class="linenos"> 175</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-176"><a href="#ONNXConverter-176"><span class="linenos"> 176</span></a>
</span><span id="ONNXConverter-177"><a href="#ONNXConverter-177"><span class="linenos"> 177</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-178"><a href="#ONNXConverter-178"><span class="linenos"> 178</span></a>
</span><span id="ONNXConverter-179"><a href="#ONNXConverter-179"><span class="linenos"> 179</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-180"><a href="#ONNXConverter-180"><span class="linenos"> 180</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_sigmoid</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-181"><a href="#ONNXConverter-181"><span class="linenos"> 181</span></a>
</span><span id="ONNXConverter-182"><a href="#ONNXConverter-182"><span class="linenos"> 182</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-183"><a href="#ONNXConverter-183"><span class="linenos"> 183</span></a>            <span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-184"><a href="#ONNXConverter-184"><span class="linenos"> 184</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-185"><a href="#ONNXConverter-185"><span class="linenos"> 185</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-186"><a href="#ONNXConverter-186"><span class="linenos"> 186</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-187"><a href="#ONNXConverter-187"><span class="linenos"> 187</span></a>
</span><span id="ONNXConverter-188"><a href="#ONNXConverter-188"><span class="linenos"> 188</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-189"><a href="#ONNXConverter-189"><span class="linenos"> 189</span></a>
</span><span id="ONNXConverter-190"><a href="#ONNXConverter-190"><span class="linenos"> 190</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-191"><a href="#ONNXConverter-191"><span class="linenos"> 191</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_tanh</span><span class="p">(</span><span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-192"><a href="#ONNXConverter-192"><span class="linenos"> 192</span></a>
</span><span id="ONNXConverter-193"><a href="#ONNXConverter-193"><span class="linenos"> 193</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-194"><a href="#ONNXConverter-194"><span class="linenos"> 194</span></a>            <span class="s1">&#39;Tanh&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-195"><a href="#ONNXConverter-195"><span class="linenos"> 195</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-196"><a href="#ONNXConverter-196"><span class="linenos"> 196</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-197"><a href="#ONNXConverter-197"><span class="linenos"> 197</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-198"><a href="#ONNXConverter-198"><span class="linenos"> 198</span></a>
</span><span id="ONNXConverter-199"><a href="#ONNXConverter-199"><span class="linenos"> 199</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-200"><a href="#ONNXConverter-200"><span class="linenos"> 200</span></a>
</span><span id="ONNXConverter-201"><a href="#ONNXConverter-201"><span class="linenos"> 201</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-202"><a href="#ONNXConverter-202"><span class="linenos"> 202</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_linear</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-203"><a href="#ONNXConverter-203"><span class="linenos"> 203</span></a>                          <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-204"><a href="#ONNXConverter-204"><span class="linenos"> 204</span></a>
</span><span id="ONNXConverter-205"><a href="#ONNXConverter-205"><span class="linenos"> 205</span></a>        <span class="n">input_weight</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_weight&quot;</span>
</span><span id="ONNXConverter-206"><a href="#ONNXConverter-206"><span class="linenos"> 206</span></a>
</span><span id="ONNXConverter-207"><a href="#ONNXConverter-207"><span class="linenos"> 207</span></a>        <span class="n">weight_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_weight</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-208"><a href="#ONNXConverter-208"><span class="linenos"> 208</span></a>                                                               <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span>
</span><span id="ONNXConverter-209"><a href="#ONNXConverter-209"><span class="linenos"> 209</span></a>                                                                <span class="n">current_node</span><span class="o">.</span><span class="n">in_features</span><span class="p">])</span>
</span><span id="ONNXConverter-210"><a href="#ONNXConverter-210"><span class="linenos"> 210</span></a>
</span><span id="ONNXConverter-211"><a href="#ONNXConverter-211"><span class="linenos"> 211</span></a>        <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">)</span>
</span><span id="ONNXConverter-212"><a href="#ONNXConverter-212"><span class="linenos"> 212</span></a>
</span><span id="ONNXConverter-213"><a href="#ONNXConverter-213"><span class="linenos"> 213</span></a>        <span class="k">if</span> <span class="n">current_node</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="ONNXConverter-214"><a href="#ONNXConverter-214"><span class="linenos"> 214</span></a>            <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="ONNXConverter-215"><a href="#ONNXConverter-215"><span class="linenos"> 215</span></a>            <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-216"><a href="#ONNXConverter-216"><span class="linenos"> 216</span></a>                                                                 <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">out_features</span><span class="p">])</span>
</span><span id="ONNXConverter-217"><a href="#ONNXConverter-217"><span class="linenos"> 217</span></a>            <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="ONNXConverter-218"><a href="#ONNXConverter-218"><span class="linenos"> 218</span></a>
</span><span id="ONNXConverter-219"><a href="#ONNXConverter-219"><span class="linenos"> 219</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-220"><a href="#ONNXConverter-220"><span class="linenos"> 220</span></a>                <span class="s1">&#39;Gemm&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-221"><a href="#ONNXConverter-221"><span class="linenos"> 221</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">],</span>
</span><span id="ONNXConverter-222"><a href="#ONNXConverter-222"><span class="linenos"> 222</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-223"><a href="#ONNXConverter-223"><span class="linenos"> 223</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="ONNXConverter-224"><a href="#ONNXConverter-224"><span class="linenos"> 224</span></a>                <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="ONNXConverter-225"><a href="#ONNXConverter-225"><span class="linenos"> 225</span></a>                <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="ONNXConverter-226"><a href="#ONNXConverter-226"><span class="linenos"> 226</span></a>                <span class="n">transB</span><span class="o">=</span><span class="mi">0</span>
</span><span id="ONNXConverter-227"><a href="#ONNXConverter-227"><span class="linenos"> 227</span></a>            <span class="p">)</span>
</span><span id="ONNXConverter-228"><a href="#ONNXConverter-228"><span class="linenos"> 228</span></a>
</span><span id="ONNXConverter-229"><a href="#ONNXConverter-229"><span class="linenos"> 229</span></a>            <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-230"><a href="#ONNXConverter-230"><span class="linenos"> 230</span></a>            <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-231"><a href="#ONNXConverter-231"><span class="linenos"> 231</span></a>
</span><span id="ONNXConverter-232"><a href="#ONNXConverter-232"><span class="linenos"> 232</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-233"><a href="#ONNXConverter-233"><span class="linenos"> 233</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-234"><a href="#ONNXConverter-234"><span class="linenos"> 234</span></a>                <span class="s1">&#39;Gemm&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-235"><a href="#ONNXConverter-235"><span class="linenos"> 235</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">],</span>
</span><span id="ONNXConverter-236"><a href="#ONNXConverter-236"><span class="linenos"> 236</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-237"><a href="#ONNXConverter-237"><span class="linenos"> 237</span></a>                <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="ONNXConverter-238"><a href="#ONNXConverter-238"><span class="linenos"> 238</span></a>                <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="ONNXConverter-239"><a href="#ONNXConverter-239"><span class="linenos"> 239</span></a>                <span class="n">transA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="ONNXConverter-240"><a href="#ONNXConverter-240"><span class="linenos"> 240</span></a>                <span class="n">transB</span><span class="o">=</span><span class="mi">0</span>
</span><span id="ONNXConverter-241"><a href="#ONNXConverter-241"><span class="linenos"> 241</span></a>            <span class="p">)</span>
</span><span id="ONNXConverter-242"><a href="#ONNXConverter-242"><span class="linenos"> 242</span></a>
</span><span id="ONNXConverter-243"><a href="#ONNXConverter-243"><span class="linenos"> 243</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-244"><a href="#ONNXConverter-244"><span class="linenos"> 244</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-245"><a href="#ONNXConverter-245"><span class="linenos"> 245</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-246"><a href="#ONNXConverter-246"><span class="linenos"> 246</span></a>
</span><span id="ONNXConverter-247"><a href="#ONNXConverter-247"><span class="linenos"> 247</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-248"><a href="#ONNXConverter-248"><span class="linenos"> 248</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_batchnorm</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-249"><a href="#ONNXConverter-249"><span class="linenos"> 249</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-250"><a href="#ONNXConverter-250"><span class="linenos"> 250</span></a>
</span><span id="ONNXConverter-251"><a href="#ONNXConverter-251"><span class="linenos"> 251</span></a>        <span class="n">input_scale</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>
</span><span id="ONNXConverter-252"><a href="#ONNXConverter-252"><span class="linenos"> 252</span></a>        <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="ONNXConverter-253"><a href="#ONNXConverter-253"><span class="linenos"> 253</span></a>        <span class="n">input_mean</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span>
</span><span id="ONNXConverter-254"><a href="#ONNXConverter-254"><span class="linenos"> 254</span></a>        <span class="n">input_var</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_var&quot;</span>
</span><span id="ONNXConverter-255"><a href="#ONNXConverter-255"><span class="linenos"> 255</span></a>
</span><span id="ONNXConverter-256"><a href="#ONNXConverter-256"><span class="linenos"> 256</span></a>        <span class="n">scale_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_scale</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-257"><a href="#ONNXConverter-257"><span class="linenos"> 257</span></a>                                                              <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="ONNXConverter-258"><a href="#ONNXConverter-258"><span class="linenos"> 258</span></a>        <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-259"><a href="#ONNXConverter-259"><span class="linenos"> 259</span></a>                                                             <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="ONNXConverter-260"><a href="#ONNXConverter-260"><span class="linenos"> 260</span></a>        <span class="n">mean_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_mean</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-261"><a href="#ONNXConverter-261"><span class="linenos"> 261</span></a>                                                             <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="ONNXConverter-262"><a href="#ONNXConverter-262"><span class="linenos"> 262</span></a>        <span class="n">var_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_var</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-263"><a href="#ONNXConverter-263"><span class="linenos"> 263</span></a>                                                            <span class="p">[</span><span class="n">current_node</span><span class="o">.</span><span class="n">num_features</span><span class="p">])</span>
</span><span id="ONNXConverter-264"><a href="#ONNXConverter-264"><span class="linenos"> 264</span></a>
</span><span id="ONNXConverter-265"><a href="#ONNXConverter-265"><span class="linenos"> 265</span></a>        <span class="n">scale_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">)</span>
</span><span id="ONNXConverter-266"><a href="#ONNXConverter-266"><span class="linenos"> 266</span></a>        <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="ONNXConverter-267"><a href="#ONNXConverter-267"><span class="linenos"> 267</span></a>        <span class="n">mean_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">running_mean</span><span class="p">,</span> <span class="n">input_mean</span><span class="p">)</span>
</span><span id="ONNXConverter-268"><a href="#ONNXConverter-268"><span class="linenos"> 268</span></a>        <span class="n">var_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">running_var</span><span class="p">,</span> <span class="n">input_var</span><span class="p">)</span>
</span><span id="ONNXConverter-269"><a href="#ONNXConverter-269"><span class="linenos"> 269</span></a>
</span><span id="ONNXConverter-270"><a href="#ONNXConverter-270"><span class="linenos"> 270</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-271"><a href="#ONNXConverter-271"><span class="linenos"> 271</span></a>            <span class="s1">&#39;BatchNormalization&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-272"><a href="#ONNXConverter-272"><span class="linenos"> 272</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_scale</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">,</span> <span class="n">input_mean</span><span class="p">,</span> <span class="n">input_var</span><span class="p">],</span>
</span><span id="ONNXConverter-273"><a href="#ONNXConverter-273"><span class="linenos"> 273</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-274"><a href="#ONNXConverter-274"><span class="linenos"> 274</span></a>            <span class="n">epsilon</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
</span><span id="ONNXConverter-275"><a href="#ONNXConverter-275"><span class="linenos"> 275</span></a>            <span class="n">momentum</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="ONNXConverter-276"><a href="#ONNXConverter-276"><span class="linenos"> 276</span></a>            <span class="n">training_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="ONNXConverter-277"><a href="#ONNXConverter-277"><span class="linenos"> 277</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-278"><a href="#ONNXConverter-278"><span class="linenos"> 278</span></a>
</span><span id="ONNXConverter-279"><a href="#ONNXConverter-279"><span class="linenos"> 279</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-280"><a href="#ONNXConverter-280"><span class="linenos"> 280</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-281"><a href="#ONNXConverter-281"><span class="linenos"> 281</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-282"><a href="#ONNXConverter-282"><span class="linenos"> 282</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-283"><a href="#ONNXConverter-283"><span class="linenos"> 283</span></a>
</span><span id="ONNXConverter-284"><a href="#ONNXConverter-284"><span class="linenos"> 284</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-285"><a href="#ONNXConverter-285"><span class="linenos"> 285</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-286"><a href="#ONNXConverter-286"><span class="linenos"> 286</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-287"><a href="#ONNXConverter-287"><span class="linenos"> 287</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">var_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-288"><a href="#ONNXConverter-288"><span class="linenos"> 288</span></a>
</span><span id="ONNXConverter-289"><a href="#ONNXConverter-289"><span class="linenos"> 289</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-290"><a href="#ONNXConverter-290"><span class="linenos"> 290</span></a>
</span><span id="ONNXConverter-291"><a href="#ONNXConverter-291"><span class="linenos"> 291</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-292"><a href="#ONNXConverter-292"><span class="linenos"> 292</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_conv</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-293"><a href="#ONNXConverter-293"><span class="linenos"> 293</span></a>                        <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-294"><a href="#ONNXConverter-294"><span class="linenos"> 294</span></a>
</span><span id="ONNXConverter-295"><a href="#ONNXConverter-295"><span class="linenos"> 295</span></a>        <span class="n">weight_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="ONNXConverter-296"><a href="#ONNXConverter-296"><span class="linenos"> 296</span></a>        <span class="n">input_weight</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_weight&quot;</span>
</span><span id="ONNXConverter-297"><a href="#ONNXConverter-297"><span class="linenos"> 297</span></a>
</span><span id="ONNXConverter-298"><a href="#ONNXConverter-298"><span class="linenos"> 298</span></a>        <span class="n">weight_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_weight</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-299"><a href="#ONNXConverter-299"><span class="linenos"> 299</span></a>                                                               <span class="n">weight_size</span><span class="p">)</span>
</span><span id="ONNXConverter-300"><a href="#ONNXConverter-300"><span class="linenos"> 300</span></a>
</span><span id="ONNXConverter-301"><a href="#ONNXConverter-301"><span class="linenos"> 301</span></a>        <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">)</span>
</span><span id="ONNXConverter-302"><a href="#ONNXConverter-302"><span class="linenos"> 302</span></a>
</span><span id="ONNXConverter-303"><a href="#ONNXConverter-303"><span class="linenos"> 303</span></a>        <span class="k">if</span> <span class="n">current_node</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="ONNXConverter-304"><a href="#ONNXConverter-304"><span class="linenos"> 304</span></a>
</span><span id="ONNXConverter-305"><a href="#ONNXConverter-305"><span class="linenos"> 305</span></a>            <span class="n">input_bias</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_bias&quot;</span>
</span><span id="ONNXConverter-306"><a href="#ONNXConverter-306"><span class="linenos"> 306</span></a>            <span class="n">bias_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="ONNXConverter-307"><a href="#ONNXConverter-307"><span class="linenos"> 307</span></a>
</span><span id="ONNXConverter-308"><a href="#ONNXConverter-308"><span class="linenos"> 308</span></a>            <span class="n">bias_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_bias</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-309"><a href="#ONNXConverter-309"><span class="linenos"> 309</span></a>                                                                 <span class="n">bias_size</span><span class="p">)</span>
</span><span id="ONNXConverter-310"><a href="#ONNXConverter-310"><span class="linenos"> 310</span></a>            <span class="n">bias_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">)</span>
</span><span id="ONNXConverter-311"><a href="#ONNXConverter-311"><span class="linenos"> 311</span></a>
</span><span id="ONNXConverter-312"><a href="#ONNXConverter-312"><span class="linenos"> 312</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-313"><a href="#ONNXConverter-313"><span class="linenos"> 313</span></a>                <span class="s1">&#39;Conv&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-314"><a href="#ONNXConverter-314"><span class="linenos"> 314</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">,</span> <span class="n">input_bias</span><span class="p">],</span>
</span><span id="ONNXConverter-315"><a href="#ONNXConverter-315"><span class="linenos"> 315</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-316"><a href="#ONNXConverter-316"><span class="linenos"> 316</span></a>                <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="ONNXConverter-317"><a href="#ONNXConverter-317"><span class="linenos"> 317</span></a>                <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="ONNXConverter-318"><a href="#ONNXConverter-318"><span class="linenos"> 318</span></a>                <span class="n">dilations</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">),</span>
</span><span id="ONNXConverter-319"><a href="#ONNXConverter-319"><span class="linenos"> 319</span></a>                <span class="n">groups</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="ONNXConverter-320"><a href="#ONNXConverter-320"><span class="linenos"> 320</span></a>                <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="ONNXConverter-321"><a href="#ONNXConverter-321"><span class="linenos"> 321</span></a>            <span class="p">)</span>
</span><span id="ONNXConverter-322"><a href="#ONNXConverter-322"><span class="linenos"> 322</span></a>
</span><span id="ONNXConverter-323"><a href="#ONNXConverter-323"><span class="linenos"> 323</span></a>            <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-324"><a href="#ONNXConverter-324"><span class="linenos"> 324</span></a>            <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-325"><a href="#ONNXConverter-325"><span class="linenos"> 325</span></a>
</span><span id="ONNXConverter-326"><a href="#ONNXConverter-326"><span class="linenos"> 326</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-327"><a href="#ONNXConverter-327"><span class="linenos"> 327</span></a>            <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-328"><a href="#ONNXConverter-328"><span class="linenos"> 328</span></a>                <span class="s1">&#39;Conv&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-329"><a href="#ONNXConverter-329"><span class="linenos"> 329</span></a>                <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">],</span>
</span><span id="ONNXConverter-330"><a href="#ONNXConverter-330"><span class="linenos"> 330</span></a>                <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-331"><a href="#ONNXConverter-331"><span class="linenos"> 331</span></a>                <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="ONNXConverter-332"><a href="#ONNXConverter-332"><span class="linenos"> 332</span></a>                <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="ONNXConverter-333"><a href="#ONNXConverter-333"><span class="linenos"> 333</span></a>                <span class="n">dilations</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">),</span>
</span><span id="ONNXConverter-334"><a href="#ONNXConverter-334"><span class="linenos"> 334</span></a>                <span class="n">groups</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="ONNXConverter-335"><a href="#ONNXConverter-335"><span class="linenos"> 335</span></a>                <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="ONNXConverter-336"><a href="#ONNXConverter-336"><span class="linenos"> 336</span></a>            <span class="p">)</span>
</span><span id="ONNXConverter-337"><a href="#ONNXConverter-337"><span class="linenos"> 337</span></a>
</span><span id="ONNXConverter-338"><a href="#ONNXConverter-338"><span class="linenos"> 338</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-339"><a href="#ONNXConverter-339"><span class="linenos"> 339</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-340"><a href="#ONNXConverter-340"><span class="linenos"> 340</span></a>
</span><span id="ONNXConverter-341"><a href="#ONNXConverter-341"><span class="linenos"> 341</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-342"><a href="#ONNXConverter-342"><span class="linenos"> 342</span></a>
</span><span id="ONNXConverter-343"><a href="#ONNXConverter-343"><span class="linenos"> 343</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-344"><a href="#ONNXConverter-344"><span class="linenos"> 344</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_averagepool</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-345"><a href="#ONNXConverter-345"><span class="linenos"> 345</span></a>                               <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-346"><a href="#ONNXConverter-346"><span class="linenos"> 346</span></a>
</span><span id="ONNXConverter-347"><a href="#ONNXConverter-347"><span class="linenos"> 347</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-348"><a href="#ONNXConverter-348"><span class="linenos"> 348</span></a>            <span class="s1">&#39;AveragePool&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-349"><a href="#ONNXConverter-349"><span class="linenos"> 349</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-350"><a href="#ONNXConverter-350"><span class="linenos"> 350</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-351"><a href="#ONNXConverter-351"><span class="linenos"> 351</span></a>            <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">),</span>
</span><span id="ONNXConverter-352"><a href="#ONNXConverter-352"><span class="linenos"> 352</span></a>            <span class="n">count_include_pad</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">),</span>
</span><span id="ONNXConverter-353"><a href="#ONNXConverter-353"><span class="linenos"> 353</span></a>            <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="ONNXConverter-354"><a href="#ONNXConverter-354"><span class="linenos"> 354</span></a>            <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="ONNXConverter-355"><a href="#ONNXConverter-355"><span class="linenos"> 355</span></a>            <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="ONNXConverter-356"><a href="#ONNXConverter-356"><span class="linenos"> 356</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-357"><a href="#ONNXConverter-357"><span class="linenos"> 357</span></a>
</span><span id="ONNXConverter-358"><a href="#ONNXConverter-358"><span class="linenos"> 358</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-359"><a href="#ONNXConverter-359"><span class="linenos"> 359</span></a>
</span><span id="ONNXConverter-360"><a href="#ONNXConverter-360"><span class="linenos"> 360</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-361"><a href="#ONNXConverter-361"><span class="linenos"> 361</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_maxpool</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-362"><a href="#ONNXConverter-362"><span class="linenos"> 362</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-363"><a href="#ONNXConverter-363"><span class="linenos"> 363</span></a>
</span><span id="ONNXConverter-364"><a href="#ONNXConverter-364"><span class="linenos"> 364</span></a>        <span class="c1"># N.B. we do not support the attribute storage_order of ONNX</span>
</span><span id="ONNXConverter-365"><a href="#ONNXConverter-365"><span class="linenos"> 365</span></a>        <span class="c1"># ONNX does not support the return_indices parameters</span>
</span><span id="ONNXConverter-366"><a href="#ONNXConverter-366"><span class="linenos"> 366</span></a>
</span><span id="ONNXConverter-367"><a href="#ONNXConverter-367"><span class="linenos"> 367</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-368"><a href="#ONNXConverter-368"><span class="linenos"> 368</span></a>            <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-369"><a href="#ONNXConverter-369"><span class="linenos"> 369</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-370"><a href="#ONNXConverter-370"><span class="linenos"> 370</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-371"><a href="#ONNXConverter-371"><span class="linenos"> 371</span></a>            <span class="n">ceil_mode</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">),</span>
</span><span id="ONNXConverter-372"><a href="#ONNXConverter-372"><span class="linenos"> 372</span></a>            <span class="n">dilations</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
</span><span id="ONNXConverter-373"><a href="#ONNXConverter-373"><span class="linenos"> 373</span></a>            <span class="n">kernel_shape</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">),</span>
</span><span id="ONNXConverter-374"><a href="#ONNXConverter-374"><span class="linenos"> 374</span></a>            <span class="n">strides</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">stride</span><span class="p">),</span>
</span><span id="ONNXConverter-375"><a href="#ONNXConverter-375"><span class="linenos"> 375</span></a>            <span class="n">pads</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="ONNXConverter-376"><a href="#ONNXConverter-376"><span class="linenos"> 376</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-377"><a href="#ONNXConverter-377"><span class="linenos"> 377</span></a>
</span><span id="ONNXConverter-378"><a href="#ONNXConverter-378"><span class="linenos"> 378</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-379"><a href="#ONNXConverter-379"><span class="linenos"> 379</span></a>
</span><span id="ONNXConverter-380"><a href="#ONNXConverter-380"><span class="linenos"> 380</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-381"><a href="#ONNXConverter-381"><span class="linenos"> 381</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_lrn</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-382"><a href="#ONNXConverter-382"><span class="linenos"> 382</span></a>                       <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-383"><a href="#ONNXConverter-383"><span class="linenos"> 383</span></a>
</span><span id="ONNXConverter-384"><a href="#ONNXConverter-384"><span class="linenos"> 384</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-385"><a href="#ONNXConverter-385"><span class="linenos"> 385</span></a>            <span class="s1">&#39;LRN&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-386"><a href="#ONNXConverter-386"><span class="linenos"> 386</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-387"><a href="#ONNXConverter-387"><span class="linenos"> 387</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-388"><a href="#ONNXConverter-388"><span class="linenos"> 388</span></a>            <span class="n">alpha</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span>
</span><span id="ONNXConverter-389"><a href="#ONNXConverter-389"><span class="linenos"> 389</span></a>            <span class="n">beta</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span>
</span><span id="ONNXConverter-390"><a href="#ONNXConverter-390"><span class="linenos"> 390</span></a>            <span class="n">bias</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">k</span><span class="p">,</span>
</span><span id="ONNXConverter-391"><a href="#ONNXConverter-391"><span class="linenos"> 391</span></a>            <span class="n">size</span><span class="o">=</span><span class="n">current_node</span><span class="o">.</span><span class="n">size</span>
</span><span id="ONNXConverter-392"><a href="#ONNXConverter-392"><span class="linenos"> 392</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-393"><a href="#ONNXConverter-393"><span class="linenos"> 393</span></a>
</span><span id="ONNXConverter-394"><a href="#ONNXConverter-394"><span class="linenos"> 394</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-395"><a href="#ONNXConverter-395"><span class="linenos"> 395</span></a>
</span><span id="ONNXConverter-396"><a href="#ONNXConverter-396"><span class="linenos"> 396</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-397"><a href="#ONNXConverter-397"><span class="linenos"> 397</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_softmax</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-398"><a href="#ONNXConverter-398"><span class="linenos"> 398</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-399"><a href="#ONNXConverter-399"><span class="linenos"> 399</span></a>
</span><span id="ONNXConverter-400"><a href="#ONNXConverter-400"><span class="linenos"> 400</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the axis by 1</span>
</span><span id="ONNXConverter-401"><a href="#ONNXConverter-401"><span class="linenos"> 401</span></a>        <span class="c1"># when we pass to the onnx representation.</span>
</span><span id="ONNXConverter-402"><a href="#ONNXConverter-402"><span class="linenos"> 402</span></a>        <span class="n">temp_axis</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="ONNXConverter-403"><a href="#ONNXConverter-403"><span class="linenos"> 403</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-404"><a href="#ONNXConverter-404"><span class="linenos"> 404</span></a>            <span class="s1">&#39;Softmax&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-405"><a href="#ONNXConverter-405"><span class="linenos"> 405</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-406"><a href="#ONNXConverter-406"><span class="linenos"> 406</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-407"><a href="#ONNXConverter-407"><span class="linenos"> 407</span></a>            <span class="n">axis</span><span class="o">=</span><span class="n">temp_axis</span>
</span><span id="ONNXConverter-408"><a href="#ONNXConverter-408"><span class="linenos"> 408</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-409"><a href="#ONNXConverter-409"><span class="linenos"> 409</span></a>
</span><span id="ONNXConverter-410"><a href="#ONNXConverter-410"><span class="linenos"> 410</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-411"><a href="#ONNXConverter-411"><span class="linenos"> 411</span></a>
</span><span id="ONNXConverter-412"><a href="#ONNXConverter-412"><span class="linenos"> 412</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-413"><a href="#ONNXConverter-413"><span class="linenos"> 413</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_unsqueeze</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-414"><a href="#ONNXConverter-414"><span class="linenos"> 414</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-415"><a href="#ONNXConverter-415"><span class="linenos"> 415</span></a>
</span><span id="ONNXConverter-416"><a href="#ONNXConverter-416"><span class="linenos"> 416</span></a>        <span class="n">axes_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">axes</span><span class="p">)]</span>
</span><span id="ONNXConverter-417"><a href="#ONNXConverter-417"><span class="linenos"> 417</span></a>        <span class="n">input_axes</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_axes&quot;</span>
</span><span id="ONNXConverter-418"><a href="#ONNXConverter-418"><span class="linenos"> 418</span></a>
</span><span id="ONNXConverter-419"><a href="#ONNXConverter-419"><span class="linenos"> 419</span></a>        <span class="n">axes_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_axes</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
</span><span id="ONNXConverter-420"><a href="#ONNXConverter-420"><span class="linenos"> 420</span></a>                                                             <span class="n">axes_size</span><span class="p">)</span>
</span><span id="ONNXConverter-421"><a href="#ONNXConverter-421"><span class="linenos"> 421</span></a>
</span><span id="ONNXConverter-422"><a href="#ONNXConverter-422"><span class="linenos"> 422</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale all the axes</span>
</span><span id="ONNXConverter-423"><a href="#ONNXConverter-423"><span class="linenos"> 423</span></a>        <span class="c1"># by 1 when we pass to the onnx representation.</span>
</span><span id="ONNXConverter-424"><a href="#ONNXConverter-424"><span class="linenos"> 424</span></a>        <span class="n">temp_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axes</span><span class="p">]</span>
</span><span id="ONNXConverter-425"><a href="#ONNXConverter-425"><span class="linenos"> 425</span></a>        <span class="n">axes_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temp_axes</span><span class="p">),</span> <span class="n">input_axes</span><span class="p">)</span>
</span><span id="ONNXConverter-426"><a href="#ONNXConverter-426"><span class="linenos"> 426</span></a>
</span><span id="ONNXConverter-427"><a href="#ONNXConverter-427"><span class="linenos"> 427</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-428"><a href="#ONNXConverter-428"><span class="linenos"> 428</span></a>            <span class="s1">&#39;Unsqueeze&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-429"><a href="#ONNXConverter-429"><span class="linenos"> 429</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_axes</span><span class="p">],</span>
</span><span id="ONNXConverter-430"><a href="#ONNXConverter-430"><span class="linenos"> 430</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">]</span>
</span><span id="ONNXConverter-431"><a href="#ONNXConverter-431"><span class="linenos"> 431</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-432"><a href="#ONNXConverter-432"><span class="linenos"> 432</span></a>
</span><span id="ONNXConverter-433"><a href="#ONNXConverter-433"><span class="linenos"> 433</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axes_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-434"><a href="#ONNXConverter-434"><span class="linenos"> 434</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axes_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-435"><a href="#ONNXConverter-435"><span class="linenos"> 435</span></a>
</span><span id="ONNXConverter-436"><a href="#ONNXConverter-436"><span class="linenos"> 436</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-437"><a href="#ONNXConverter-437"><span class="linenos"> 437</span></a>
</span><span id="ONNXConverter-438"><a href="#ONNXConverter-438"><span class="linenos"> 438</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-439"><a href="#ONNXConverter-439"><span class="linenos"> 439</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_reshape</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-440"><a href="#ONNXConverter-440"><span class="linenos"> 440</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-441"><a href="#ONNXConverter-441"><span class="linenos"> 441</span></a>
</span><span id="ONNXConverter-442"><a href="#ONNXConverter-442"><span class="linenos"> 442</span></a>        <span class="c1"># Need to add the batch dimension to the shape</span>
</span><span id="ONNXConverter-443"><a href="#ONNXConverter-443"><span class="linenos"> 443</span></a>        <span class="n">temp_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter-444"><a href="#ONNXConverter-444"><span class="linenos"> 444</span></a>        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="ONNXConverter-445"><a href="#ONNXConverter-445"><span class="linenos"> 445</span></a>            <span class="n">temp_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="ONNXConverter-446"><a href="#ONNXConverter-446"><span class="linenos"> 446</span></a>        <span class="n">shape_size</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
</span><span id="ONNXConverter-447"><a href="#ONNXConverter-447"><span class="linenos"> 447</span></a>        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_shape&quot;</span>
</span><span id="ONNXConverter-448"><a href="#ONNXConverter-448"><span class="linenos"> 448</span></a>
</span><span id="ONNXConverter-449"><a href="#ONNXConverter-449"><span class="linenos"> 449</span></a>        <span class="n">shape_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
</span><span id="ONNXConverter-450"><a href="#ONNXConverter-450"><span class="linenos"> 450</span></a>                                                              <span class="n">shape_size</span><span class="p">)</span>
</span><span id="ONNXConverter-451"><a href="#ONNXConverter-451"><span class="linenos"> 451</span></a>
</span><span id="ONNXConverter-452"><a href="#ONNXConverter-452"><span class="linenos"> 452</span></a>        <span class="n">shape_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temp_shape</span><span class="p">),</span> <span class="n">input_shape</span><span class="p">)</span>
</span><span id="ONNXConverter-453"><a href="#ONNXConverter-453"><span class="linenos"> 453</span></a>
</span><span id="ONNXConverter-454"><a href="#ONNXConverter-454"><span class="linenos"> 454</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-455"><a href="#ONNXConverter-455"><span class="linenos"> 455</span></a>            <span class="s1">&#39;Reshape&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-456"><a href="#ONNXConverter-456"><span class="linenos"> 456</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">],</span>
</span><span id="ONNXConverter-457"><a href="#ONNXConverter-457"><span class="linenos"> 457</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-458"><a href="#ONNXConverter-458"><span class="linenos"> 458</span></a>            <span class="n">allow_zero</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">current_node</span><span class="o">.</span><span class="n">allow_zero</span><span class="p">)</span>
</span><span id="ONNXConverter-459"><a href="#ONNXConverter-459"><span class="linenos"> 459</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-460"><a href="#ONNXConverter-460"><span class="linenos"> 460</span></a>
</span><span id="ONNXConverter-461"><a href="#ONNXConverter-461"><span class="linenos"> 461</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-462"><a href="#ONNXConverter-462"><span class="linenos"> 462</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-463"><a href="#ONNXConverter-463"><span class="linenos"> 463</span></a>
</span><span id="ONNXConverter-464"><a href="#ONNXConverter-464"><span class="linenos"> 464</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-465"><a href="#ONNXConverter-465"><span class="linenos"> 465</span></a>
</span><span id="ONNXConverter-466"><a href="#ONNXConverter-466"><span class="linenos"> 466</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-467"><a href="#ONNXConverter-467"><span class="linenos"> 467</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_flatten</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-468"><a href="#ONNXConverter-468"><span class="linenos"> 468</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-469"><a href="#ONNXConverter-469"><span class="linenos"> 469</span></a>
</span><span id="ONNXConverter-470"><a href="#ONNXConverter-470"><span class="linenos"> 470</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the axis by 1</span>
</span><span id="ONNXConverter-471"><a href="#ONNXConverter-471"><span class="linenos"> 471</span></a>        <span class="c1"># when we pass to the onnx representation.</span>
</span><span id="ONNXConverter-472"><a href="#ONNXConverter-472"><span class="linenos"> 472</span></a>        <span class="n">temp_axis</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span>
</span><span id="ONNXConverter-473"><a href="#ONNXConverter-473"><span class="linenos"> 473</span></a>
</span><span id="ONNXConverter-474"><a href="#ONNXConverter-474"><span class="linenos"> 474</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-475"><a href="#ONNXConverter-475"><span class="linenos"> 475</span></a>            <span class="s1">&#39;Flatten&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-476"><a href="#ONNXConverter-476"><span class="linenos"> 476</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-477"><a href="#ONNXConverter-477"><span class="linenos"> 477</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-478"><a href="#ONNXConverter-478"><span class="linenos"> 478</span></a>            <span class="n">axis</span><span class="o">=</span><span class="n">temp_axis</span>
</span><span id="ONNXConverter-479"><a href="#ONNXConverter-479"><span class="linenos"> 479</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-480"><a href="#ONNXConverter-480"><span class="linenos"> 480</span></a>
</span><span id="ONNXConverter-481"><a href="#ONNXConverter-481"><span class="linenos"> 481</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-482"><a href="#ONNXConverter-482"><span class="linenos"> 482</span></a>
</span><span id="ONNXConverter-483"><a href="#ONNXConverter-483"><span class="linenos"> 483</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-484"><a href="#ONNXConverter-484"><span class="linenos"> 484</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_dropout</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-485"><a href="#ONNXConverter-485"><span class="linenos"> 485</span></a>                           <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">input_info</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">initializers</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-486"><a href="#ONNXConverter-486"><span class="linenos"> 486</span></a>
</span><span id="ONNXConverter-487"><a href="#ONNXConverter-487"><span class="linenos"> 487</span></a>        <span class="c1"># N.B. we do not support the seed attribute and the training_mode input.</span>
</span><span id="ONNXConverter-488"><a href="#ONNXConverter-488"><span class="linenos"> 488</span></a>
</span><span id="ONNXConverter-489"><a href="#ONNXConverter-489"><span class="linenos"> 489</span></a>        <span class="n">ratio_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter-490"><a href="#ONNXConverter-490"><span class="linenos"> 490</span></a>        <span class="n">input_ratio</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span> <span class="o">+</span> <span class="s2">&quot;_ratio&quot;</span>
</span><span id="ONNXConverter-491"><a href="#ONNXConverter-491"><span class="linenos"> 491</span></a>
</span><span id="ONNXConverter-492"><a href="#ONNXConverter-492"><span class="linenos"> 492</span></a>        <span class="n">ratio_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">input_ratio</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-493"><a href="#ONNXConverter-493"><span class="linenos"> 493</span></a>                                                              <span class="n">ratio_size</span><span class="p">)</span>
</span><span id="ONNXConverter-494"><a href="#ONNXConverter-494"><span class="linenos"> 494</span></a>
</span><span id="ONNXConverter-495"><a href="#ONNXConverter-495"><span class="linenos"> 495</span></a>        <span class="n">ratio_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">current_node</span><span class="o">.</span><span class="n">p</span><span class="p">]),</span> <span class="n">input_ratio</span><span class="p">)</span>
</span><span id="ONNXConverter-496"><a href="#ONNXConverter-496"><span class="linenos"> 496</span></a>
</span><span id="ONNXConverter-497"><a href="#ONNXConverter-497"><span class="linenos"> 497</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-498"><a href="#ONNXConverter-498"><span class="linenos"> 498</span></a>            <span class="s1">&#39;Dropout&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-499"><a href="#ONNXConverter-499"><span class="linenos"> 499</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">,</span> <span class="n">input_ratio</span><span class="p">],</span>
</span><span id="ONNXConverter-500"><a href="#ONNXConverter-500"><span class="linenos"> 500</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">]</span>
</span><span id="ONNXConverter-501"><a href="#ONNXConverter-501"><span class="linenos"> 501</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-502"><a href="#ONNXConverter-502"><span class="linenos"> 502</span></a>
</span><span id="ONNXConverter-503"><a href="#ONNXConverter-503"><span class="linenos"> 503</span></a>        <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-504"><a href="#ONNXConverter-504"><span class="linenos"> 504</span></a>        <span class="n">initializers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio_tensor</span><span class="p">)</span>
</span><span id="ONNXConverter-505"><a href="#ONNXConverter-505"><span class="linenos"> 505</span></a>
</span><span id="ONNXConverter-506"><a href="#ONNXConverter-506"><span class="linenos"> 506</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-507"><a href="#ONNXConverter-507"><span class="linenos"> 507</span></a>
</span><span id="ONNXConverter-508"><a href="#ONNXConverter-508"><span class="linenos"> 508</span></a>    <span class="nd">@staticmethod</span>
</span><span id="ONNXConverter-509"><a href="#ONNXConverter-509"><span class="linenos"> 509</span></a>    <span class="k">def</span> <span class="nf">__add_onnx_transpose</span><span class="p">(</span><span class="n">current_node</span><span class="p">:</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">,</span> <span class="n">current_input</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">current_output</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="ONNXConverter-510"><a href="#ONNXConverter-510"><span class="linenos"> 510</span></a>                             <span class="n">onnx_nodes</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ONNXConverter-511"><a href="#ONNXConverter-511"><span class="linenos"> 511</span></a>
</span><span id="ONNXConverter-512"><a href="#ONNXConverter-512"><span class="linenos"> 512</span></a>        <span class="c1"># Since our representation do not consider the batch dimension we need to scale the perm by 1</span>
</span><span id="ONNXConverter-513"><a href="#ONNXConverter-513"><span class="linenos"> 513</span></a>        <span class="c1"># and add the 0 dimension when we pass to the onnx representation.</span>
</span><span id="ONNXConverter-514"><a href="#ONNXConverter-514"><span class="linenos"> 514</span></a>        <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter-515"><a href="#ONNXConverter-515"><span class="linenos"> 515</span></a>        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">perm</span><span class="p">:</span>
</span><span id="ONNXConverter-516"><a href="#ONNXConverter-516"><span class="linenos"> 516</span></a>            <span class="n">perm</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="ONNXConverter-517"><a href="#ONNXConverter-517"><span class="linenos"> 517</span></a>
</span><span id="ONNXConverter-518"><a href="#ONNXConverter-518"><span class="linenos"> 518</span></a>        <span class="n">onnx_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
</span><span id="ONNXConverter-519"><a href="#ONNXConverter-519"><span class="linenos"> 519</span></a>            <span class="s1">&#39;Transpose&#39;</span><span class="p">,</span>
</span><span id="ONNXConverter-520"><a href="#ONNXConverter-520"><span class="linenos"> 520</span></a>            <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_input</span><span class="p">],</span>
</span><span id="ONNXConverter-521"><a href="#ONNXConverter-521"><span class="linenos"> 521</span></a>            <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">current_output</span><span class="p">],</span>
</span><span id="ONNXConverter-522"><a href="#ONNXConverter-522"><span class="linenos"> 522</span></a>            <span class="n">perm</span><span class="o">=</span><span class="n">perm</span>
</span><span id="ONNXConverter-523"><a href="#ONNXConverter-523"><span class="linenos"> 523</span></a>        <span class="p">)</span>
</span><span id="ONNXConverter-524"><a href="#ONNXConverter-524"><span class="linenos"> 524</span></a>
</span><span id="ONNXConverter-525"><a href="#ONNXConverter-525"><span class="linenos"> 525</span></a>        <span class="n">onnx_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx_node</span><span class="p">)</span>
</span><span id="ONNXConverter-526"><a href="#ONNXConverter-526"><span class="linenos"> 526</span></a>
</span><span id="ONNXConverter-527"><a href="#ONNXConverter-527"><span class="linenos"> 527</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ONNXNetwork</span><span class="p">:</span>
</span><span id="ONNXConverter-528"><a href="#ONNXConverter-528"><span class="linenos"> 528</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXConverter-529"><a href="#ONNXConverter-529"><span class="linenos"> 529</span></a><span class="sd">        Convert the neural network of interest to a ONNX representation.</span>
</span><span id="ONNXConverter-530"><a href="#ONNXConverter-530"><span class="linenos"> 530</span></a>
</span><span id="ONNXConverter-531"><a href="#ONNXConverter-531"><span class="linenos"> 531</span></a><span class="sd">        Parameters</span>
</span><span id="ONNXConverter-532"><a href="#ONNXConverter-532"><span class="linenos"> 532</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter-533"><a href="#ONNXConverter-533"><span class="linenos"> 533</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="ONNXConverter-534"><a href="#ONNXConverter-534"><span class="linenos"> 534</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="ONNXConverter-535"><a href="#ONNXConverter-535"><span class="linenos"> 535</span></a>
</span><span id="ONNXConverter-536"><a href="#ONNXConverter-536"><span class="linenos"> 536</span></a><span class="sd">        Returns</span>
</span><span id="ONNXConverter-537"><a href="#ONNXConverter-537"><span class="linenos"> 537</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter-538"><a href="#ONNXConverter-538"><span class="linenos"> 538</span></a><span class="sd">        ONNXNetwork</span>
</span><span id="ONNXConverter-539"><a href="#ONNXConverter-539"><span class="linenos"> 539</span></a><span class="sd">            The ONNX representation resulting from the conversion of the original network.</span>
</span><span id="ONNXConverter-540"><a href="#ONNXConverter-540"><span class="linenos"> 540</span></a>
</span><span id="ONNXConverter-541"><a href="#ONNXConverter-541"><span class="linenos"> 541</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ONNXConverter-542"><a href="#ONNXConverter-542"><span class="linenos"> 542</span></a>
</span><span id="ONNXConverter-543"><a href="#ONNXConverter-543"><span class="linenos"> 543</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-544"><a href="#ONNXConverter-544"><span class="linenos"> 544</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="ONNXConverter-545"><a href="#ONNXConverter-545"><span class="linenos"> 545</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter-546"><a href="#ONNXConverter-546"><span class="linenos"> 546</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="ONNXConverter-547"><a href="#ONNXConverter-547"><span class="linenos"> 547</span></a>
</span><span id="ONNXConverter-548"><a href="#ONNXConverter-548"><span class="linenos"> 548</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXConverter-549"><a href="#ONNXConverter-549"><span class="linenos"> 549</span></a>
</span><span id="ONNXConverter-550"><a href="#ONNXConverter-550"><span class="linenos"> 550</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter-551"><a href="#ONNXConverter-551"><span class="linenos"> 551</span></a>
</span><span id="ONNXConverter-552"><a href="#ONNXConverter-552"><span class="linenos"> 552</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="ONNXConverter-553"><a href="#ONNXConverter-553"><span class="linenos"> 553</span></a>
</span><span id="ONNXConverter-554"><a href="#ONNXConverter-554"><span class="linenos"> 554</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter-555"><a href="#ONNXConverter-555"><span class="linenos"> 555</span></a>
</span><span id="ONNXConverter-556"><a href="#ONNXConverter-556"><span class="linenos"> 556</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">):</span>
</span><span id="ONNXConverter-557"><a href="#ONNXConverter-557"><span class="linenos"> 557</span></a>                            <span class="n">pytorch_cv</span> <span class="o">=</span> <span class="n">PyTorchConverter</span><span class="p">()</span>
</span><span id="ONNXConverter-558"><a href="#ONNXConverter-558"><span class="linenos"> 558</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">pytorch_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="ONNXConverter-559"><a href="#ONNXConverter-559"><span class="linenos"> 559</span></a>
</span><span id="ONNXConverter-560"><a href="#ONNXConverter-560"><span class="linenos"> 560</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-561"><a href="#ONNXConverter-561"><span class="linenos"> 561</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter-562"><a href="#ONNXConverter-562"><span class="linenos"> 562</span></a>                        <span class="k">break</span>
</span><span id="ONNXConverter-563"><a href="#ONNXConverter-563"><span class="linenos"> 563</span></a>
</span><span id="ONNXConverter-564"><a href="#ONNXConverter-564"><span class="linenos"> 564</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="ONNXConverter-565"><a href="#ONNXConverter-565"><span class="linenos"> 565</span></a>
</span><span id="ONNXConverter-566"><a href="#ONNXConverter-566"><span class="linenos"> 566</span></a>                <span class="n">current_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-567"><a href="#ONNXConverter-567"><span class="linenos"> 567</span></a>                <span class="n">previous_output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="ONNXConverter-568"><a href="#ONNXConverter-568"><span class="linenos"> 568</span></a>                <span class="n">input_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter-569"><a href="#ONNXConverter-569"><span class="linenos"> 569</span></a>                <span class="n">output_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter-570"><a href="#ONNXConverter-570"><span class="linenos"> 570</span></a>                <span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter-571"><a href="#ONNXConverter-571"><span class="linenos"> 571</span></a>                <span class="n">onnx_nodes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter-572"><a href="#ONNXConverter-572"><span class="linenos"> 572</span></a>
</span><span id="ONNXConverter-573"><a href="#ONNXConverter-573"><span class="linenos"> 573</span></a>                <span class="k">while</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXConverter-574"><a href="#ONNXConverter-574"><span class="linenos"> 574</span></a>
</span><span id="ONNXConverter-575"><a href="#ONNXConverter-575"><span class="linenos"> 575</span></a>                    <span class="n">current_node</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span>
</span><span id="ONNXConverter-576"><a href="#ONNXConverter-576"><span class="linenos"> 576</span></a>                    <span class="n">current_input</span> <span class="o">=</span> <span class="n">previous_output</span>
</span><span id="ONNXConverter-577"><a href="#ONNXConverter-577"><span class="linenos"> 577</span></a>                    <span class="n">current_output</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="ONNXConverter-578"><a href="#ONNXConverter-578"><span class="linenos"> 578</span></a>
</span><span id="ONNXConverter-579"><a href="#ONNXConverter-579"><span class="linenos"> 579</span></a>                    <span class="n">input_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter-580"><a href="#ONNXConverter-580"><span class="linenos"> 580</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">in_dim</span><span class="p">:</span>
</span><span id="ONNXConverter-581"><a href="#ONNXConverter-581"><span class="linenos"> 581</span></a>                        <span class="n">input_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="ONNXConverter-582"><a href="#ONNXConverter-582"><span class="linenos"> 582</span></a>
</span><span id="ONNXConverter-583"><a href="#ONNXConverter-583"><span class="linenos"> 583</span></a>                    <span class="n">output_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter-584"><a href="#ONNXConverter-584"><span class="linenos"> 584</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">out_dim</span><span class="p">:</span>
</span><span id="ONNXConverter-585"><a href="#ONNXConverter-585"><span class="linenos"> 585</span></a>                        <span class="n">output_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="ONNXConverter-586"><a href="#ONNXConverter-586"><span class="linenos"> 586</span></a>
</span><span id="ONNXConverter-587"><a href="#ONNXConverter-587"><span class="linenos"> 587</span></a>                    <span class="n">input_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-588"><a href="#ONNXConverter-588"><span class="linenos"> 588</span></a>                                                                          <span class="n">input_dim</span><span class="p">)</span>
</span><span id="ONNXConverter-589"><a href="#ONNXConverter-589"><span class="linenos"> 589</span></a>                    <span class="n">output_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_output</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter-590"><a href="#ONNXConverter-590"><span class="linenos"> 590</span></a>                                                                           <span class="n">output_dim</span><span class="p">)</span>
</span><span id="ONNXConverter-591"><a href="#ONNXConverter-591"><span class="linenos"> 591</span></a>
</span><span id="ONNXConverter-592"><a href="#ONNXConverter-592"><span class="linenos"> 592</span></a>                    <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-593"><a href="#ONNXConverter-593"><span class="linenos"> 593</span></a>                    <span class="n">output_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter-594"><a href="#ONNXConverter-594"><span class="linenos"> 594</span></a>
</span><span id="ONNXConverter-595"><a href="#ONNXConverter-595"><span class="linenos"> 595</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="ONNXConverter-596"><a href="#ONNXConverter-596"><span class="linenos"> 596</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_relu</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-597"><a href="#ONNXConverter-597"><span class="linenos"> 597</span></a>
</span><span id="ONNXConverter-598"><a href="#ONNXConverter-598"><span class="linenos"> 598</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="ONNXConverter-599"><a href="#ONNXConverter-599"><span class="linenos"> 599</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_elu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-600"><a href="#ONNXConverter-600"><span class="linenos"> 600</span></a>
</span><span id="ONNXConverter-601"><a href="#ONNXConverter-601"><span class="linenos"> 601</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="ONNXConverter-602"><a href="#ONNXConverter-602"><span class="linenos"> 602</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_leakyrelu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-603"><a href="#ONNXConverter-603"><span class="linenos"> 603</span></a>
</span><span id="ONNXConverter-604"><a href="#ONNXConverter-604"><span class="linenos"> 604</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="ONNXConverter-605"><a href="#ONNXConverter-605"><span class="linenos"> 605</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_celu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-606"><a href="#ONNXConverter-606"><span class="linenos"> 606</span></a>
</span><span id="ONNXConverter-607"><a href="#ONNXConverter-607"><span class="linenos"> 607</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="ONNXConverter-608"><a href="#ONNXConverter-608"><span class="linenos"> 608</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_sigmoid</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-609"><a href="#ONNXConverter-609"><span class="linenos"> 609</span></a>
</span><span id="ONNXConverter-610"><a href="#ONNXConverter-610"><span class="linenos"> 610</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="ONNXConverter-611"><a href="#ONNXConverter-611"><span class="linenos"> 611</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_tanh</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-612"><a href="#ONNXConverter-612"><span class="linenos"> 612</span></a>
</span><span id="ONNXConverter-613"><a href="#ONNXConverter-613"><span class="linenos"> 613</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="ONNXConverter-614"><a href="#ONNXConverter-614"><span class="linenos"> 614</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_linear</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-615"><a href="#ONNXConverter-615"><span class="linenos"> 615</span></a>                                               <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-616"><a href="#ONNXConverter-616"><span class="linenos"> 616</span></a>
</span><span id="ONNXConverter-617"><a href="#ONNXConverter-617"><span class="linenos"> 617</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="ONNXConverter-618"><a href="#ONNXConverter-618"><span class="linenos"> 618</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_batchnorm</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-619"><a href="#ONNXConverter-619"><span class="linenos"> 619</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-620"><a href="#ONNXConverter-620"><span class="linenos"> 620</span></a>
</span><span id="ONNXConverter-621"><a href="#ONNXConverter-621"><span class="linenos"> 621</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="ONNXConverter-622"><a href="#ONNXConverter-622"><span class="linenos"> 622</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_conv</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-623"><a href="#ONNXConverter-623"><span class="linenos"> 623</span></a>                                             <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-624"><a href="#ONNXConverter-624"><span class="linenos"> 624</span></a>
</span><span id="ONNXConverter-625"><a href="#ONNXConverter-625"><span class="linenos"> 625</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="ONNXConverter-626"><a href="#ONNXConverter-626"><span class="linenos"> 626</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_averagepool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-627"><a href="#ONNXConverter-627"><span class="linenos"> 627</span></a>
</span><span id="ONNXConverter-628"><a href="#ONNXConverter-628"><span class="linenos"> 628</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="ONNXConverter-629"><a href="#ONNXConverter-629"><span class="linenos"> 629</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_maxpool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-630"><a href="#ONNXConverter-630"><span class="linenos"> 630</span></a>
</span><span id="ONNXConverter-631"><a href="#ONNXConverter-631"><span class="linenos"> 631</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="ONNXConverter-632"><a href="#ONNXConverter-632"><span class="linenos"> 632</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_lrn</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-633"><a href="#ONNXConverter-633"><span class="linenos"> 633</span></a>
</span><span id="ONNXConverter-634"><a href="#ONNXConverter-634"><span class="linenos"> 634</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="ONNXConverter-635"><a href="#ONNXConverter-635"><span class="linenos"> 635</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_softmax</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-636"><a href="#ONNXConverter-636"><span class="linenos"> 636</span></a>
</span><span id="ONNXConverter-637"><a href="#ONNXConverter-637"><span class="linenos"> 637</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="ONNXConverter-638"><a href="#ONNXConverter-638"><span class="linenos"> 638</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_unsqueeze</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-639"><a href="#ONNXConverter-639"><span class="linenos"> 639</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-640"><a href="#ONNXConverter-640"><span class="linenos"> 640</span></a>
</span><span id="ONNXConverter-641"><a href="#ONNXConverter-641"><span class="linenos"> 641</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="ONNXConverter-642"><a href="#ONNXConverter-642"><span class="linenos"> 642</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_reshape</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-643"><a href="#ONNXConverter-643"><span class="linenos"> 643</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-644"><a href="#ONNXConverter-644"><span class="linenos"> 644</span></a>
</span><span id="ONNXConverter-645"><a href="#ONNXConverter-645"><span class="linenos"> 645</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="ONNXConverter-646"><a href="#ONNXConverter-646"><span class="linenos"> 646</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_flatten</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter-647"><a href="#ONNXConverter-647"><span class="linenos"> 647</span></a>
</span><span id="ONNXConverter-648"><a href="#ONNXConverter-648"><span class="linenos"> 648</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="ONNXConverter-649"><a href="#ONNXConverter-649"><span class="linenos"> 649</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_dropout</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-650"><a href="#ONNXConverter-650"><span class="linenos"> 650</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-651"><a href="#ONNXConverter-651"><span class="linenos"> 651</span></a>
</span><span id="ONNXConverter-652"><a href="#ONNXConverter-652"><span class="linenos"> 652</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">):</span>
</span><span id="ONNXConverter-653"><a href="#ONNXConverter-653"><span class="linenos"> 653</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_transpose</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter-654"><a href="#ONNXConverter-654"><span class="linenos"> 654</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter-655"><a href="#ONNXConverter-655"><span class="linenos"> 655</span></a>
</span><span id="ONNXConverter-656"><a href="#ONNXConverter-656"><span class="linenos"> 656</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-657"><a href="#ONNXConverter-657"><span class="linenos"> 657</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter-658"><a href="#ONNXConverter-658"><span class="linenos"> 658</span></a>
</span><span id="ONNXConverter-659"><a href="#ONNXConverter-659"><span class="linenos"> 659</span></a>                    <span class="n">previous_output</span> <span class="o">=</span> <span class="n">current_output</span>
</span><span id="ONNXConverter-660"><a href="#ONNXConverter-660"><span class="linenos"> 660</span></a>
</span><span id="ONNXConverter-661"><a href="#ONNXConverter-661"><span class="linenos"> 661</span></a>                <span class="n">onnx_graph</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
</span><span id="ONNXConverter-662"><a href="#ONNXConverter-662"><span class="linenos"> 662</span></a>                    <span class="n">nodes</span><span class="o">=</span><span class="n">onnx_nodes</span><span class="p">,</span>
</span><span id="ONNXConverter-663"><a href="#ONNXConverter-663"><span class="linenos"> 663</span></a>                    <span class="n">name</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span>
</span><span id="ONNXConverter-664"><a href="#ONNXConverter-664"><span class="linenos"> 664</span></a>                    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
</span><span id="ONNXConverter-665"><a href="#ONNXConverter-665"><span class="linenos"> 665</span></a>                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output_info</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
</span><span id="ONNXConverter-666"><a href="#ONNXConverter-666"><span class="linenos"> 666</span></a>                    <span class="n">initializer</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
</span><span id="ONNXConverter-667"><a href="#ONNXConverter-667"><span class="linenos"> 667</span></a>                    <span class="n">value_info</span><span class="o">=</span><span class="n">input_info</span>
</span><span id="ONNXConverter-668"><a href="#ONNXConverter-668"><span class="linenos"> 668</span></a>                <span class="p">)</span>
</span><span id="ONNXConverter-669"><a href="#ONNXConverter-669"><span class="linenos"> 669</span></a>
</span><span id="ONNXConverter-670"><a href="#ONNXConverter-670"><span class="linenos"> 670</span></a>                <span class="n">onnx_network</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">onnx_graph</span><span class="p">)</span>
</span><span id="ONNXConverter-671"><a href="#ONNXConverter-671"><span class="linenos"> 671</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">ONNXNetwork</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">)</span>
</span><span id="ONNXConverter-672"><a href="#ONNXConverter-672"><span class="linenos"> 672</span></a>
</span><span id="ONNXConverter-673"><a href="#ONNXConverter-673"><span class="linenos"> 673</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-674"><a href="#ONNXConverter-674"><span class="linenos"> 674</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter-675"><a href="#ONNXConverter-675"><span class="linenos"> 675</span></a>
</span><span id="ONNXConverter-676"><a href="#ONNXConverter-676"><span class="linenos"> 676</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span><span id="ONNXConverter-677"><a href="#ONNXConverter-677"><span class="linenos"> 677</span></a>
</span><span id="ONNXConverter-678"><a href="#ONNXConverter-678"><span class="linenos"> 678</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="ONNXConverter-679"><a href="#ONNXConverter-679"><span class="linenos"> 679</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXConverter-680"><a href="#ONNXConverter-680"><span class="linenos"> 680</span></a><span class="sd">        Convert the ONNX representation of interest to the internal one.</span>
</span><span id="ONNXConverter-681"><a href="#ONNXConverter-681"><span class="linenos"> 681</span></a>
</span><span id="ONNXConverter-682"><a href="#ONNXConverter-682"><span class="linenos"> 682</span></a><span class="sd">        Parameters</span>
</span><span id="ONNXConverter-683"><a href="#ONNXConverter-683"><span class="linenos"> 683</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter-684"><a href="#ONNXConverter-684"><span class="linenos"> 684</span></a><span class="sd">        alt_rep : ONNXNetwork</span>
</span><span id="ONNXConverter-685"><a href="#ONNXConverter-685"><span class="linenos"> 685</span></a><span class="sd">            The ONNX Representation to convert.</span>
</span><span id="ONNXConverter-686"><a href="#ONNXConverter-686"><span class="linenos"> 686</span></a>
</span><span id="ONNXConverter-687"><a href="#ONNXConverter-687"><span class="linenos"> 687</span></a><span class="sd">        Returns</span>
</span><span id="ONNXConverter-688"><a href="#ONNXConverter-688"><span class="linenos"> 688</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter-689"><a href="#ONNXConverter-689"><span class="linenos"> 689</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="ONNXConverter-690"><a href="#ONNXConverter-690"><span class="linenos"> 690</span></a><span class="sd">            The Neural Network resulting from the conversion of ONNX Representation.</span>
</span><span id="ONNXConverter-691"><a href="#ONNXConverter-691"><span class="linenos"> 691</span></a>
</span><span id="ONNXConverter-692"><a href="#ONNXConverter-692"><span class="linenos"> 692</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ONNXConverter-693"><a href="#ONNXConverter-693"><span class="linenos"> 693</span></a>
</span><span id="ONNXConverter-694"><a href="#ONNXConverter-694"><span class="linenos"> 694</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="ONNXConverter-695"><a href="#ONNXConverter-695"><span class="linenos"> 695</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</span><span id="ONNXConverter-696"><a href="#ONNXConverter-696"><span class="linenos"> 696</span></a>
</span><span id="ONNXConverter-697"><a href="#ONNXConverter-697"><span class="linenos"> 697</span></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="ONNXConverter-698"><a href="#ONNXConverter-698"><span class="linenos"> 698</span></a>        <span class="k">for</span> <span class="n">initializer</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">:</span>
</span><span id="ONNXConverter-699"><a href="#ONNXConverter-699"><span class="linenos"> 699</span></a>            <span class="n">parameters</span><span class="p">[</span><span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
</span><span id="ONNXConverter-700"><a href="#ONNXConverter-700"><span class="linenos"> 700</span></a>
</span><span id="ONNXConverter-701"><a href="#ONNXConverter-701"><span class="linenos"> 701</span></a>        <span class="n">shape_info</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="ONNXConverter-702"><a href="#ONNXConverter-702"><span class="linenos"> 702</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
</span><span id="ONNXConverter-703"><a href="#ONNXConverter-703"><span class="linenos"> 703</span></a>            <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter-704"><a href="#ONNXConverter-704"><span class="linenos"> 704</span></a>            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">i</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
</span><span id="ONNXConverter-705"><a href="#ONNXConverter-705"><span class="linenos"> 705</span></a>                <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dim</span><span class="o">.</span><span class="n">dim_value</span><span class="p">)</span>
</span><span id="ONNXConverter-706"><a href="#ONNXConverter-706"><span class="linenos"> 706</span></a>            <span class="n">shape_info</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="ONNXConverter-707"><a href="#ONNXConverter-707"><span class="linenos"> 707</span></a>
</span><span id="ONNXConverter-708"><a href="#ONNXConverter-708"><span class="linenos"> 708</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="ONNXConverter-709"><a href="#ONNXConverter-709"><span class="linenos"> 709</span></a>        <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
</span><span id="ONNXConverter-710"><a href="#ONNXConverter-710"><span class="linenos"> 710</span></a>        <span class="k">if</span> <span class="n">in_dim</span> <span class="o">==</span> <span class="p">():</span>
</span><span id="ONNXConverter-711"><a href="#ONNXConverter-711"><span class="linenos"> 711</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
</span><span id="ONNXConverter-712"><a href="#ONNXConverter-712"><span class="linenos"> 712</span></a>
</span><span id="ONNXConverter-713"><a href="#ONNXConverter-713"><span class="linenos"> 713</span></a>        <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-714"><a href="#ONNXConverter-714"><span class="linenos"> 714</span></a>        <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-715"><a href="#ONNXConverter-715"><span class="linenos"> 715</span></a>
</span><span id="ONNXConverter-716"><a href="#ONNXConverter-716"><span class="linenos"> 716</span></a>        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
</span><span id="ONNXConverter-717"><a href="#ONNXConverter-717"><span class="linenos"> 717</span></a>
</span><span id="ONNXConverter-718"><a href="#ONNXConverter-718"><span class="linenos"> 718</span></a>            <span class="k">if</span> <span class="n">matmul_found</span><span class="p">:</span>
</span><span id="ONNXConverter-719"><a href="#ONNXConverter-719"><span class="linenos"> 719</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Add&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-720"><a href="#ONNXConverter-720"><span class="linenos"> 720</span></a>
</span><span id="ONNXConverter-721"><a href="#ONNXConverter-721"><span class="linenos"> 721</span></a>                    <span class="c1"># We assume that the bias is always the second element of node.input</span>
</span><span id="ONNXConverter-722"><a href="#ONNXConverter-722"><span class="linenos"> 722</span></a>
</span><span id="ONNXConverter-723"><a href="#ONNXConverter-723"><span class="linenos"> 723</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter-724"><a href="#ONNXConverter-724"><span class="linenos"> 724</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter-725"><a href="#ONNXConverter-725"><span class="linenos"> 725</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
</span><span id="ONNXConverter-726"><a href="#ONNXConverter-726"><span class="linenos"> 726</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-727"><a href="#ONNXConverter-727"><span class="linenos"> 727</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-728"><a href="#ONNXConverter-728"><span class="linenos"> 728</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter-729"><a href="#ONNXConverter-729"><span class="linenos"> 729</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter-730"><a href="#ONNXConverter-730"><span class="linenos"> 730</span></a>                    <span class="k">continue</span>
</span><span id="ONNXConverter-731"><a href="#ONNXConverter-731"><span class="linenos"> 731</span></a>
</span><span id="ONNXConverter-732"><a href="#ONNXConverter-732"><span class="linenos"> 732</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-733"><a href="#ONNXConverter-733"><span class="linenos"> 733</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter-734"><a href="#ONNXConverter-734"><span class="linenos"> 734</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</span><span id="ONNXConverter-735"><a href="#ONNXConverter-735"><span class="linenos"> 735</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-736"><a href="#ONNXConverter-736"><span class="linenos"> 736</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-737"><a href="#ONNXConverter-737"><span class="linenos"> 737</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter-738"><a href="#ONNXConverter-738"><span class="linenos"> 738</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter-739"><a href="#ONNXConverter-739"><span class="linenos"> 739</span></a>
</span><span id="ONNXConverter-740"><a href="#ONNXConverter-740"><span class="linenos"> 740</span></a>            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-741"><a href="#ONNXConverter-741"><span class="linenos"> 741</span></a>
</span><span id="ONNXConverter-742"><a href="#ONNXConverter-742"><span class="linenos"> 742</span></a>                <span class="c1"># If the weight is the second parameter we need to transpose it</span>
</span><span id="ONNXConverter-743"><a href="#ONNXConverter-743"><span class="linenos"> 743</span></a>
</span><span id="ONNXConverter-744"><a href="#ONNXConverter-744"><span class="linenos"> 744</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="ONNXConverter-745"><a href="#ONNXConverter-745"><span class="linenos"> 745</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span><span id="ONNXConverter-746"><a href="#ONNXConverter-746"><span class="linenos"> 746</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-747"><a href="#ONNXConverter-747"><span class="linenos"> 747</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="ONNXConverter-748"><a href="#ONNXConverter-748"><span class="linenos"> 748</span></a>
</span><span id="ONNXConverter-749"><a href="#ONNXConverter-749"><span class="linenos"> 749</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter-750"><a href="#ONNXConverter-750"><span class="linenos"> 750</span></a>                <span class="n">temp_fc</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="ONNXConverter-751"><a href="#ONNXConverter-751"><span class="linenos"> 751</span></a>                <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter-752"><a href="#ONNXConverter-752"><span class="linenos"> 752</span></a>                <span class="k">continue</span>
</span><span id="ONNXConverter-753"><a href="#ONNXConverter-753"><span class="linenos"> 753</span></a>
</span><span id="ONNXConverter-754"><a href="#ONNXConverter-754"><span class="linenos"> 754</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Relu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-755"><a href="#ONNXConverter-755"><span class="linenos"> 755</span></a>
</span><span id="ONNXConverter-756"><a href="#ONNXConverter-756"><span class="linenos"> 756</span></a>                <span class="c1"># We assume that the real input of the node is always the first element of node.input</span>
</span><span id="ONNXConverter-757"><a href="#ONNXConverter-757"><span class="linenos"> 757</span></a>                <span class="c1"># and the first element of the shape is the batch placeholder</span>
</span><span id="ONNXConverter-758"><a href="#ONNXConverter-758"><span class="linenos"> 758</span></a>
</span><span id="ONNXConverter-759"><a href="#ONNXConverter-759"><span class="linenos"> 759</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter-760"><a href="#ONNXConverter-760"><span class="linenos"> 760</span></a>
</span><span id="ONNXConverter-761"><a href="#ONNXConverter-761"><span class="linenos"> 761</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Elu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-762"><a href="#ONNXConverter-762"><span class="linenos"> 762</span></a>
</span><span id="ONNXConverter-763"><a href="#ONNXConverter-763"><span class="linenos"> 763</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter-764"><a href="#ONNXConverter-764"><span class="linenos"> 764</span></a>
</span><span id="ONNXConverter-765"><a href="#ONNXConverter-765"><span class="linenos"> 765</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-766"><a href="#ONNXConverter-766"><span class="linenos"> 766</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-767"><a href="#ONNXConverter-767"><span class="linenos"> 767</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-768"><a href="#ONNXConverter-768"><span class="linenos"> 768</span></a>
</span><span id="ONNXConverter-769"><a href="#ONNXConverter-769"><span class="linenos"> 769</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="ONNXConverter-770"><a href="#ONNXConverter-770"><span class="linenos"> 770</span></a>
</span><span id="ONNXConverter-771"><a href="#ONNXConverter-771"><span class="linenos"> 771</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LeakyRelu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-772"><a href="#ONNXConverter-772"><span class="linenos"> 772</span></a>
</span><span id="ONNXConverter-773"><a href="#ONNXConverter-773"><span class="linenos"> 773</span></a>                <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter-774"><a href="#ONNXConverter-774"><span class="linenos"> 774</span></a>
</span><span id="ONNXConverter-775"><a href="#ONNXConverter-775"><span class="linenos"> 775</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-776"><a href="#ONNXConverter-776"><span class="linenos"> 776</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-777"><a href="#ONNXConverter-777"><span class="linenos"> 777</span></a>                        <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-778"><a href="#ONNXConverter-778"><span class="linenos"> 778</span></a>
</span><span id="ONNXConverter-779"><a href="#ONNXConverter-779"><span class="linenos"> 779</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">))</span>
</span><span id="ONNXConverter-780"><a href="#ONNXConverter-780"><span class="linenos"> 780</span></a>
</span><span id="ONNXConverter-781"><a href="#ONNXConverter-781"><span class="linenos"> 781</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Celu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-782"><a href="#ONNXConverter-782"><span class="linenos"> 782</span></a>
</span><span id="ONNXConverter-783"><a href="#ONNXConverter-783"><span class="linenos"> 783</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter-784"><a href="#ONNXConverter-784"><span class="linenos"> 784</span></a>
</span><span id="ONNXConverter-785"><a href="#ONNXConverter-785"><span class="linenos"> 785</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-786"><a href="#ONNXConverter-786"><span class="linenos"> 786</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-787"><a href="#ONNXConverter-787"><span class="linenos"> 787</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-788"><a href="#ONNXConverter-788"><span class="linenos"> 788</span></a>
</span><span id="ONNXConverter-789"><a href="#ONNXConverter-789"><span class="linenos"> 789</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="ONNXConverter-790"><a href="#ONNXConverter-790"><span class="linenos"> 790</span></a>
</span><span id="ONNXConverter-791"><a href="#ONNXConverter-791"><span class="linenos"> 791</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-792"><a href="#ONNXConverter-792"><span class="linenos"> 792</span></a>
</span><span id="ONNXConverter-793"><a href="#ONNXConverter-793"><span class="linenos"> 793</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter-794"><a href="#ONNXConverter-794"><span class="linenos"> 794</span></a>
</span><span id="ONNXConverter-795"><a href="#ONNXConverter-795"><span class="linenos"> 795</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Tanh&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-796"><a href="#ONNXConverter-796"><span class="linenos"> 796</span></a>
</span><span id="ONNXConverter-797"><a href="#ONNXConverter-797"><span class="linenos"> 797</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter-798"><a href="#ONNXConverter-798"><span class="linenos"> 798</span></a>
</span><span id="ONNXConverter-799"><a href="#ONNXConverter-799"><span class="linenos"> 799</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Gemm&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-800"><a href="#ONNXConverter-800"><span class="linenos"> 800</span></a>                <span class="c1"># We assume that the weight tensor is always the second element of node.input and the bias tensor</span>
</span><span id="ONNXConverter-801"><a href="#ONNXConverter-801"><span class="linenos"> 801</span></a>                <span class="c1"># is always the third.</span>
</span><span id="ONNXConverter-802"><a href="#ONNXConverter-802"><span class="linenos"> 802</span></a>                <span class="c1"># N.B: We do not support the attributes transA and transB,</span>
</span><span id="ONNXConverter-803"><a href="#ONNXConverter-803"><span class="linenos"> 803</span></a>                <span class="c1"># therefore we need to transpose the weight vector.</span>
</span><span id="ONNXConverter-804"><a href="#ONNXConverter-804"><span class="linenos"> 804</span></a>                <span class="c1"># TODO: Can we support transA and transB in some way?</span>
</span><span id="ONNXConverter-805"><a href="#ONNXConverter-805"><span class="linenos"> 805</span></a>
</span><span id="ONNXConverter-806"><a href="#ONNXConverter-806"><span class="linenos"> 806</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-807"><a href="#ONNXConverter-807"><span class="linenos"> 807</span></a>                    <span class="k">if</span> <span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transA&#39;</span> <span class="ow">or</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transB&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ONNXConverter-808"><a href="#ONNXConverter-808"><span class="linenos"> 808</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="ONNXConverter-809"><a href="#ONNXConverter-809"><span class="linenos"> 809</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-810"><a href="#ONNXConverter-810"><span class="linenos"> 810</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter-811"><a href="#ONNXConverter-811"><span class="linenos"> 811</span></a>
</span><span id="ONNXConverter-812"><a href="#ONNXConverter-812"><span class="linenos"> 812</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="ONNXConverter-813"><a href="#ONNXConverter-813"><span class="linenos"> 813</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-814"><a href="#ONNXConverter-814"><span class="linenos"> 814</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-815"><a href="#ONNXConverter-815"><span class="linenos"> 815</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-816"><a href="#ONNXConverter-816"><span class="linenos"> 816</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter-817"><a href="#ONNXConverter-817"><span class="linenos"> 817</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter-818"><a href="#ONNXConverter-818"><span class="linenos"> 818</span></a>
</span><span id="ONNXConverter-819"><a href="#ONNXConverter-819"><span class="linenos"> 819</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter-820"><a href="#ONNXConverter-820"><span class="linenos"> 820</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter-821"><a href="#ONNXConverter-821"><span class="linenos"> 821</span></a>                                                          <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">))</span>
</span><span id="ONNXConverter-822"><a href="#ONNXConverter-822"><span class="linenos"> 822</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;BatchNormalization&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-823"><a href="#ONNXConverter-823"><span class="linenos"> 823</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="ONNXConverter-824"><a href="#ONNXConverter-824"><span class="linenos"> 824</span></a>                <span class="c1"># is always the second, the bias tensor is always the third, the running_mean always the fourth</span>
</span><span id="ONNXConverter-825"><a href="#ONNXConverter-825"><span class="linenos"> 825</span></a>                <span class="c1"># and the running_var always the fifth.</span>
</span><span id="ONNXConverter-826"><a href="#ONNXConverter-826"><span class="linenos"> 826</span></a>
</span><span id="ONNXConverter-827"><a href="#ONNXConverter-827"><span class="linenos"> 827</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter-828"><a href="#ONNXConverter-828"><span class="linenos"> 828</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter-829"><a href="#ONNXConverter-829"><span class="linenos"> 829</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
</span><span id="ONNXConverter-830"><a href="#ONNXConverter-830"><span class="linenos"> 830</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">4</span><span class="p">]]</span>
</span><span id="ONNXConverter-831"><a href="#ONNXConverter-831"><span class="linenos"> 831</span></a>
</span><span id="ONNXConverter-832"><a href="#ONNXConverter-832"><span class="linenos"> 832</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-05</span>
</span><span id="ONNXConverter-833"><a href="#ONNXConverter-833"><span class="linenos"> 833</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="ONNXConverter-834"><a href="#ONNXConverter-834"><span class="linenos"> 834</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-835"><a href="#ONNXConverter-835"><span class="linenos"> 835</span></a>
</span><span id="ONNXConverter-836"><a href="#ONNXConverter-836"><span class="linenos"> 836</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-837"><a href="#ONNXConverter-837"><span class="linenos"> 837</span></a>                        <span class="n">eps</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-838"><a href="#ONNXConverter-838"><span class="linenos"> 838</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-839"><a href="#ONNXConverter-839"><span class="linenos"> 839</span></a>                        <span class="n">momentum</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-840"><a href="#ONNXConverter-840"><span class="linenos"> 840</span></a>
</span><span id="ONNXConverter-841"><a href="#ONNXConverter-841"><span class="linenos"> 841</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="ONNXConverter-842"><a href="#ONNXConverter-842"><span class="linenos"> 842</span></a>                                                     <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">))</span>
</span><span id="ONNXConverter-843"><a href="#ONNXConverter-843"><span class="linenos"> 843</span></a>
</span><span id="ONNXConverter-844"><a href="#ONNXConverter-844"><span class="linenos"> 844</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-845"><a href="#ONNXConverter-845"><span class="linenos"> 845</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="ONNXConverter-846"><a href="#ONNXConverter-846"><span class="linenos"> 846</span></a>                <span class="c1"># is always the second and the bias tensor is always the third.</span>
</span><span id="ONNXConverter-847"><a href="#ONNXConverter-847"><span class="linenos"> 847</span></a>
</span><span id="ONNXConverter-848"><a href="#ONNXConverter-848"><span class="linenos"> 848</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter-849"><a href="#ONNXConverter-849"><span class="linenos"> 849</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="ONNXConverter-850"><a href="#ONNXConverter-850"><span class="linenos"> 850</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-851"><a href="#ONNXConverter-851"><span class="linenos"> 851</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-852"><a href="#ONNXConverter-852"><span class="linenos"> 852</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-853"><a href="#ONNXConverter-853"><span class="linenos"> 853</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter-854"><a href="#ONNXConverter-854"><span class="linenos"> 854</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter-855"><a href="#ONNXConverter-855"><span class="linenos"> 855</span></a>
</span><span id="ONNXConverter-856"><a href="#ONNXConverter-856"><span class="linenos"> 856</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter-857"><a href="#ONNXConverter-857"><span class="linenos"> 857</span></a>
</span><span id="ONNXConverter-858"><a href="#ONNXConverter-858"><span class="linenos"> 858</span></a>                <span class="c1"># TODO: at present we do not support auto_pad and implicit kernel_shape.</span>
</span><span id="ONNXConverter-859"><a href="#ONNXConverter-859"><span class="linenos"> 859</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="ONNXConverter-860"><a href="#ONNXConverter-860"><span class="linenos"> 860</span></a>                <span class="c1"># We need to exclude the first axis (channels) from the following quantities.</span>
</span><span id="ONNXConverter-861"><a href="#ONNXConverter-861"><span class="linenos"> 861</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-862"><a href="#ONNXConverter-862"><span class="linenos"> 862</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-863"><a href="#ONNXConverter-863"><span class="linenos"> 863</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-864"><a href="#ONNXConverter-864"><span class="linenos"> 864</span></a>
</span><span id="ONNXConverter-865"><a href="#ONNXConverter-865"><span class="linenos"> 865</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-866"><a href="#ONNXConverter-866"><span class="linenos"> 866</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-867"><a href="#ONNXConverter-867"><span class="linenos"> 867</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-868"><a href="#ONNXConverter-868"><span class="linenos"> 868</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;groups&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-869"><a href="#ONNXConverter-869"><span class="linenos"> 869</span></a>                        <span class="n">groups</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter-870"><a href="#ONNXConverter-870"><span class="linenos"> 870</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-871"><a href="#ONNXConverter-871"><span class="linenos"> 871</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-872"><a href="#ONNXConverter-872"><span class="linenos"> 872</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-873"><a href="#ONNXConverter-873"><span class="linenos"> 873</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-874"><a href="#ONNXConverter-874"><span class="linenos"> 874</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-875"><a href="#ONNXConverter-875"><span class="linenos"> 875</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-876"><a href="#ONNXConverter-876"><span class="linenos"> 876</span></a>
</span><span id="ONNXConverter-877"><a href="#ONNXConverter-877"><span class="linenos"> 877</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span>
</span><span id="ONNXConverter-878"><a href="#ONNXConverter-878"><span class="linenos"> 878</span></a>                                                <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
</span><span id="ONNXConverter-879"><a href="#ONNXConverter-879"><span class="linenos"> 879</span></a>
</span><span id="ONNXConverter-880"><a href="#ONNXConverter-880"><span class="linenos"> 880</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;AveragePool&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-881"><a href="#ONNXConverter-881"><span class="linenos"> 881</span></a>
</span><span id="ONNXConverter-882"><a href="#ONNXConverter-882"><span class="linenos"> 882</span></a>                <span class="c1"># TODO: at present we do not support auto_pad.</span>
</span><span id="ONNXConverter-883"><a href="#ONNXConverter-883"><span class="linenos"> 883</span></a>
</span><span id="ONNXConverter-884"><a href="#ONNXConverter-884"><span class="linenos"> 884</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-885"><a href="#ONNXConverter-885"><span class="linenos"> 885</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-886"><a href="#ONNXConverter-886"><span class="linenos"> 886</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-887"><a href="#ONNXConverter-887"><span class="linenos"> 887</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-888"><a href="#ONNXConverter-888"><span class="linenos"> 888</span></a>
</span><span id="ONNXConverter-889"><a href="#ONNXConverter-889"><span class="linenos"> 889</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-890"><a href="#ONNXConverter-890"><span class="linenos"> 890</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-891"><a href="#ONNXConverter-891"><span class="linenos"> 891</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter-892"><a href="#ONNXConverter-892"><span class="linenos"> 892</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;count_include_pad&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-893"><a href="#ONNXConverter-893"><span class="linenos"> 893</span></a>                        <span class="n">count_include_pad</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter-894"><a href="#ONNXConverter-894"><span class="linenos"> 894</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-895"><a href="#ONNXConverter-895"><span class="linenos"> 895</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-896"><a href="#ONNXConverter-896"><span class="linenos"> 896</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-897"><a href="#ONNXConverter-897"><span class="linenos"> 897</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-898"><a href="#ONNXConverter-898"><span class="linenos"> 898</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-899"><a href="#ONNXConverter-899"><span class="linenos"> 899</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-900"><a href="#ONNXConverter-900"><span class="linenos"> 900</span></a>
</span><span id="ONNXConverter-901"><a href="#ONNXConverter-901"><span class="linenos"> 901</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span>
</span><span id="ONNXConverter-902"><a href="#ONNXConverter-902"><span class="linenos"> 902</span></a>                                                       <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">))</span>
</span><span id="ONNXConverter-903"><a href="#ONNXConverter-903"><span class="linenos"> 903</span></a>
</span><span id="ONNXConverter-904"><a href="#ONNXConverter-904"><span class="linenos"> 904</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MaxPool&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-905"><a href="#ONNXConverter-905"><span class="linenos"> 905</span></a>
</span><span id="ONNXConverter-906"><a href="#ONNXConverter-906"><span class="linenos"> 906</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter-907"><a href="#ONNXConverter-907"><span class="linenos"> 907</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-908"><a href="#ONNXConverter-908"><span class="linenos"> 908</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-909"><a href="#ONNXConverter-909"><span class="linenos"> 909</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter-910"><a href="#ONNXConverter-910"><span class="linenos"> 910</span></a>
</span><span id="ONNXConverter-911"><a href="#ONNXConverter-911"><span class="linenos"> 911</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-912"><a href="#ONNXConverter-912"><span class="linenos"> 912</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-913"><a href="#ONNXConverter-913"><span class="linenos"> 913</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter-914"><a href="#ONNXConverter-914"><span class="linenos"> 914</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-915"><a href="#ONNXConverter-915"><span class="linenos"> 915</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-916"><a href="#ONNXConverter-916"><span class="linenos"> 916</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-917"><a href="#ONNXConverter-917"><span class="linenos"> 917</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-918"><a href="#ONNXConverter-918"><span class="linenos"> 918</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-919"><a href="#ONNXConverter-919"><span class="linenos"> 919</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-920"><a href="#ONNXConverter-920"><span class="linenos"> 920</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-921"><a href="#ONNXConverter-921"><span class="linenos"> 921</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter-922"><a href="#ONNXConverter-922"><span class="linenos"> 922</span></a>
</span><span id="ONNXConverter-923"><a href="#ONNXConverter-923"><span class="linenos"> 923</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="ONNXConverter-924"><a href="#ONNXConverter-924"><span class="linenos"> 924</span></a>                                                   <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">))</span>
</span><span id="ONNXConverter-925"><a href="#ONNXConverter-925"><span class="linenos"> 925</span></a>
</span><span id="ONNXConverter-926"><a href="#ONNXConverter-926"><span class="linenos"> 926</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LRN&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-927"><a href="#ONNXConverter-927"><span class="linenos"> 927</span></a>
</span><span id="ONNXConverter-928"><a href="#ONNXConverter-928"><span class="linenos"> 928</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
</span><span id="ONNXConverter-929"><a href="#ONNXConverter-929"><span class="linenos"> 929</span></a>                <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.75</span>
</span><span id="ONNXConverter-930"><a href="#ONNXConverter-930"><span class="linenos"> 930</span></a>                <span class="n">k</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter-931"><a href="#ONNXConverter-931"><span class="linenos"> 931</span></a>
</span><span id="ONNXConverter-932"><a href="#ONNXConverter-932"><span class="linenos"> 932</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-933"><a href="#ONNXConverter-933"><span class="linenos"> 933</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-934"><a href="#ONNXConverter-934"><span class="linenos"> 934</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-935"><a href="#ONNXConverter-935"><span class="linenos"> 935</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;beta&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-936"><a href="#ONNXConverter-936"><span class="linenos"> 936</span></a>                        <span class="n">beta</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-937"><a href="#ONNXConverter-937"><span class="linenos"> 937</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;bias&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-938"><a href="#ONNXConverter-938"><span class="linenos"> 938</span></a>                        <span class="n">k</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter-939"><a href="#ONNXConverter-939"><span class="linenos"> 939</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-940"><a href="#ONNXConverter-940"><span class="linenos"> 940</span></a>                        <span class="n">size</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter-941"><a href="#ONNXConverter-941"><span class="linenos"> 941</span></a>
</span><span id="ONNXConverter-942"><a href="#ONNXConverter-942"><span class="linenos"> 942</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
</span><span id="ONNXConverter-943"><a href="#ONNXConverter-943"><span class="linenos"> 943</span></a>
</span><span id="ONNXConverter-944"><a href="#ONNXConverter-944"><span class="linenos"> 944</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Softmax&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-945"><a href="#ONNXConverter-945"><span class="linenos"> 945</span></a>
</span><span id="ONNXConverter-946"><a href="#ONNXConverter-946"><span class="linenos"> 946</span></a>                <span class="c1"># Since the ONNX representation consider the batch dimension we need to scale the axis by 1</span>
</span><span id="ONNXConverter-947"><a href="#ONNXConverter-947"><span class="linenos"> 947</span></a>                <span class="c1"># when we pass to our representation.</span>
</span><span id="ONNXConverter-948"><a href="#ONNXConverter-948"><span class="linenos"> 948</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="ONNXConverter-949"><a href="#ONNXConverter-949"><span class="linenos"> 949</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-950"><a href="#ONNXConverter-950"><span class="linenos"> 950</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-951"><a href="#ONNXConverter-951"><span class="linenos"> 951</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="ONNXConverter-952"><a href="#ONNXConverter-952"><span class="linenos"> 952</span></a>
</span><span id="ONNXConverter-953"><a href="#ONNXConverter-953"><span class="linenos"> 953</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="ONNXConverter-954"><a href="#ONNXConverter-954"><span class="linenos"> 954</span></a>
</span><span id="ONNXConverter-955"><a href="#ONNXConverter-955"><span class="linenos"> 955</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Unsqueeze&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-956"><a href="#ONNXConverter-956"><span class="linenos"> 956</span></a>
</span><span id="ONNXConverter-957"><a href="#ONNXConverter-957"><span class="linenos"> 957</span></a>                <span class="n">temp_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="ONNXConverter-958"><a href="#ONNXConverter-958"><span class="linenos"> 958</span></a>                <span class="c1"># Since our representation do not consider the batch dimension we need to scale all the axes</span>
</span><span id="ONNXConverter-959"><a href="#ONNXConverter-959"><span class="linenos"> 959</span></a>                <span class="c1"># by 1 when we pass to the onnx representation.</span>
</span><span id="ONNXConverter-960"><a href="#ONNXConverter-960"><span class="linenos"> 960</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">temp_axes</span><span class="p">])</span>
</span><span id="ONNXConverter-961"><a href="#ONNXConverter-961"><span class="linenos"> 961</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
</span><span id="ONNXConverter-962"><a href="#ONNXConverter-962"><span class="linenos"> 962</span></a>
</span><span id="ONNXConverter-963"><a href="#ONNXConverter-963"><span class="linenos"> 963</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Reshape&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-964"><a href="#ONNXConverter-964"><span class="linenos"> 964</span></a>
</span><span id="ONNXConverter-965"><a href="#ONNXConverter-965"><span class="linenos"> 965</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="ONNXConverter-966"><a href="#ONNXConverter-966"><span class="linenos"> 966</span></a>                <span class="c1"># We need to eliminate the first dimension corresponding to the batch dimension</span>
</span><span id="ONNXConverter-967"><a href="#ONNXConverter-967"><span class="linenos"> 967</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="ONNXConverter-968"><a href="#ONNXConverter-968"><span class="linenos"> 968</span></a>                <span class="n">allow_zero</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ONNXConverter-969"><a href="#ONNXConverter-969"><span class="linenos"> 969</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-970"><a href="#ONNXConverter-970"><span class="linenos"> 970</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;allowzero&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-971"><a href="#ONNXConverter-971"><span class="linenos"> 971</span></a>                        <span class="n">allow_zero</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter-972"><a href="#ONNXConverter-972"><span class="linenos"> 972</span></a>
</span><span id="ONNXConverter-973"><a href="#ONNXConverter-973"><span class="linenos"> 973</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">allow_zero</span><span class="p">))</span>
</span><span id="ONNXConverter-974"><a href="#ONNXConverter-974"><span class="linenos"> 974</span></a>
</span><span id="ONNXConverter-975"><a href="#ONNXConverter-975"><span class="linenos"> 975</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Flatten&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-976"><a href="#ONNXConverter-976"><span class="linenos"> 976</span></a>
</span><span id="ONNXConverter-977"><a href="#ONNXConverter-977"><span class="linenos"> 977</span></a>                <span class="c1"># We need to scale the axis value since our representation does not have the batch dimension</span>
</span><span id="ONNXConverter-978"><a href="#ONNXConverter-978"><span class="linenos"> 978</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ONNXConverter-979"><a href="#ONNXConverter-979"><span class="linenos"> 979</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-980"><a href="#ONNXConverter-980"><span class="linenos"> 980</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-981"><a href="#ONNXConverter-981"><span class="linenos"> 981</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="ONNXConverter-982"><a href="#ONNXConverter-982"><span class="linenos"> 982</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="ONNXConverter-983"><a href="#ONNXConverter-983"><span class="linenos"> 983</span></a>
</span><span id="ONNXConverter-984"><a href="#ONNXConverter-984"><span class="linenos"> 984</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Dropout&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-985"><a href="#ONNXConverter-985"><span class="linenos"> 985</span></a>
</span><span id="ONNXConverter-986"><a href="#ONNXConverter-986"><span class="linenos"> 986</span></a>                <span class="n">ratio</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter-987"><a href="#ONNXConverter-987"><span class="linenos"> 987</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">ratio</span><span class="p">))</span>
</span><span id="ONNXConverter-988"><a href="#ONNXConverter-988"><span class="linenos"> 988</span></a>
</span><span id="ONNXConverter-989"><a href="#ONNXConverter-989"><span class="linenos"> 989</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Transpose&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter-990"><a href="#ONNXConverter-990"><span class="linenos"> 990</span></a>
</span><span id="ONNXConverter-991"><a href="#ONNXConverter-991"><span class="linenos"> 991</span></a>                <span class="n">perm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter-992"><a href="#ONNXConverter-992"><span class="linenos"> 992</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter-993"><a href="#ONNXConverter-993"><span class="linenos"> 993</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;perm&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter-994"><a href="#ONNXConverter-994"><span class="linenos"> 994</span></a>                        <span class="c1"># Must manage batch dimension</span>
</span><span id="ONNXConverter-995"><a href="#ONNXConverter-995"><span class="linenos"> 995</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">):</span>
</span><span id="ONNXConverter-996"><a href="#ONNXConverter-996"><span class="linenos"> 996</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">))]</span>
</span><span id="ONNXConverter-997"><a href="#ONNXConverter-997"><span class="linenos"> 997</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-998"><a href="#ONNXConverter-998"><span class="linenos"> 998</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">ints</span>
</span><span id="ONNXConverter-999"><a href="#ONNXConverter-999"><span class="linenos"> 999</span></a>
</span><span id="ONNXConverter-1000"><a href="#ONNXConverter-1000"><span class="linenos">1000</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">perm</span><span class="p">))</span>
</span><span id="ONNXConverter-1001"><a href="#ONNXConverter-1001"><span class="linenos">1001</span></a>
</span><span id="ONNXConverter-1002"><a href="#ONNXConverter-1002"><span class="linenos">1002</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter-1003"><a href="#ONNXConverter-1003"><span class="linenos">1003</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter-1004"><a href="#ONNXConverter-1004"><span class="linenos">1004</span></a>
</span><span id="ONNXConverter-1005"><a href="#ONNXConverter-1005"><span class="linenos">1005</span></a>            <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter-1006"><a href="#ONNXConverter-1006"><span class="linenos">1006</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter-1007"><a href="#ONNXConverter-1007"><span class="linenos">1007</span></a>
</span><span id="ONNXConverter-1008"><a href="#ONNXConverter-1008"><span class="linenos">1008</span></a>        <span class="k">return</span> <span class="n">network</span>
</span></pre></div>


            <div class="docstring"><p>A class used to represent the conversion strategy for ONNX models.</p>

<h2 id="methods">Methods</h2>

<p>from_neural_network(NeuralNetwork)
    Convert the neural network of interest to a ONNXNetwork model.
to_neural_network(ONNXNetwork)
    Convert the ONNXNetwork of interest to our internal representation of a Neural Network.</p>
</div>


                            <div id="ONNXConverter.from_neural_network" class="classattr">
                                        <input id="ONNXConverter.from_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">from_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">network</span><span class="p">:</span> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span></span><span class="return-annotation">) -> <span class="n"><a href="#ONNXNetwork">ONNXNetwork</a></span>:</span></span>

                <label class="view-source-button" for="ONNXConverter.from_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXConverter.from_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXConverter.from_neural_network-527"><a href="#ONNXConverter.from_neural_network-527"><span class="linenos">527</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ONNXNetwork</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-528"><a href="#ONNXConverter.from_neural_network-528"><span class="linenos">528</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXConverter.from_neural_network-529"><a href="#ONNXConverter.from_neural_network-529"><span class="linenos">529</span></a><span class="sd">        Convert the neural network of interest to a ONNX representation.</span>
</span><span id="ONNXConverter.from_neural_network-530"><a href="#ONNXConverter.from_neural_network-530"><span class="linenos">530</span></a>
</span><span id="ONNXConverter.from_neural_network-531"><a href="#ONNXConverter.from_neural_network-531"><span class="linenos">531</span></a><span class="sd">        Parameters</span>
</span><span id="ONNXConverter.from_neural_network-532"><a href="#ONNXConverter.from_neural_network-532"><span class="linenos">532</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter.from_neural_network-533"><a href="#ONNXConverter.from_neural_network-533"><span class="linenos">533</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="ONNXConverter.from_neural_network-534"><a href="#ONNXConverter.from_neural_network-534"><span class="linenos">534</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="ONNXConverter.from_neural_network-535"><a href="#ONNXConverter.from_neural_network-535"><span class="linenos">535</span></a>
</span><span id="ONNXConverter.from_neural_network-536"><a href="#ONNXConverter.from_neural_network-536"><span class="linenos">536</span></a><span class="sd">        Returns</span>
</span><span id="ONNXConverter.from_neural_network-537"><a href="#ONNXConverter.from_neural_network-537"><span class="linenos">537</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter.from_neural_network-538"><a href="#ONNXConverter.from_neural_network-538"><span class="linenos">538</span></a><span class="sd">        ONNXNetwork</span>
</span><span id="ONNXConverter.from_neural_network-539"><a href="#ONNXConverter.from_neural_network-539"><span class="linenos">539</span></a><span class="sd">            The ONNX representation resulting from the conversion of the original network.</span>
</span><span id="ONNXConverter.from_neural_network-540"><a href="#ONNXConverter.from_neural_network-540"><span class="linenos">540</span></a>
</span><span id="ONNXConverter.from_neural_network-541"><a href="#ONNXConverter.from_neural_network-541"><span class="linenos">541</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ONNXConverter.from_neural_network-542"><a href="#ONNXConverter.from_neural_network-542"><span class="linenos">542</span></a>
</span><span id="ONNXConverter.from_neural_network-543"><a href="#ONNXConverter.from_neural_network-543"><span class="linenos">543</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.from_neural_network-544"><a href="#ONNXConverter.from_neural_network-544"><span class="linenos">544</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-545"><a href="#ONNXConverter.from_neural_network-545"><span class="linenos">545</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-546"><a href="#ONNXConverter.from_neural_network-546"><span class="linenos">546</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="ONNXConverter.from_neural_network-547"><a href="#ONNXConverter.from_neural_network-547"><span class="linenos">547</span></a>
</span><span id="ONNXConverter.from_neural_network-548"><a href="#ONNXConverter.from_neural_network-548"><span class="linenos">548</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-549"><a href="#ONNXConverter.from_neural_network-549"><span class="linenos">549</span></a>
</span><span id="ONNXConverter.from_neural_network-550"><a href="#ONNXConverter.from_neural_network-550"><span class="linenos">550</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-551"><a href="#ONNXConverter.from_neural_network-551"><span class="linenos">551</span></a>
</span><span id="ONNXConverter.from_neural_network-552"><a href="#ONNXConverter.from_neural_network-552"><span class="linenos">552</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-553"><a href="#ONNXConverter.from_neural_network-553"><span class="linenos">553</span></a>
</span><span id="ONNXConverter.from_neural_network-554"><a href="#ONNXConverter.from_neural_network-554"><span class="linenos">554</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-555"><a href="#ONNXConverter.from_neural_network-555"><span class="linenos">555</span></a>
</span><span id="ONNXConverter.from_neural_network-556"><a href="#ONNXConverter.from_neural_network-556"><span class="linenos">556</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-557"><a href="#ONNXConverter.from_neural_network-557"><span class="linenos">557</span></a>                            <span class="n">pytorch_cv</span> <span class="o">=</span> <span class="n">PyTorchConverter</span><span class="p">()</span>
</span><span id="ONNXConverter.from_neural_network-558"><a href="#ONNXConverter.from_neural_network-558"><span class="linenos">558</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">pytorch_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-559"><a href="#ONNXConverter.from_neural_network-559"><span class="linenos">559</span></a>
</span><span id="ONNXConverter.from_neural_network-560"><a href="#ONNXConverter.from_neural_network-560"><span class="linenos">560</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-561"><a href="#ONNXConverter.from_neural_network-561"><span class="linenos">561</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter.from_neural_network-562"><a href="#ONNXConverter.from_neural_network-562"><span class="linenos">562</span></a>                        <span class="k">break</span>
</span><span id="ONNXConverter.from_neural_network-563"><a href="#ONNXConverter.from_neural_network-563"><span class="linenos">563</span></a>
</span><span id="ONNXConverter.from_neural_network-564"><a href="#ONNXConverter.from_neural_network-564"><span class="linenos">564</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-565"><a href="#ONNXConverter.from_neural_network-565"><span class="linenos">565</span></a>
</span><span id="ONNXConverter.from_neural_network-566"><a href="#ONNXConverter.from_neural_network-566"><span class="linenos">566</span></a>                <span class="n">current_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.from_neural_network-567"><a href="#ONNXConverter.from_neural_network-567"><span class="linenos">567</span></a>                <span class="n">previous_output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="ONNXConverter.from_neural_network-568"><a href="#ONNXConverter.from_neural_network-568"><span class="linenos">568</span></a>                <span class="n">input_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter.from_neural_network-569"><a href="#ONNXConverter.from_neural_network-569"><span class="linenos">569</span></a>                <span class="n">output_info</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter.from_neural_network-570"><a href="#ONNXConverter.from_neural_network-570"><span class="linenos">570</span></a>                <span class="n">initializers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter.from_neural_network-571"><a href="#ONNXConverter.from_neural_network-571"><span class="linenos">571</span></a>                <span class="n">onnx_nodes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter.from_neural_network-572"><a href="#ONNXConverter.from_neural_network-572"><span class="linenos">572</span></a>
</span><span id="ONNXConverter.from_neural_network-573"><a href="#ONNXConverter.from_neural_network-573"><span class="linenos">573</span></a>                <span class="k">while</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-574"><a href="#ONNXConverter.from_neural_network-574"><span class="linenos">574</span></a>
</span><span id="ONNXConverter.from_neural_network-575"><a href="#ONNXConverter.from_neural_network-575"><span class="linenos">575</span></a>                    <span class="n">current_node</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_next_node</span><span class="p">(</span><span class="n">current_node</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-576"><a href="#ONNXConverter.from_neural_network-576"><span class="linenos">576</span></a>                    <span class="n">current_input</span> <span class="o">=</span> <span class="n">previous_output</span>
</span><span id="ONNXConverter.from_neural_network-577"><a href="#ONNXConverter.from_neural_network-577"><span class="linenos">577</span></a>                    <span class="n">current_output</span> <span class="o">=</span> <span class="n">current_node</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="ONNXConverter.from_neural_network-578"><a href="#ONNXConverter.from_neural_network-578"><span class="linenos">578</span></a>
</span><span id="ONNXConverter.from_neural_network-579"><a href="#ONNXConverter.from_neural_network-579"><span class="linenos">579</span></a>                    <span class="n">input_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter.from_neural_network-580"><a href="#ONNXConverter.from_neural_network-580"><span class="linenos">580</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">in_dim</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-581"><a href="#ONNXConverter.from_neural_network-581"><span class="linenos">581</span></a>                        <span class="n">input_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-582"><a href="#ONNXConverter.from_neural_network-582"><span class="linenos">582</span></a>
</span><span id="ONNXConverter.from_neural_network-583"><a href="#ONNXConverter.from_neural_network-583"><span class="linenos">583</span></a>                    <span class="n">output_dim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ONNXConverter.from_neural_network-584"><a href="#ONNXConverter.from_neural_network-584"><span class="linenos">584</span></a>                    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">current_node</span><span class="o">.</span><span class="n">out_dim</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-585"><a href="#ONNXConverter.from_neural_network-585"><span class="linenos">585</span></a>                        <span class="n">output_dim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-586"><a href="#ONNXConverter.from_neural_network-586"><span class="linenos">586</span></a>
</span><span id="ONNXConverter.from_neural_network-587"><a href="#ONNXConverter.from_neural_network-587"><span class="linenos">587</span></a>                    <span class="n">input_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-588"><a href="#ONNXConverter.from_neural_network-588"><span class="linenos">588</span></a>                                                                          <span class="n">input_dim</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-589"><a href="#ONNXConverter.from_neural_network-589"><span class="linenos">589</span></a>                    <span class="n">output_value_info</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="n">current_output</span><span class="p">,</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">DOUBLE</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-590"><a href="#ONNXConverter.from_neural_network-590"><span class="linenos">590</span></a>                                                                           <span class="n">output_dim</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-591"><a href="#ONNXConverter.from_neural_network-591"><span class="linenos">591</span></a>
</span><span id="ONNXConverter.from_neural_network-592"><a href="#ONNXConverter.from_neural_network-592"><span class="linenos">592</span></a>                    <span class="n">input_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-593"><a href="#ONNXConverter.from_neural_network-593"><span class="linenos">593</span></a>                    <span class="n">output_info</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_value_info</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-594"><a href="#ONNXConverter.from_neural_network-594"><span class="linenos">594</span></a>
</span><span id="ONNXConverter.from_neural_network-595"><a href="#ONNXConverter.from_neural_network-595"><span class="linenos">595</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-596"><a href="#ONNXConverter.from_neural_network-596"><span class="linenos">596</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_relu</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-597"><a href="#ONNXConverter.from_neural_network-597"><span class="linenos">597</span></a>
</span><span id="ONNXConverter.from_neural_network-598"><a href="#ONNXConverter.from_neural_network-598"><span class="linenos">598</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-599"><a href="#ONNXConverter.from_neural_network-599"><span class="linenos">599</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_elu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-600"><a href="#ONNXConverter.from_neural_network-600"><span class="linenos">600</span></a>
</span><span id="ONNXConverter.from_neural_network-601"><a href="#ONNXConverter.from_neural_network-601"><span class="linenos">601</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-602"><a href="#ONNXConverter.from_neural_network-602"><span class="linenos">602</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_leakyrelu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-603"><a href="#ONNXConverter.from_neural_network-603"><span class="linenos">603</span></a>
</span><span id="ONNXConverter.from_neural_network-604"><a href="#ONNXConverter.from_neural_network-604"><span class="linenos">604</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-605"><a href="#ONNXConverter.from_neural_network-605"><span class="linenos">605</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_celu</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-606"><a href="#ONNXConverter.from_neural_network-606"><span class="linenos">606</span></a>
</span><span id="ONNXConverter.from_neural_network-607"><a href="#ONNXConverter.from_neural_network-607"><span class="linenos">607</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-608"><a href="#ONNXConverter.from_neural_network-608"><span class="linenos">608</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_sigmoid</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-609"><a href="#ONNXConverter.from_neural_network-609"><span class="linenos">609</span></a>
</span><span id="ONNXConverter.from_neural_network-610"><a href="#ONNXConverter.from_neural_network-610"><span class="linenos">610</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-611"><a href="#ONNXConverter.from_neural_network-611"><span class="linenos">611</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_tanh</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-612"><a href="#ONNXConverter.from_neural_network-612"><span class="linenos">612</span></a>
</span><span id="ONNXConverter.from_neural_network-613"><a href="#ONNXConverter.from_neural_network-613"><span class="linenos">613</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-614"><a href="#ONNXConverter.from_neural_network-614"><span class="linenos">614</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_linear</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-615"><a href="#ONNXConverter.from_neural_network-615"><span class="linenos">615</span></a>                                               <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-616"><a href="#ONNXConverter.from_neural_network-616"><span class="linenos">616</span></a>
</span><span id="ONNXConverter.from_neural_network-617"><a href="#ONNXConverter.from_neural_network-617"><span class="linenos">617</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-618"><a href="#ONNXConverter.from_neural_network-618"><span class="linenos">618</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_batchnorm</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-619"><a href="#ONNXConverter.from_neural_network-619"><span class="linenos">619</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-620"><a href="#ONNXConverter.from_neural_network-620"><span class="linenos">620</span></a>
</span><span id="ONNXConverter.from_neural_network-621"><a href="#ONNXConverter.from_neural_network-621"><span class="linenos">621</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-622"><a href="#ONNXConverter.from_neural_network-622"><span class="linenos">622</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_conv</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-623"><a href="#ONNXConverter.from_neural_network-623"><span class="linenos">623</span></a>                                             <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-624"><a href="#ONNXConverter.from_neural_network-624"><span class="linenos">624</span></a>
</span><span id="ONNXConverter.from_neural_network-625"><a href="#ONNXConverter.from_neural_network-625"><span class="linenos">625</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-626"><a href="#ONNXConverter.from_neural_network-626"><span class="linenos">626</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_averagepool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-627"><a href="#ONNXConverter.from_neural_network-627"><span class="linenos">627</span></a>
</span><span id="ONNXConverter.from_neural_network-628"><a href="#ONNXConverter.from_neural_network-628"><span class="linenos">628</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-629"><a href="#ONNXConverter.from_neural_network-629"><span class="linenos">629</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_maxpool</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-630"><a href="#ONNXConverter.from_neural_network-630"><span class="linenos">630</span></a>
</span><span id="ONNXConverter.from_neural_network-631"><a href="#ONNXConverter.from_neural_network-631"><span class="linenos">631</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-632"><a href="#ONNXConverter.from_neural_network-632"><span class="linenos">632</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_lrn</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-633"><a href="#ONNXConverter.from_neural_network-633"><span class="linenos">633</span></a>
</span><span id="ONNXConverter.from_neural_network-634"><a href="#ONNXConverter.from_neural_network-634"><span class="linenos">634</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-635"><a href="#ONNXConverter.from_neural_network-635"><span class="linenos">635</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_softmax</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-636"><a href="#ONNXConverter.from_neural_network-636"><span class="linenos">636</span></a>
</span><span id="ONNXConverter.from_neural_network-637"><a href="#ONNXConverter.from_neural_network-637"><span class="linenos">637</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-638"><a href="#ONNXConverter.from_neural_network-638"><span class="linenos">638</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_unsqueeze</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-639"><a href="#ONNXConverter.from_neural_network-639"><span class="linenos">639</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-640"><a href="#ONNXConverter.from_neural_network-640"><span class="linenos">640</span></a>
</span><span id="ONNXConverter.from_neural_network-641"><a href="#ONNXConverter.from_neural_network-641"><span class="linenos">641</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-642"><a href="#ONNXConverter.from_neural_network-642"><span class="linenos">642</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_reshape</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-643"><a href="#ONNXConverter.from_neural_network-643"><span class="linenos">643</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-644"><a href="#ONNXConverter.from_neural_network-644"><span class="linenos">644</span></a>
</span><span id="ONNXConverter.from_neural_network-645"><a href="#ONNXConverter.from_neural_network-645"><span class="linenos">645</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-646"><a href="#ONNXConverter.from_neural_network-646"><span class="linenos">646</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_flatten</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-647"><a href="#ONNXConverter.from_neural_network-647"><span class="linenos">647</span></a>
</span><span id="ONNXConverter.from_neural_network-648"><a href="#ONNXConverter.from_neural_network-648"><span class="linenos">648</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-649"><a href="#ONNXConverter.from_neural_network-649"><span class="linenos">649</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_dropout</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-650"><a href="#ONNXConverter.from_neural_network-650"><span class="linenos">650</span></a>                                                <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-651"><a href="#ONNXConverter.from_neural_network-651"><span class="linenos">651</span></a>
</span><span id="ONNXConverter.from_neural_network-652"><a href="#ONNXConverter.from_neural_network-652"><span class="linenos">652</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">):</span>
</span><span id="ONNXConverter.from_neural_network-653"><a href="#ONNXConverter.from_neural_network-653"><span class="linenos">653</span></a>                        <span class="bp">self</span><span class="o">.</span><span class="n">__add_onnx_transpose</span><span class="p">(</span><span class="n">current_node</span><span class="p">,</span> <span class="n">current_input</span><span class="p">,</span> <span class="n">current_output</span><span class="p">,</span> <span class="n">onnx_nodes</span><span class="p">,</span> <span class="n">input_info</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-654"><a href="#ONNXConverter.from_neural_network-654"><span class="linenos">654</span></a>                                                  <span class="n">initializers</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-655"><a href="#ONNXConverter.from_neural_network-655"><span class="linenos">655</span></a>
</span><span id="ONNXConverter.from_neural_network-656"><a href="#ONNXConverter.from_neural_network-656"><span class="linenos">656</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-657"><a href="#ONNXConverter.from_neural_network-657"><span class="linenos">657</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter.from_neural_network-658"><a href="#ONNXConverter.from_neural_network-658"><span class="linenos">658</span></a>
</span><span id="ONNXConverter.from_neural_network-659"><a href="#ONNXConverter.from_neural_network-659"><span class="linenos">659</span></a>                    <span class="n">previous_output</span> <span class="o">=</span> <span class="n">current_output</span>
</span><span id="ONNXConverter.from_neural_network-660"><a href="#ONNXConverter.from_neural_network-660"><span class="linenos">660</span></a>
</span><span id="ONNXConverter.from_neural_network-661"><a href="#ONNXConverter.from_neural_network-661"><span class="linenos">661</span></a>                <span class="n">onnx_graph</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
</span><span id="ONNXConverter.from_neural_network-662"><a href="#ONNXConverter.from_neural_network-662"><span class="linenos">662</span></a>                    <span class="n">nodes</span><span class="o">=</span><span class="n">onnx_nodes</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-663"><a href="#ONNXConverter.from_neural_network-663"><span class="linenos">663</span></a>                    <span class="n">name</span><span class="o">=</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-664"><a href="#ONNXConverter.from_neural_network-664"><span class="linenos">664</span></a>                    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
</span><span id="ONNXConverter.from_neural_network-665"><a href="#ONNXConverter.from_neural_network-665"><span class="linenos">665</span></a>                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output_info</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
</span><span id="ONNXConverter.from_neural_network-666"><a href="#ONNXConverter.from_neural_network-666"><span class="linenos">666</span></a>                    <span class="n">initializer</span><span class="o">=</span><span class="n">initializers</span><span class="p">,</span>
</span><span id="ONNXConverter.from_neural_network-667"><a href="#ONNXConverter.from_neural_network-667"><span class="linenos">667</span></a>                    <span class="n">value_info</span><span class="o">=</span><span class="n">input_info</span>
</span><span id="ONNXConverter.from_neural_network-668"><a href="#ONNXConverter.from_neural_network-668"><span class="linenos">668</span></a>                <span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-669"><a href="#ONNXConverter.from_neural_network-669"><span class="linenos">669</span></a>
</span><span id="ONNXConverter.from_neural_network-670"><a href="#ONNXConverter.from_neural_network-670"><span class="linenos">670</span></a>                <span class="n">onnx_network</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">onnx_graph</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-671"><a href="#ONNXConverter.from_neural_network-671"><span class="linenos">671</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">ONNXNetwork</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">onnx_network</span><span class="p">)</span>
</span><span id="ONNXConverter.from_neural_network-672"><a href="#ONNXConverter.from_neural_network-672"><span class="linenos">672</span></a>
</span><span id="ONNXConverter.from_neural_network-673"><a href="#ONNXConverter.from_neural_network-673"><span class="linenos">673</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.from_neural_network-674"><a href="#ONNXConverter.from_neural_network-674"><span class="linenos">674</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter.from_neural_network-675"><a href="#ONNXConverter.from_neural_network-675"><span class="linenos">675</span></a>
</span><span id="ONNXConverter.from_neural_network-676"><a href="#ONNXConverter.from_neural_network-676"><span class="linenos">676</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span></pre></div>


            <div class="docstring"><p>Convert the neural network of interest to a ONNX representation.</p>

<h2 id="parameters">Parameters</h2>

<p>network : NeuralNetwork
    The neural network to convert.</p>

<h2 id="returns">Returns</h2>

<p>ONNXNetwork
    The ONNX representation resulting from the conversion of the original network.</p>
</div>


                            </div>
                            <div id="ONNXConverter.to_neural_network" class="classattr">
                                        <input id="ONNXConverter.to_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">alt_rep</span><span class="p">:</span> <span class="n"><a href="#ONNXNetwork">ONNXNetwork</a></span></span><span class="return-annotation">) -> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span>:</span></span>

                <label class="view-source-button" for="ONNXConverter.to_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ONNXConverter.to_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ONNXConverter.to_neural_network-678"><a href="#ONNXConverter.to_neural_network-678"><span class="linenos"> 678</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">ONNXNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-679"><a href="#ONNXConverter.to_neural_network-679"><span class="linenos"> 679</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ONNXConverter.to_neural_network-680"><a href="#ONNXConverter.to_neural_network-680"><span class="linenos"> 680</span></a><span class="sd">        Convert the ONNX representation of interest to the internal one.</span>
</span><span id="ONNXConverter.to_neural_network-681"><a href="#ONNXConverter.to_neural_network-681"><span class="linenos"> 681</span></a>
</span><span id="ONNXConverter.to_neural_network-682"><a href="#ONNXConverter.to_neural_network-682"><span class="linenos"> 682</span></a><span class="sd">        Parameters</span>
</span><span id="ONNXConverter.to_neural_network-683"><a href="#ONNXConverter.to_neural_network-683"><span class="linenos"> 683</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter.to_neural_network-684"><a href="#ONNXConverter.to_neural_network-684"><span class="linenos"> 684</span></a><span class="sd">        alt_rep : ONNXNetwork</span>
</span><span id="ONNXConverter.to_neural_network-685"><a href="#ONNXConverter.to_neural_network-685"><span class="linenos"> 685</span></a><span class="sd">            The ONNX Representation to convert.</span>
</span><span id="ONNXConverter.to_neural_network-686"><a href="#ONNXConverter.to_neural_network-686"><span class="linenos"> 686</span></a>
</span><span id="ONNXConverter.to_neural_network-687"><a href="#ONNXConverter.to_neural_network-687"><span class="linenos"> 687</span></a><span class="sd">        Returns</span>
</span><span id="ONNXConverter.to_neural_network-688"><a href="#ONNXConverter.to_neural_network-688"><span class="linenos"> 688</span></a><span class="sd">        ----------</span>
</span><span id="ONNXConverter.to_neural_network-689"><a href="#ONNXConverter.to_neural_network-689"><span class="linenos"> 689</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="ONNXConverter.to_neural_network-690"><a href="#ONNXConverter.to_neural_network-690"><span class="linenos"> 690</span></a><span class="sd">            The Neural Network resulting from the conversion of ONNX Representation.</span>
</span><span id="ONNXConverter.to_neural_network-691"><a href="#ONNXConverter.to_neural_network-691"><span class="linenos"> 691</span></a>
</span><span id="ONNXConverter.to_neural_network-692"><a href="#ONNXConverter.to_neural_network-692"><span class="linenos"> 692</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ONNXConverter.to_neural_network-693"><a href="#ONNXConverter.to_neural_network-693"><span class="linenos"> 693</span></a>
</span><span id="ONNXConverter.to_neural_network-694"><a href="#ONNXConverter.to_neural_network-694"><span class="linenos"> 694</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="ONNXConverter.to_neural_network-695"><a href="#ONNXConverter.to_neural_network-695"><span class="linenos"> 695</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-696"><a href="#ONNXConverter.to_neural_network-696"><span class="linenos"> 696</span></a>
</span><span id="ONNXConverter.to_neural_network-697"><a href="#ONNXConverter.to_neural_network-697"><span class="linenos"> 697</span></a>        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="ONNXConverter.to_neural_network-698"><a href="#ONNXConverter.to_neural_network-698"><span class="linenos"> 698</span></a>        <span class="k">for</span> <span class="n">initializer</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-699"><a href="#ONNXConverter.to_neural_network-699"><span class="linenos"> 699</span></a>            <span class="n">parameters</span><span class="p">[</span><span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-700"><a href="#ONNXConverter.to_neural_network-700"><span class="linenos"> 700</span></a>
</span><span id="ONNXConverter.to_neural_network-701"><a href="#ONNXConverter.to_neural_network-701"><span class="linenos"> 701</span></a>        <span class="n">shape_info</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="ONNXConverter.to_neural_network-702"><a href="#ONNXConverter.to_neural_network-702"><span class="linenos"> 702</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-703"><a href="#ONNXConverter.to_neural_network-703"><span class="linenos"> 703</span></a>            <span class="n">shape</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="ONNXConverter.to_neural_network-704"><a href="#ONNXConverter.to_neural_network-704"><span class="linenos"> 704</span></a>            <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">i</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-705"><a href="#ONNXConverter.to_neural_network-705"><span class="linenos"> 705</span></a>                <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dim</span><span class="o">.</span><span class="n">dim_value</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-706"><a href="#ONNXConverter.to_neural_network-706"><span class="linenos"> 706</span></a>            <span class="n">shape_info</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">shape</span>
</span><span id="ONNXConverter.to_neural_network-707"><a href="#ONNXConverter.to_neural_network-707"><span class="linenos"> 707</span></a>
</span><span id="ONNXConverter.to_neural_network-708"><a href="#ONNXConverter.to_neural_network-708"><span class="linenos"> 708</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-709"><a href="#ONNXConverter.to_neural_network-709"><span class="linenos"> 709</span></a>        <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
</span><span id="ONNXConverter.to_neural_network-710"><a href="#ONNXConverter.to_neural_network-710"><span class="linenos"> 710</span></a>        <span class="k">if</span> <span class="n">in_dim</span> <span class="o">==</span> <span class="p">():</span>
</span><span id="ONNXConverter.to_neural_network-711"><a href="#ONNXConverter.to_neural_network-711"><span class="linenos"> 711</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape_info</span><span class="p">[</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
</span><span id="ONNXConverter.to_neural_network-712"><a href="#ONNXConverter.to_neural_network-712"><span class="linenos"> 712</span></a>
</span><span id="ONNXConverter.to_neural_network-713"><a href="#ONNXConverter.to_neural_network-713"><span class="linenos"> 713</span></a>        <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-714"><a href="#ONNXConverter.to_neural_network-714"><span class="linenos"> 714</span></a>        <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-715"><a href="#ONNXConverter.to_neural_network-715"><span class="linenos"> 715</span></a>
</span><span id="ONNXConverter.to_neural_network-716"><a href="#ONNXConverter.to_neural_network-716"><span class="linenos"> 716</span></a>        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">onnx_network</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-717"><a href="#ONNXConverter.to_neural_network-717"><span class="linenos"> 717</span></a>
</span><span id="ONNXConverter.to_neural_network-718"><a href="#ONNXConverter.to_neural_network-718"><span class="linenos"> 718</span></a>            <span class="k">if</span> <span class="n">matmul_found</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-719"><a href="#ONNXConverter.to_neural_network-719"><span class="linenos"> 719</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Add&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-720"><a href="#ONNXConverter.to_neural_network-720"><span class="linenos"> 720</span></a>
</span><span id="ONNXConverter.to_neural_network-721"><a href="#ONNXConverter.to_neural_network-721"><span class="linenos"> 721</span></a>                    <span class="c1"># We assume that the bias is always the second element of node.input</span>
</span><span id="ONNXConverter.to_neural_network-722"><a href="#ONNXConverter.to_neural_network-722"><span class="linenos"> 722</span></a>
</span><span id="ONNXConverter.to_neural_network-723"><a href="#ONNXConverter.to_neural_network-723"><span class="linenos"> 723</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-724"><a href="#ONNXConverter.to_neural_network-724"><span class="linenos"> 724</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-725"><a href="#ONNXConverter.to_neural_network-725"><span class="linenos"> 725</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="kc">True</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-726"><a href="#ONNXConverter.to_neural_network-726"><span class="linenos"> 726</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-727"><a href="#ONNXConverter.to_neural_network-727"><span class="linenos"> 727</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-728"><a href="#ONNXConverter.to_neural_network-728"><span class="linenos"> 728</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-729"><a href="#ONNXConverter.to_neural_network-729"><span class="linenos"> 729</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter.to_neural_network-730"><a href="#ONNXConverter.to_neural_network-730"><span class="linenos"> 730</span></a>                    <span class="k">continue</span>
</span><span id="ONNXConverter.to_neural_network-731"><a href="#ONNXConverter.to_neural_network-731"><span class="linenos"> 731</span></a>
</span><span id="ONNXConverter.to_neural_network-732"><a href="#ONNXConverter.to_neural_network-732"><span class="linenos"> 732</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-733"><a href="#ONNXConverter.to_neural_network-733"><span class="linenos"> 733</span></a>                    <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">temp_fc</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-734"><a href="#ONNXConverter.to_neural_network-734"><span class="linenos"> 734</span></a>                                                              <span class="n">temp_fc</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span> <span class="n">temp_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-735"><a href="#ONNXConverter.to_neural_network-735"><span class="linenos"> 735</span></a>                    <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-736"><a href="#ONNXConverter.to_neural_network-736"><span class="linenos"> 736</span></a>                    <span class="n">temp_fc</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-737"><a href="#ONNXConverter.to_neural_network-737"><span class="linenos"> 737</span></a>                    <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-738"><a href="#ONNXConverter.to_neural_network-738"><span class="linenos"> 738</span></a>                    <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter.to_neural_network-739"><a href="#ONNXConverter.to_neural_network-739"><span class="linenos"> 739</span></a>
</span><span id="ONNXConverter.to_neural_network-740"><a href="#ONNXConverter.to_neural_network-740"><span class="linenos"> 740</span></a>            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-741"><a href="#ONNXConverter.to_neural_network-741"><span class="linenos"> 741</span></a>
</span><span id="ONNXConverter.to_neural_network-742"><a href="#ONNXConverter.to_neural_network-742"><span class="linenos"> 742</span></a>                <span class="c1"># If the weight is the second parameter we need to transpose it</span>
</span><span id="ONNXConverter.to_neural_network-743"><a href="#ONNXConverter.to_neural_network-743"><span class="linenos"> 743</span></a>
</span><span id="ONNXConverter.to_neural_network-744"><a href="#ONNXConverter.to_neural_network-744"><span class="linenos"> 744</span></a>                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span><span id="ONNXConverter.to_neural_network-745"><a href="#ONNXConverter.to_neural_network-745"><span class="linenos"> 745</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-746"><a href="#ONNXConverter.to_neural_network-746"><span class="linenos"> 746</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-747"><a href="#ONNXConverter.to_neural_network-747"><span class="linenos"> 747</span></a>                    <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="ONNXConverter.to_neural_network-748"><a href="#ONNXConverter.to_neural_network-748"><span class="linenos"> 748</span></a>
</span><span id="ONNXConverter.to_neural_network-749"><a href="#ONNXConverter.to_neural_network-749"><span class="linenos"> 749</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter.to_neural_network-750"><a href="#ONNXConverter.to_neural_network-750"><span class="linenos"> 750</span></a>                <span class="n">temp_fc</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-751"><a href="#ONNXConverter.to_neural_network-751"><span class="linenos"> 751</span></a>                <span class="n">matmul_found</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter.to_neural_network-752"><a href="#ONNXConverter.to_neural_network-752"><span class="linenos"> 752</span></a>                <span class="k">continue</span>
</span><span id="ONNXConverter.to_neural_network-753"><a href="#ONNXConverter.to_neural_network-753"><span class="linenos"> 753</span></a>
</span><span id="ONNXConverter.to_neural_network-754"><a href="#ONNXConverter.to_neural_network-754"><span class="linenos"> 754</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Relu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-755"><a href="#ONNXConverter.to_neural_network-755"><span class="linenos"> 755</span></a>
</span><span id="ONNXConverter.to_neural_network-756"><a href="#ONNXConverter.to_neural_network-756"><span class="linenos"> 756</span></a>                <span class="c1"># We assume that the real input of the node is always the first element of node.input</span>
</span><span id="ONNXConverter.to_neural_network-757"><a href="#ONNXConverter.to_neural_network-757"><span class="linenos"> 757</span></a>                <span class="c1"># and the first element of the shape is the batch placeholder</span>
</span><span id="ONNXConverter.to_neural_network-758"><a href="#ONNXConverter.to_neural_network-758"><span class="linenos"> 758</span></a>
</span><span id="ONNXConverter.to_neural_network-759"><a href="#ONNXConverter.to_neural_network-759"><span class="linenos"> 759</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-760"><a href="#ONNXConverter.to_neural_network-760"><span class="linenos"> 760</span></a>
</span><span id="ONNXConverter.to_neural_network-761"><a href="#ONNXConverter.to_neural_network-761"><span class="linenos"> 761</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Elu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-762"><a href="#ONNXConverter.to_neural_network-762"><span class="linenos"> 762</span></a>
</span><span id="ONNXConverter.to_neural_network-763"><a href="#ONNXConverter.to_neural_network-763"><span class="linenos"> 763</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter.to_neural_network-764"><a href="#ONNXConverter.to_neural_network-764"><span class="linenos"> 764</span></a>
</span><span id="ONNXConverter.to_neural_network-765"><a href="#ONNXConverter.to_neural_network-765"><span class="linenos"> 765</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-766"><a href="#ONNXConverter.to_neural_network-766"><span class="linenos"> 766</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-767"><a href="#ONNXConverter.to_neural_network-767"><span class="linenos"> 767</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-768"><a href="#ONNXConverter.to_neural_network-768"><span class="linenos"> 768</span></a>
</span><span id="ONNXConverter.to_neural_network-769"><a href="#ONNXConverter.to_neural_network-769"><span class="linenos"> 769</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-770"><a href="#ONNXConverter.to_neural_network-770"><span class="linenos"> 770</span></a>
</span><span id="ONNXConverter.to_neural_network-771"><a href="#ONNXConverter.to_neural_network-771"><span class="linenos"> 771</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LeakyRelu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-772"><a href="#ONNXConverter.to_neural_network-772"><span class="linenos"> 772</span></a>
</span><span id="ONNXConverter.to_neural_network-773"><a href="#ONNXConverter.to_neural_network-773"><span class="linenos"> 773</span></a>                <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter.to_neural_network-774"><a href="#ONNXConverter.to_neural_network-774"><span class="linenos"> 774</span></a>
</span><span id="ONNXConverter.to_neural_network-775"><a href="#ONNXConverter.to_neural_network-775"><span class="linenos"> 775</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-776"><a href="#ONNXConverter.to_neural_network-776"><span class="linenos"> 776</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-777"><a href="#ONNXConverter.to_neural_network-777"><span class="linenos"> 777</span></a>                        <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-778"><a href="#ONNXConverter.to_neural_network-778"><span class="linenos"> 778</span></a>
</span><span id="ONNXConverter.to_neural_network-779"><a href="#ONNXConverter.to_neural_network-779"><span class="linenos"> 779</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-780"><a href="#ONNXConverter.to_neural_network-780"><span class="linenos"> 780</span></a>
</span><span id="ONNXConverter.to_neural_network-781"><a href="#ONNXConverter.to_neural_network-781"><span class="linenos"> 781</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Celu&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-782"><a href="#ONNXConverter.to_neural_network-782"><span class="linenos"> 782</span></a>
</span><span id="ONNXConverter.to_neural_network-783"><a href="#ONNXConverter.to_neural_network-783"><span class="linenos"> 783</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter.to_neural_network-784"><a href="#ONNXConverter.to_neural_network-784"><span class="linenos"> 784</span></a>
</span><span id="ONNXConverter.to_neural_network-785"><a href="#ONNXConverter.to_neural_network-785"><span class="linenos"> 785</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-786"><a href="#ONNXConverter.to_neural_network-786"><span class="linenos"> 786</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-787"><a href="#ONNXConverter.to_neural_network-787"><span class="linenos"> 787</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-788"><a href="#ONNXConverter.to_neural_network-788"><span class="linenos"> 788</span></a>
</span><span id="ONNXConverter.to_neural_network-789"><a href="#ONNXConverter.to_neural_network-789"><span class="linenos"> 789</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">alpha</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-790"><a href="#ONNXConverter.to_neural_network-790"><span class="linenos"> 790</span></a>
</span><span id="ONNXConverter.to_neural_network-791"><a href="#ONNXConverter.to_neural_network-791"><span class="linenos"> 791</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-792"><a href="#ONNXConverter.to_neural_network-792"><span class="linenos"> 792</span></a>
</span><span id="ONNXConverter.to_neural_network-793"><a href="#ONNXConverter.to_neural_network-793"><span class="linenos"> 793</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-794"><a href="#ONNXConverter.to_neural_network-794"><span class="linenos"> 794</span></a>
</span><span id="ONNXConverter.to_neural_network-795"><a href="#ONNXConverter.to_neural_network-795"><span class="linenos"> 795</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Tanh&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-796"><a href="#ONNXConverter.to_neural_network-796"><span class="linenos"> 796</span></a>
</span><span id="ONNXConverter.to_neural_network-797"><a href="#ONNXConverter.to_neural_network-797"><span class="linenos"> 797</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-798"><a href="#ONNXConverter.to_neural_network-798"><span class="linenos"> 798</span></a>
</span><span id="ONNXConverter.to_neural_network-799"><a href="#ONNXConverter.to_neural_network-799"><span class="linenos"> 799</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Gemm&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-800"><a href="#ONNXConverter.to_neural_network-800"><span class="linenos"> 800</span></a>                <span class="c1"># We assume that the weight tensor is always the second element of node.input and the bias tensor</span>
</span><span id="ONNXConverter.to_neural_network-801"><a href="#ONNXConverter.to_neural_network-801"><span class="linenos"> 801</span></a>                <span class="c1"># is always the third.</span>
</span><span id="ONNXConverter.to_neural_network-802"><a href="#ONNXConverter.to_neural_network-802"><span class="linenos"> 802</span></a>                <span class="c1"># N.B: We do not support the attributes transA and transB,</span>
</span><span id="ONNXConverter.to_neural_network-803"><a href="#ONNXConverter.to_neural_network-803"><span class="linenos"> 803</span></a>                <span class="c1"># therefore we need to transpose the weight vector.</span>
</span><span id="ONNXConverter.to_neural_network-804"><a href="#ONNXConverter.to_neural_network-804"><span class="linenos"> 804</span></a>                <span class="c1"># TODO: Can we support transA and transB in some way?</span>
</span><span id="ONNXConverter.to_neural_network-805"><a href="#ONNXConverter.to_neural_network-805"><span class="linenos"> 805</span></a>
</span><span id="ONNXConverter.to_neural_network-806"><a href="#ONNXConverter.to_neural_network-806"><span class="linenos"> 806</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-807"><a href="#ONNXConverter.to_neural_network-807"><span class="linenos"> 807</span></a>                    <span class="k">if</span> <span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transA&#39;</span> <span class="ow">or</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;transB&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-808"><a href="#ONNXConverter.to_neural_network-808"><span class="linenos"> 808</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
</span><span id="ONNXConverter.to_neural_network-809"><a href="#ONNXConverter.to_neural_network-809"><span class="linenos"> 809</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-810"><a href="#ONNXConverter.to_neural_network-810"><span class="linenos"> 810</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-811"><a href="#ONNXConverter.to_neural_network-811"><span class="linenos"> 811</span></a>
</span><span id="ONNXConverter.to_neural_network-812"><a href="#ONNXConverter.to_neural_network-812"><span class="linenos"> 812</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-813"><a href="#ONNXConverter.to_neural_network-813"><span class="linenos"> 813</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-814"><a href="#ONNXConverter.to_neural_network-814"><span class="linenos"> 814</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-815"><a href="#ONNXConverter.to_neural_network-815"><span class="linenos"> 815</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-816"><a href="#ONNXConverter.to_neural_network-816"><span class="linenos"> 816</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter.to_neural_network-817"><a href="#ONNXConverter.to_neural_network-817"><span class="linenos"> 817</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-818"><a href="#ONNXConverter.to_neural_network-818"><span class="linenos"> 818</span></a>
</span><span id="ONNXConverter.to_neural_network-819"><a href="#ONNXConverter.to_neural_network-819"><span class="linenos"> 819</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter.to_neural_network-820"><a href="#ONNXConverter.to_neural_network-820"><span class="linenos"> 820</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-821"><a href="#ONNXConverter.to_neural_network-821"><span class="linenos"> 821</span></a>                                                          <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-822"><a href="#ONNXConverter.to_neural_network-822"><span class="linenos"> 822</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;BatchNormalization&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-823"><a href="#ONNXConverter.to_neural_network-823"><span class="linenos"> 823</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="ONNXConverter.to_neural_network-824"><a href="#ONNXConverter.to_neural_network-824"><span class="linenos"> 824</span></a>                <span class="c1"># is always the second, the bias tensor is always the third, the running_mean always the fourth</span>
</span><span id="ONNXConverter.to_neural_network-825"><a href="#ONNXConverter.to_neural_network-825"><span class="linenos"> 825</span></a>                <span class="c1"># and the running_var always the fifth.</span>
</span><span id="ONNXConverter.to_neural_network-826"><a href="#ONNXConverter.to_neural_network-826"><span class="linenos"> 826</span></a>
</span><span id="ONNXConverter.to_neural_network-827"><a href="#ONNXConverter.to_neural_network-827"><span class="linenos"> 827</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-828"><a href="#ONNXConverter.to_neural_network-828"><span class="linenos"> 828</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-829"><a href="#ONNXConverter.to_neural_network-829"><span class="linenos"> 829</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-830"><a href="#ONNXConverter.to_neural_network-830"><span class="linenos"> 830</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">4</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-831"><a href="#ONNXConverter.to_neural_network-831"><span class="linenos"> 831</span></a>
</span><span id="ONNXConverter.to_neural_network-832"><a href="#ONNXConverter.to_neural_network-832"><span class="linenos"> 832</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-05</span>
</span><span id="ONNXConverter.to_neural_network-833"><a href="#ONNXConverter.to_neural_network-833"><span class="linenos"> 833</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="ONNXConverter.to_neural_network-834"><a href="#ONNXConverter.to_neural_network-834"><span class="linenos"> 834</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-835"><a href="#ONNXConverter.to_neural_network-835"><span class="linenos"> 835</span></a>
</span><span id="ONNXConverter.to_neural_network-836"><a href="#ONNXConverter.to_neural_network-836"><span class="linenos"> 836</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-837"><a href="#ONNXConverter.to_neural_network-837"><span class="linenos"> 837</span></a>                        <span class="n">eps</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-838"><a href="#ONNXConverter.to_neural_network-838"><span class="linenos"> 838</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;momentum&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-839"><a href="#ONNXConverter.to_neural_network-839"><span class="linenos"> 839</span></a>                        <span class="n">momentum</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-840"><a href="#ONNXConverter.to_neural_network-840"><span class="linenos"> 840</span></a>
</span><span id="ONNXConverter.to_neural_network-841"><a href="#ONNXConverter.to_neural_network-841"><span class="linenos"> 841</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-842"><a href="#ONNXConverter.to_neural_network-842"><span class="linenos"> 842</span></a>                                                     <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-843"><a href="#ONNXConverter.to_neural_network-843"><span class="linenos"> 843</span></a>
</span><span id="ONNXConverter.to_neural_network-844"><a href="#ONNXConverter.to_neural_network-844"><span class="linenos"> 844</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-845"><a href="#ONNXConverter.to_neural_network-845"><span class="linenos"> 845</span></a>                <span class="c1"># We assume that the real input is always the first element of node.input, the weight tensor</span>
</span><span id="ONNXConverter.to_neural_network-846"><a href="#ONNXConverter.to_neural_network-846"><span class="linenos"> 846</span></a>                <span class="c1"># is always the second and the bias tensor is always the third.</span>
</span><span id="ONNXConverter.to_neural_network-847"><a href="#ONNXConverter.to_neural_network-847"><span class="linenos"> 847</span></a>
</span><span id="ONNXConverter.to_neural_network-848"><a href="#ONNXConverter.to_neural_network-848"><span class="linenos"> 848</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-849"><a href="#ONNXConverter.to_neural_network-849"><span class="linenos"> 849</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-850"><a href="#ONNXConverter.to_neural_network-850"><span class="linenos"> 850</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-851"><a href="#ONNXConverter.to_neural_network-851"><span class="linenos"> 851</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-852"><a href="#ONNXConverter.to_neural_network-852"><span class="linenos"> 852</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-853"><a href="#ONNXConverter.to_neural_network-853"><span class="linenos"> 853</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ONNXConverter.to_neural_network-854"><a href="#ONNXConverter.to_neural_network-854"><span class="linenos"> 854</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="ONNXConverter.to_neural_network-855"><a href="#ONNXConverter.to_neural_network-855"><span class="linenos"> 855</span></a>
</span><span id="ONNXConverter.to_neural_network-856"><a href="#ONNXConverter.to_neural_network-856"><span class="linenos"> 856</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter.to_neural_network-857"><a href="#ONNXConverter.to_neural_network-857"><span class="linenos"> 857</span></a>
</span><span id="ONNXConverter.to_neural_network-858"><a href="#ONNXConverter.to_neural_network-858"><span class="linenos"> 858</span></a>                <span class="c1"># TODO: at present we do not support auto_pad and implicit kernel_shape.</span>
</span><span id="ONNXConverter.to_neural_network-859"><a href="#ONNXConverter.to_neural_network-859"><span class="linenos"> 859</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-860"><a href="#ONNXConverter.to_neural_network-860"><span class="linenos"> 860</span></a>                <span class="c1"># We need to exclude the first axis (channels) from the following quantities.</span>
</span><span id="ONNXConverter.to_neural_network-861"><a href="#ONNXConverter.to_neural_network-861"><span class="linenos"> 861</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-862"><a href="#ONNXConverter.to_neural_network-862"><span class="linenos"> 862</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-863"><a href="#ONNXConverter.to_neural_network-863"><span class="linenos"> 863</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-864"><a href="#ONNXConverter.to_neural_network-864"><span class="linenos"> 864</span></a>
</span><span id="ONNXConverter.to_neural_network-865"><a href="#ONNXConverter.to_neural_network-865"><span class="linenos"> 865</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-866"><a href="#ONNXConverter.to_neural_network-866"><span class="linenos"> 866</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-867"><a href="#ONNXConverter.to_neural_network-867"><span class="linenos"> 867</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-868"><a href="#ONNXConverter.to_neural_network-868"><span class="linenos"> 868</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;groups&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-869"><a href="#ONNXConverter.to_neural_network-869"><span class="linenos"> 869</span></a>                        <span class="n">groups</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter.to_neural_network-870"><a href="#ONNXConverter.to_neural_network-870"><span class="linenos"> 870</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-871"><a href="#ONNXConverter.to_neural_network-871"><span class="linenos"> 871</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-872"><a href="#ONNXConverter.to_neural_network-872"><span class="linenos"> 872</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-873"><a href="#ONNXConverter.to_neural_network-873"><span class="linenos"> 873</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-874"><a href="#ONNXConverter.to_neural_network-874"><span class="linenos"> 874</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-875"><a href="#ONNXConverter.to_neural_network-875"><span class="linenos"> 875</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-876"><a href="#ONNXConverter.to_neural_network-876"><span class="linenos"> 876</span></a>
</span><span id="ONNXConverter.to_neural_network-877"><a href="#ONNXConverter.to_neural_network-877"><span class="linenos"> 877</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-878"><a href="#ONNXConverter.to_neural_network-878"><span class="linenos"> 878</span></a>                                                <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-879"><a href="#ONNXConverter.to_neural_network-879"><span class="linenos"> 879</span></a>
</span><span id="ONNXConverter.to_neural_network-880"><a href="#ONNXConverter.to_neural_network-880"><span class="linenos"> 880</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;AveragePool&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-881"><a href="#ONNXConverter.to_neural_network-881"><span class="linenos"> 881</span></a>
</span><span id="ONNXConverter.to_neural_network-882"><a href="#ONNXConverter.to_neural_network-882"><span class="linenos"> 882</span></a>                <span class="c1"># TODO: at present we do not support auto_pad.</span>
</span><span id="ONNXConverter.to_neural_network-883"><a href="#ONNXConverter.to_neural_network-883"><span class="linenos"> 883</span></a>
</span><span id="ONNXConverter.to_neural_network-884"><a href="#ONNXConverter.to_neural_network-884"><span class="linenos"> 884</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-885"><a href="#ONNXConverter.to_neural_network-885"><span class="linenos"> 885</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-886"><a href="#ONNXConverter.to_neural_network-886"><span class="linenos"> 886</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-887"><a href="#ONNXConverter.to_neural_network-887"><span class="linenos"> 887</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-888"><a href="#ONNXConverter.to_neural_network-888"><span class="linenos"> 888</span></a>
</span><span id="ONNXConverter.to_neural_network-889"><a href="#ONNXConverter.to_neural_network-889"><span class="linenos"> 889</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-890"><a href="#ONNXConverter.to_neural_network-890"><span class="linenos"> 890</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-891"><a href="#ONNXConverter.to_neural_network-891"><span class="linenos"> 891</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-892"><a href="#ONNXConverter.to_neural_network-892"><span class="linenos"> 892</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;count_include_pad&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-893"><a href="#ONNXConverter.to_neural_network-893"><span class="linenos"> 893</span></a>                        <span class="n">count_include_pad</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-894"><a href="#ONNXConverter.to_neural_network-894"><span class="linenos"> 894</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-895"><a href="#ONNXConverter.to_neural_network-895"><span class="linenos"> 895</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-896"><a href="#ONNXConverter.to_neural_network-896"><span class="linenos"> 896</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-897"><a href="#ONNXConverter.to_neural_network-897"><span class="linenos"> 897</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-898"><a href="#ONNXConverter.to_neural_network-898"><span class="linenos"> 898</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-899"><a href="#ONNXConverter.to_neural_network-899"><span class="linenos"> 899</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-900"><a href="#ONNXConverter.to_neural_network-900"><span class="linenos"> 900</span></a>
</span><span id="ONNXConverter.to_neural_network-901"><a href="#ONNXConverter.to_neural_network-901"><span class="linenos"> 901</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-902"><a href="#ONNXConverter.to_neural_network-902"><span class="linenos"> 902</span></a>                                                       <span class="n">padding</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-903"><a href="#ONNXConverter.to_neural_network-903"><span class="linenos"> 903</span></a>
</span><span id="ONNXConverter.to_neural_network-904"><a href="#ONNXConverter.to_neural_network-904"><span class="linenos"> 904</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MaxPool&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-905"><a href="#ONNXConverter.to_neural_network-905"><span class="linenos"> 905</span></a>
</span><span id="ONNXConverter.to_neural_network-906"><a href="#ONNXConverter.to_neural_network-906"><span class="linenos"> 906</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ONNXConverter.to_neural_network-907"><a href="#ONNXConverter.to_neural_network-907"><span class="linenos"> 907</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-908"><a href="#ONNXConverter.to_neural_network-908"><span class="linenos"> 908</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-909"><a href="#ONNXConverter.to_neural_network-909"><span class="linenos"> 909</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">intc</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-910"><a href="#ONNXConverter.to_neural_network-910"><span class="linenos"> 910</span></a>
</span><span id="ONNXConverter.to_neural_network-911"><a href="#ONNXConverter.to_neural_network-911"><span class="linenos"> 911</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-912"><a href="#ONNXConverter.to_neural_network-912"><span class="linenos"> 912</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;ceil_mode&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-913"><a href="#ONNXConverter.to_neural_network-913"><span class="linenos"> 913</span></a>                        <span class="n">ceil_mode</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">i</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-914"><a href="#ONNXConverter.to_neural_network-914"><span class="linenos"> 914</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;dilations&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-915"><a href="#ONNXConverter.to_neural_network-915"><span class="linenos"> 915</span></a>                        <span class="n">dilation</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-916"><a href="#ONNXConverter.to_neural_network-916"><span class="linenos"> 916</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;kernel_shape&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-917"><a href="#ONNXConverter.to_neural_network-917"><span class="linenos"> 917</span></a>                        <span class="n">kernel_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-918"><a href="#ONNXConverter.to_neural_network-918"><span class="linenos"> 918</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;pads&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-919"><a href="#ONNXConverter.to_neural_network-919"><span class="linenos"> 919</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-920"><a href="#ONNXConverter.to_neural_network-920"><span class="linenos"> 920</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;strides&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-921"><a href="#ONNXConverter.to_neural_network-921"><span class="linenos"> 921</span></a>                        <span class="n">stride</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span>
</span><span id="ONNXConverter.to_neural_network-922"><a href="#ONNXConverter.to_neural_network-922"><span class="linenos"> 922</span></a>
</span><span id="ONNXConverter.to_neural_network-923"><a href="#ONNXConverter.to_neural_network-923"><span class="linenos"> 923</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="ONNXConverter.to_neural_network-924"><a href="#ONNXConverter.to_neural_network-924"><span class="linenos"> 924</span></a>                                                   <span class="n">dilation</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-925"><a href="#ONNXConverter.to_neural_network-925"><span class="linenos"> 925</span></a>
</span><span id="ONNXConverter.to_neural_network-926"><a href="#ONNXConverter.to_neural_network-926"><span class="linenos"> 926</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;LRN&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-927"><a href="#ONNXConverter.to_neural_network-927"><span class="linenos"> 927</span></a>
</span><span id="ONNXConverter.to_neural_network-928"><a href="#ONNXConverter.to_neural_network-928"><span class="linenos"> 928</span></a>                <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.0001</span>
</span><span id="ONNXConverter.to_neural_network-929"><a href="#ONNXConverter.to_neural_network-929"><span class="linenos"> 929</span></a>                <span class="n">beta</span> <span class="o">=</span> <span class="mf">0.75</span>
</span><span id="ONNXConverter.to_neural_network-930"><a href="#ONNXConverter.to_neural_network-930"><span class="linenos"> 930</span></a>                <span class="n">k</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="ONNXConverter.to_neural_network-931"><a href="#ONNXConverter.to_neural_network-931"><span class="linenos"> 931</span></a>
</span><span id="ONNXConverter.to_neural_network-932"><a href="#ONNXConverter.to_neural_network-932"><span class="linenos"> 932</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-933"><a href="#ONNXConverter.to_neural_network-933"><span class="linenos"> 933</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-934"><a href="#ONNXConverter.to_neural_network-934"><span class="linenos"> 934</span></a>                        <span class="n">alpha</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-935"><a href="#ONNXConverter.to_neural_network-935"><span class="linenos"> 935</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;beta&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-936"><a href="#ONNXConverter.to_neural_network-936"><span class="linenos"> 936</span></a>                        <span class="n">beta</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-937"><a href="#ONNXConverter.to_neural_network-937"><span class="linenos"> 937</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;bias&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-938"><a href="#ONNXConverter.to_neural_network-938"><span class="linenos"> 938</span></a>                        <span class="n">k</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">f</span>
</span><span id="ONNXConverter.to_neural_network-939"><a href="#ONNXConverter.to_neural_network-939"><span class="linenos"> 939</span></a>                    <span class="k">elif</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-940"><a href="#ONNXConverter.to_neural_network-940"><span class="linenos"> 940</span></a>                        <span class="n">size</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter.to_neural_network-941"><a href="#ONNXConverter.to_neural_network-941"><span class="linenos"> 941</span></a>
</span><span id="ONNXConverter.to_neural_network-942"><a href="#ONNXConverter.to_neural_network-942"><span class="linenos"> 942</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-943"><a href="#ONNXConverter.to_neural_network-943"><span class="linenos"> 943</span></a>
</span><span id="ONNXConverter.to_neural_network-944"><a href="#ONNXConverter.to_neural_network-944"><span class="linenos"> 944</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Softmax&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-945"><a href="#ONNXConverter.to_neural_network-945"><span class="linenos"> 945</span></a>
</span><span id="ONNXConverter.to_neural_network-946"><a href="#ONNXConverter.to_neural_network-946"><span class="linenos"> 946</span></a>                <span class="c1"># Since the ONNX representation consider the batch dimension we need to scale the axis by 1</span>
</span><span id="ONNXConverter.to_neural_network-947"><a href="#ONNXConverter.to_neural_network-947"><span class="linenos"> 947</span></a>                <span class="c1"># when we pass to our representation.</span>
</span><span id="ONNXConverter.to_neural_network-948"><a href="#ONNXConverter.to_neural_network-948"><span class="linenos"> 948</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-949"><a href="#ONNXConverter.to_neural_network-949"><span class="linenos"> 949</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-950"><a href="#ONNXConverter.to_neural_network-950"><span class="linenos"> 950</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-951"><a href="#ONNXConverter.to_neural_network-951"><span class="linenos"> 951</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-952"><a href="#ONNXConverter.to_neural_network-952"><span class="linenos"> 952</span></a>
</span><span id="ONNXConverter.to_neural_network-953"><a href="#ONNXConverter.to_neural_network-953"><span class="linenos"> 953</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-954"><a href="#ONNXConverter.to_neural_network-954"><span class="linenos"> 954</span></a>
</span><span id="ONNXConverter.to_neural_network-955"><a href="#ONNXConverter.to_neural_network-955"><span class="linenos"> 955</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Unsqueeze&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-956"><a href="#ONNXConverter.to_neural_network-956"><span class="linenos"> 956</span></a>
</span><span id="ONNXConverter.to_neural_network-957"><a href="#ONNXConverter.to_neural_network-957"><span class="linenos"> 957</span></a>                <span class="n">temp_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="ONNXConverter.to_neural_network-958"><a href="#ONNXConverter.to_neural_network-958"><span class="linenos"> 958</span></a>                <span class="c1"># Since our representation do not consider the batch dimension we need to scale all the axes</span>
</span><span id="ONNXConverter.to_neural_network-959"><a href="#ONNXConverter.to_neural_network-959"><span class="linenos"> 959</span></a>                <span class="c1"># by 1 when we pass to the onnx representation.</span>
</span><span id="ONNXConverter.to_neural_network-960"><a href="#ONNXConverter.to_neural_network-960"><span class="linenos"> 960</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">temp_axes</span><span class="p">])</span>
</span><span id="ONNXConverter.to_neural_network-961"><a href="#ONNXConverter.to_neural_network-961"><span class="linenos"> 961</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-962"><a href="#ONNXConverter.to_neural_network-962"><span class="linenos"> 962</span></a>
</span><span id="ONNXConverter.to_neural_network-963"><a href="#ONNXConverter.to_neural_network-963"><span class="linenos"> 963</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Reshape&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-964"><a href="#ONNXConverter.to_neural_network-964"><span class="linenos"> 964</span></a>
</span><span id="ONNXConverter.to_neural_network-965"><a href="#ONNXConverter.to_neural_network-965"><span class="linenos"> 965</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
</span><span id="ONNXConverter.to_neural_network-966"><a href="#ONNXConverter.to_neural_network-966"><span class="linenos"> 966</span></a>                <span class="c1"># We need to eliminate the first dimension corresponding to the batch dimension</span>
</span><span id="ONNXConverter.to_neural_network-967"><a href="#ONNXConverter.to_neural_network-967"><span class="linenos"> 967</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="ONNXConverter.to_neural_network-968"><a href="#ONNXConverter.to_neural_network-968"><span class="linenos"> 968</span></a>                <span class="n">allow_zero</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ONNXConverter.to_neural_network-969"><a href="#ONNXConverter.to_neural_network-969"><span class="linenos"> 969</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-970"><a href="#ONNXConverter.to_neural_network-970"><span class="linenos"> 970</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;allowzero&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-971"><a href="#ONNXConverter.to_neural_network-971"><span class="linenos"> 971</span></a>                        <span class="n">allow_zero</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span>
</span><span id="ONNXConverter.to_neural_network-972"><a href="#ONNXConverter.to_neural_network-972"><span class="linenos"> 972</span></a>
</span><span id="ONNXConverter.to_neural_network-973"><a href="#ONNXConverter.to_neural_network-973"><span class="linenos"> 973</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">allow_zero</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-974"><a href="#ONNXConverter.to_neural_network-974"><span class="linenos"> 974</span></a>
</span><span id="ONNXConverter.to_neural_network-975"><a href="#ONNXConverter.to_neural_network-975"><span class="linenos"> 975</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Flatten&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-976"><a href="#ONNXConverter.to_neural_network-976"><span class="linenos"> 976</span></a>
</span><span id="ONNXConverter.to_neural_network-977"><a href="#ONNXConverter.to_neural_network-977"><span class="linenos"> 977</span></a>                <span class="c1"># We need to scale the axis value since our representation does not have the batch dimension</span>
</span><span id="ONNXConverter.to_neural_network-978"><a href="#ONNXConverter.to_neural_network-978"><span class="linenos"> 978</span></a>                <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="ONNXConverter.to_neural_network-979"><a href="#ONNXConverter.to_neural_network-979"><span class="linenos"> 979</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-980"><a href="#ONNXConverter.to_neural_network-980"><span class="linenos"> 980</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;axis&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-981"><a href="#ONNXConverter.to_neural_network-981"><span class="linenos"> 981</span></a>                        <span class="n">axis</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-982"><a href="#ONNXConverter.to_neural_network-982"><span class="linenos"> 982</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-983"><a href="#ONNXConverter.to_neural_network-983"><span class="linenos"> 983</span></a>
</span><span id="ONNXConverter.to_neural_network-984"><a href="#ONNXConverter.to_neural_network-984"><span class="linenos"> 984</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Dropout&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-985"><a href="#ONNXConverter.to_neural_network-985"><span class="linenos"> 985</span></a>
</span><span id="ONNXConverter.to_neural_network-986"><a href="#ONNXConverter.to_neural_network-986"><span class="linenos"> 986</span></a>                <span class="n">ratio</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ONNXConverter.to_neural_network-987"><a href="#ONNXConverter.to_neural_network-987"><span class="linenos"> 987</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">ratio</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-988"><a href="#ONNXConverter.to_neural_network-988"><span class="linenos"> 988</span></a>
</span><span id="ONNXConverter.to_neural_network-989"><a href="#ONNXConverter.to_neural_network-989"><span class="linenos"> 989</span></a>            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Transpose&quot;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-990"><a href="#ONNXConverter.to_neural_network-990"><span class="linenos"> 990</span></a>
</span><span id="ONNXConverter.to_neural_network-991"><a href="#ONNXConverter.to_neural_network-991"><span class="linenos"> 991</span></a>                <span class="n">perm</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="ONNXConverter.to_neural_network-992"><a href="#ONNXConverter.to_neural_network-992"><span class="linenos"> 992</span></a>                <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-993"><a href="#ONNXConverter.to_neural_network-993"><span class="linenos"> 993</span></a>                    <span class="k">if</span> <span class="n">att</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;perm&#39;</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-994"><a href="#ONNXConverter.to_neural_network-994"><span class="linenos"> 994</span></a>                        <span class="c1"># Must manage batch dimension</span>
</span><span id="ONNXConverter.to_neural_network-995"><a href="#ONNXConverter.to_neural_network-995"><span class="linenos"> 995</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_dim</span><span class="p">):</span>
</span><span id="ONNXConverter.to_neural_network-996"><a href="#ONNXConverter.to_neural_network-996"><span class="linenos"> 996</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att</span><span class="o">.</span><span class="n">ints</span><span class="p">))]</span>
</span><span id="ONNXConverter.to_neural_network-997"><a href="#ONNXConverter.to_neural_network-997"><span class="linenos"> 997</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-998"><a href="#ONNXConverter.to_neural_network-998"><span class="linenos"> 998</span></a>                            <span class="n">perm</span> <span class="o">=</span> <span class="n">att</span><span class="o">.</span><span class="n">ints</span>
</span><span id="ONNXConverter.to_neural_network-999"><a href="#ONNXConverter.to_neural_network-999"><span class="linenos"> 999</span></a>
</span><span id="ONNXConverter.to_neural_network-1000"><a href="#ONNXConverter.to_neural_network-1000"><span class="linenos">1000</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">TransposeNode</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">perm</span><span class="p">))</span>
</span><span id="ONNXConverter.to_neural_network-1001"><a href="#ONNXConverter.to_neural_network-1001"><span class="linenos">1001</span></a>
</span><span id="ONNXConverter.to_neural_network-1002"><a href="#ONNXConverter.to_neural_network-1002"><span class="linenos">1002</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ONNXConverter.to_neural_network-1003"><a href="#ONNXConverter.to_neural_network-1003"><span class="linenos">1003</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="ONNXConverter.to_neural_network-1004"><a href="#ONNXConverter.to_neural_network-1004"><span class="linenos">1004</span></a>
</span><span id="ONNXConverter.to_neural_network-1005"><a href="#ONNXConverter.to_neural_network-1005"><span class="linenos">1005</span></a>            <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="ONNXConverter.to_neural_network-1006"><a href="#ONNXConverter.to_neural_network-1006"><span class="linenos">1006</span></a>            <span class="n">in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="ONNXConverter.to_neural_network-1007"><a href="#ONNXConverter.to_neural_network-1007"><span class="linenos">1007</span></a>
</span><span id="ONNXConverter.to_neural_network-1008"><a href="#ONNXConverter.to_neural_network-1008"><span class="linenos">1008</span></a>        <span class="k">return</span> <span class="n">network</span>
</span></pre></div>


            <div class="docstring"><p>Convert the ONNX representation of interest to the internal one.</p>

<h2 id="parameters">Parameters</h2>

<p>alt_rep : ONNXNetwork
    The ONNX Representation to convert.</p>

<h2 id="returns">Returns</h2>

<p>NeuralNetwork
    The Neural Network resulting from the conversion of ONNX Representation.</p>
</div>


                            </div>
                </section>
                <section id="PyTorchConverter">
                            <input id="PyTorchConverter-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PyTorchConverter</span><wbr>(<span class="base"><a href="#ConversionStrategy">ConversionStrategy</a></span>):

                <label class="view-source-button" for="PyTorchConverter-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PyTorchConverter"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PyTorchConverter-1011"><a href="#PyTorchConverter-1011"><span class="linenos">1011</span></a><span class="k">class</span> <span class="nc">PyTorchConverter</span><span class="p">(</span><span class="n">ConversionStrategy</span><span class="p">):</span>
</span><span id="PyTorchConverter-1012"><a href="#PyTorchConverter-1012"><span class="linenos">1012</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1013"><a href="#PyTorchConverter-1013"><span class="linenos">1013</span></a><span class="sd">    A class used to represent the conversion strategy for PyTorch models.</span>
</span><span id="PyTorchConverter-1014"><a href="#PyTorchConverter-1014"><span class="linenos">1014</span></a>
</span><span id="PyTorchConverter-1015"><a href="#PyTorchConverter-1015"><span class="linenos">1015</span></a><span class="sd">    Methods</span>
</span><span id="PyTorchConverter-1016"><a href="#PyTorchConverter-1016"><span class="linenos">1016</span></a><span class="sd">    ----------</span>
</span><span id="PyTorchConverter-1017"><a href="#PyTorchConverter-1017"><span class="linenos">1017</span></a><span class="sd">    from_neural_network(NeuralNetwork)</span>
</span><span id="PyTorchConverter-1018"><a href="#PyTorchConverter-1018"><span class="linenos">1018</span></a><span class="sd">        Convert the neural network of interest to a PyTorchNetwork model.</span>
</span><span id="PyTorchConverter-1019"><a href="#PyTorchConverter-1019"><span class="linenos">1019</span></a><span class="sd">    to_neural_network(PyTorchNetwork)</span>
</span><span id="PyTorchConverter-1020"><a href="#PyTorchConverter-1020"><span class="linenos">1020</span></a><span class="sd">        Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.</span>
</span><span id="PyTorchConverter-1021"><a href="#PyTorchConverter-1021"><span class="linenos">1021</span></a>
</span><span id="PyTorchConverter-1022"><a href="#PyTorchConverter-1022"><span class="linenos">1022</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1023"><a href="#PyTorchConverter-1023"><span class="linenos">1023</span></a>
</span><span id="PyTorchConverter-1024"><a href="#PyTorchConverter-1024"><span class="linenos">1024</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PyTorchNetwork</span><span class="p">:</span>
</span><span id="PyTorchConverter-1025"><a href="#PyTorchConverter-1025"><span class="linenos">1025</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1026"><a href="#PyTorchConverter-1026"><span class="linenos">1026</span></a><span class="sd">        Convert the neural network of interest to a PyTorch representation.</span>
</span><span id="PyTorchConverter-1027"><a href="#PyTorchConverter-1027"><span class="linenos">1027</span></a>
</span><span id="PyTorchConverter-1028"><a href="#PyTorchConverter-1028"><span class="linenos">1028</span></a><span class="sd">        Parameters</span>
</span><span id="PyTorchConverter-1029"><a href="#PyTorchConverter-1029"><span class="linenos">1029</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter-1030"><a href="#PyTorchConverter-1030"><span class="linenos">1030</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="PyTorchConverter-1031"><a href="#PyTorchConverter-1031"><span class="linenos">1031</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="PyTorchConverter-1032"><a href="#PyTorchConverter-1032"><span class="linenos">1032</span></a>
</span><span id="PyTorchConverter-1033"><a href="#PyTorchConverter-1033"><span class="linenos">1033</span></a><span class="sd">        Returns</span>
</span><span id="PyTorchConverter-1034"><a href="#PyTorchConverter-1034"><span class="linenos">1034</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter-1035"><a href="#PyTorchConverter-1035"><span class="linenos">1035</span></a><span class="sd">        PyTorchNetwork</span>
</span><span id="PyTorchConverter-1036"><a href="#PyTorchConverter-1036"><span class="linenos">1036</span></a><span class="sd">            The PyTorch representation resulting from the conversion of the original network.</span>
</span><span id="PyTorchConverter-1037"><a href="#PyTorchConverter-1037"><span class="linenos">1037</span></a>
</span><span id="PyTorchConverter-1038"><a href="#PyTorchConverter-1038"><span class="linenos">1038</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1039"><a href="#PyTorchConverter-1039"><span class="linenos">1039</span></a>
</span><span id="PyTorchConverter-1040"><a href="#PyTorchConverter-1040"><span class="linenos">1040</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1041"><a href="#PyTorchConverter-1041"><span class="linenos">1041</span></a>        <span class="n">pytorch_network</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1042"><a href="#PyTorchConverter-1042"><span class="linenos">1042</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="PyTorchConverter-1043"><a href="#PyTorchConverter-1043"><span class="linenos">1043</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter-1044"><a href="#PyTorchConverter-1044"><span class="linenos">1044</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="PyTorchConverter-1045"><a href="#PyTorchConverter-1045"><span class="linenos">1045</span></a>
</span><span id="PyTorchConverter-1046"><a href="#PyTorchConverter-1046"><span class="linenos">1046</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1047"><a href="#PyTorchConverter-1047"><span class="linenos">1047</span></a>
</span><span id="PyTorchConverter-1048"><a href="#PyTorchConverter-1048"><span class="linenos">1048</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter-1049"><a href="#PyTorchConverter-1049"><span class="linenos">1049</span></a>
</span><span id="PyTorchConverter-1050"><a href="#PyTorchConverter-1050"><span class="linenos">1050</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="PyTorchConverter-1051"><a href="#PyTorchConverter-1051"><span class="linenos">1051</span></a>
</span><span id="PyTorchConverter-1052"><a href="#PyTorchConverter-1052"><span class="linenos">1052</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter-1053"><a href="#PyTorchConverter-1053"><span class="linenos">1053</span></a>
</span><span id="PyTorchConverter-1054"><a href="#PyTorchConverter-1054"><span class="linenos">1054</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">):</span>
</span><span id="PyTorchConverter-1055"><a href="#PyTorchConverter-1055"><span class="linenos">1055</span></a>                            <span class="n">onnx_cv</span> <span class="o">=</span> <span class="n">ONNXConverter</span><span class="p">()</span>
</span><span id="PyTorchConverter-1056"><a href="#PyTorchConverter-1056"><span class="linenos">1056</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">onnx_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="PyTorchConverter-1057"><a href="#PyTorchConverter-1057"><span class="linenos">1057</span></a>
</span><span id="PyTorchConverter-1058"><a href="#PyTorchConverter-1058"><span class="linenos">1058</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1059"><a href="#PyTorchConverter-1059"><span class="linenos">1059</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter-1060"><a href="#PyTorchConverter-1060"><span class="linenos">1060</span></a>                        <span class="k">break</span>
</span><span id="PyTorchConverter-1061"><a href="#PyTorchConverter-1061"><span class="linenos">1061</span></a>
</span><span id="PyTorchConverter-1062"><a href="#PyTorchConverter-1062"><span class="linenos">1062</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="PyTorchConverter-1063"><a href="#PyTorchConverter-1063"><span class="linenos">1063</span></a>                <span class="n">pytorch_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PyTorchConverter-1064"><a href="#PyTorchConverter-1064"><span class="linenos">1064</span></a>                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
</span><span id="PyTorchConverter-1065"><a href="#PyTorchConverter-1065"><span class="linenos">1065</span></a>
</span><span id="PyTorchConverter-1066"><a href="#PyTorchConverter-1066"><span class="linenos">1066</span></a>                    <span class="n">new_layer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1067"><a href="#PyTorchConverter-1067"><span class="linenos">1067</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1068"><a href="#PyTorchConverter-1068"><span class="linenos">1068</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1069"><a href="#PyTorchConverter-1069"><span class="linenos">1069</span></a>
</span><span id="PyTorchConverter-1070"><a href="#PyTorchConverter-1070"><span class="linenos">1070</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1071"><a href="#PyTorchConverter-1071"><span class="linenos">1071</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter-1072"><a href="#PyTorchConverter-1072"><span class="linenos">1072</span></a>
</span><span id="PyTorchConverter-1073"><a href="#PyTorchConverter-1073"><span class="linenos">1073</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1074"><a href="#PyTorchConverter-1074"><span class="linenos">1074</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="PyTorchConverter-1075"><a href="#PyTorchConverter-1075"><span class="linenos">1075</span></a>
</span><span id="PyTorchConverter-1076"><a href="#PyTorchConverter-1076"><span class="linenos">1076</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1077"><a href="#PyTorchConverter-1077"><span class="linenos">1077</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter-1078"><a href="#PyTorchConverter-1078"><span class="linenos">1078</span></a>
</span><span id="PyTorchConverter-1079"><a href="#PyTorchConverter-1079"><span class="linenos">1079</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1080"><a href="#PyTorchConverter-1080"><span class="linenos">1080</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1081"><a href="#PyTorchConverter-1081"><span class="linenos">1081</span></a>
</span><span id="PyTorchConverter-1082"><a href="#PyTorchConverter-1082"><span class="linenos">1082</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1083"><a href="#PyTorchConverter-1083"><span class="linenos">1083</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1084"><a href="#PyTorchConverter-1084"><span class="linenos">1084</span></a>
</span><span id="PyTorchConverter-1085"><a href="#PyTorchConverter-1085"><span class="linenos">1085</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1086"><a href="#PyTorchConverter-1086"><span class="linenos">1086</span></a>
</span><span id="PyTorchConverter-1087"><a href="#PyTorchConverter-1087"><span class="linenos">1087</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1088"><a href="#PyTorchConverter-1088"><span class="linenos">1088</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter-1089"><a href="#PyTorchConverter-1089"><span class="linenos">1089</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1090"><a href="#PyTorchConverter-1090"><span class="linenos">1090</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter-1091"><a href="#PyTorchConverter-1091"><span class="linenos">1091</span></a>
</span><span id="PyTorchConverter-1092"><a href="#PyTorchConverter-1092"><span class="linenos">1092</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1093"><a href="#PyTorchConverter-1093"><span class="linenos">1093</span></a>                                                 <span class="n">in_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span>
</span><span id="PyTorchConverter-1094"><a href="#PyTorchConverter-1094"><span class="linenos">1094</span></a>                                                 <span class="n">bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1095"><a href="#PyTorchConverter-1095"><span class="linenos">1095</span></a>
</span><span id="PyTorchConverter-1096"><a href="#PyTorchConverter-1096"><span class="linenos">1096</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter-1097"><a href="#PyTorchConverter-1097"><span class="linenos">1097</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight</span>
</span><span id="PyTorchConverter-1098"><a href="#PyTorchConverter-1098"><span class="linenos">1098</span></a>
</span><span id="PyTorchConverter-1099"><a href="#PyTorchConverter-1099"><span class="linenos">1099</span></a>                        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
</span><span id="PyTorchConverter-1100"><a href="#PyTorchConverter-1100"><span class="linenos">1100</span></a>                            <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1101"><a href="#PyTorchConverter-1101"><span class="linenos">1101</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">bias</span>
</span><span id="PyTorchConverter-1102"><a href="#PyTorchConverter-1102"><span class="linenos">1102</span></a>
</span><span id="PyTorchConverter-1103"><a href="#PyTorchConverter-1103"><span class="linenos">1103</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1104"><a href="#PyTorchConverter-1104"><span class="linenos">1104</span></a>
</span><span id="PyTorchConverter-1105"><a href="#PyTorchConverter-1105"><span class="linenos">1105</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter-1106"><a href="#PyTorchConverter-1106"><span class="linenos">1106</span></a>
</span><span id="PyTorchConverter-1107"><a href="#PyTorchConverter-1107"><span class="linenos">1107</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1108"><a href="#PyTorchConverter-1108"><span class="linenos">1108</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter-1109"><a href="#PyTorchConverter-1109"><span class="linenos">1109</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter-1110"><a href="#PyTorchConverter-1110"><span class="linenos">1110</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter-1111"><a href="#PyTorchConverter-1111"><span class="linenos">1111</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter-1112"><a href="#PyTorchConverter-1112"><span class="linenos">1112</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter-1113"><a href="#PyTorchConverter-1113"><span class="linenos">1113</span></a>
</span><span id="PyTorchConverter-1114"><a href="#PyTorchConverter-1114"><span class="linenos">1114</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1115"><a href="#PyTorchConverter-1115"><span class="linenos">1115</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter-1116"><a href="#PyTorchConverter-1116"><span class="linenos">1116</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter-1117"><a href="#PyTorchConverter-1117"><span class="linenos">1117</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter-1118"><a href="#PyTorchConverter-1118"><span class="linenos">1118</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter-1119"><a href="#PyTorchConverter-1119"><span class="linenos">1119</span></a>
</span><span id="PyTorchConverter-1120"><a href="#PyTorchConverter-1120"><span class="linenos">1120</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter-1121"><a href="#PyTorchConverter-1121"><span class="linenos">1121</span></a>
</span><span id="PyTorchConverter-1122"><a href="#PyTorchConverter-1122"><span class="linenos">1122</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1123"><a href="#PyTorchConverter-1123"><span class="linenos">1123</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter-1124"><a href="#PyTorchConverter-1124"><span class="linenos">1124</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter-1125"><a href="#PyTorchConverter-1125"><span class="linenos">1125</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter-1126"><a href="#PyTorchConverter-1126"><span class="linenos">1126</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter-1127"><a href="#PyTorchConverter-1127"><span class="linenos">1127</span></a>
</span><span id="PyTorchConverter-1128"><a href="#PyTorchConverter-1128"><span class="linenos">1128</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1129"><a href="#PyTorchConverter-1129"><span class="linenos">1129</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support batchnorm layer for input with more than&quot;</span>
</span><span id="PyTorchConverter-1130"><a href="#PyTorchConverter-1130"><span class="linenos">1130</span></a>                                            <span class="s2">&quot;4 or less than 1 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1131"><a href="#PyTorchConverter-1131"><span class="linenos">1131</span></a>
</span><span id="PyTorchConverter-1132"><a href="#PyTorchConverter-1132"><span class="linenos">1132</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter-1133"><a href="#PyTorchConverter-1133"><span class="linenos">1133</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1134"><a href="#PyTorchConverter-1134"><span class="linenos">1134</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span>
</span><span id="PyTorchConverter-1135"><a href="#PyTorchConverter-1135"><span class="linenos">1135</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_var</span><span class="p">)</span>
</span><span id="PyTorchConverter-1136"><a href="#PyTorchConverter-1136"><span class="linenos">1136</span></a>
</span><span id="PyTorchConverter-1137"><a href="#PyTorchConverter-1137"><span class="linenos">1137</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1138"><a href="#PyTorchConverter-1138"><span class="linenos">1138</span></a>
</span><span id="PyTorchConverter-1139"><a href="#PyTorchConverter-1139"><span class="linenos">1139</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter-1140"><a href="#PyTorchConverter-1140"><span class="linenos">1140</span></a>                        <span class="c1"># symmetric. Padding mode is not supported in our representation therefore we let it be</span>
</span><span id="PyTorchConverter-1141"><a href="#PyTorchConverter-1141"><span class="linenos">1141</span></a>                        <span class="c1"># set to the default value.</span>
</span><span id="PyTorchConverter-1142"><a href="#PyTorchConverter-1142"><span class="linenos">1142</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter-1143"><a href="#PyTorchConverter-1143"><span class="linenos">1143</span></a>
</span><span id="PyTorchConverter-1144"><a href="#PyTorchConverter-1144"><span class="linenos">1144</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter-1145"><a href="#PyTorchConverter-1145"><span class="linenos">1145</span></a>
</span><span id="PyTorchConverter-1146"><a href="#PyTorchConverter-1146"><span class="linenos">1146</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1147"><a href="#PyTorchConverter-1147"><span class="linenos">1147</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter-1148"><a href="#PyTorchConverter-1148"><span class="linenos">1148</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter-1149"><a href="#PyTorchConverter-1149"><span class="linenos">1149</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1150"><a href="#PyTorchConverter-1150"><span class="linenos">1150</span></a>
</span><span id="PyTorchConverter-1151"><a href="#PyTorchConverter-1151"><span class="linenos">1151</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter-1152"><a href="#PyTorchConverter-1152"><span class="linenos">1152</span></a>
</span><span id="PyTorchConverter-1153"><a href="#PyTorchConverter-1153"><span class="linenos">1153</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1154"><a href="#PyTorchConverter-1154"><span class="linenos">1154</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter-1155"><a href="#PyTorchConverter-1155"><span class="linenos">1155</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter-1156"><a href="#PyTorchConverter-1156"><span class="linenos">1156</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1157"><a href="#PyTorchConverter-1157"><span class="linenos">1157</span></a>
</span><span id="PyTorchConverter-1158"><a href="#PyTorchConverter-1158"><span class="linenos">1158</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter-1159"><a href="#PyTorchConverter-1159"><span class="linenos">1159</span></a>
</span><span id="PyTorchConverter-1160"><a href="#PyTorchConverter-1160"><span class="linenos">1160</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1161"><a href="#PyTorchConverter-1161"><span class="linenos">1161</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter-1162"><a href="#PyTorchConverter-1162"><span class="linenos">1162</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter-1163"><a href="#PyTorchConverter-1163"><span class="linenos">1163</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1164"><a href="#PyTorchConverter-1164"><span class="linenos">1164</span></a>
</span><span id="PyTorchConverter-1165"><a href="#PyTorchConverter-1165"><span class="linenos">1165</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1166"><a href="#PyTorchConverter-1166"><span class="linenos">1166</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="PyTorchConverter-1167"><a href="#PyTorchConverter-1167"><span class="linenos">1167</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1168"><a href="#PyTorchConverter-1168"><span class="linenos">1168</span></a>
</span><span id="PyTorchConverter-1169"><a href="#PyTorchConverter-1169"><span class="linenos">1169</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter-1170"><a href="#PyTorchConverter-1170"><span class="linenos">1170</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="PyTorchConverter-1171"><a href="#PyTorchConverter-1171"><span class="linenos">1171</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1172"><a href="#PyTorchConverter-1172"><span class="linenos">1172</span></a>
</span><span id="PyTorchConverter-1173"><a href="#PyTorchConverter-1173"><span class="linenos">1173</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1174"><a href="#PyTorchConverter-1174"><span class="linenos">1174</span></a>
</span><span id="PyTorchConverter-1175"><a href="#PyTorchConverter-1175"><span class="linenos">1175</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter-1176"><a href="#PyTorchConverter-1176"><span class="linenos">1176</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="PyTorchConverter-1177"><a href="#PyTorchConverter-1177"><span class="linenos">1177</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter-1178"><a href="#PyTorchConverter-1178"><span class="linenos">1178</span></a>
</span><span id="PyTorchConverter-1179"><a href="#PyTorchConverter-1179"><span class="linenos">1179</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter-1180"><a href="#PyTorchConverter-1180"><span class="linenos">1180</span></a>
</span><span id="PyTorchConverter-1181"><a href="#PyTorchConverter-1181"><span class="linenos">1181</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1182"><a href="#PyTorchConverter-1182"><span class="linenos">1182</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1183"><a href="#PyTorchConverter-1183"><span class="linenos">1183</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter-1184"><a href="#PyTorchConverter-1184"><span class="linenos">1184</span></a>
</span><span id="PyTorchConverter-1185"><a href="#PyTorchConverter-1185"><span class="linenos">1185</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter-1186"><a href="#PyTorchConverter-1186"><span class="linenos">1186</span></a>
</span><span id="PyTorchConverter-1187"><a href="#PyTorchConverter-1187"><span class="linenos">1187</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1188"><a href="#PyTorchConverter-1188"><span class="linenos">1188</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1189"><a href="#PyTorchConverter-1189"><span class="linenos">1189</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter-1190"><a href="#PyTorchConverter-1190"><span class="linenos">1190</span></a>
</span><span id="PyTorchConverter-1191"><a href="#PyTorchConverter-1191"><span class="linenos">1191</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter-1192"><a href="#PyTorchConverter-1192"><span class="linenos">1192</span></a>
</span><span id="PyTorchConverter-1193"><a href="#PyTorchConverter-1193"><span class="linenos">1193</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1194"><a href="#PyTorchConverter-1194"><span class="linenos">1194</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1195"><a href="#PyTorchConverter-1195"><span class="linenos">1195</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter-1196"><a href="#PyTorchConverter-1196"><span class="linenos">1196</span></a>
</span><span id="PyTorchConverter-1197"><a href="#PyTorchConverter-1197"><span class="linenos">1197</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1198"><a href="#PyTorchConverter-1198"><span class="linenos">1198</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support AvgPool layer for input with more than&quot;</span>
</span><span id="PyTorchConverter-1199"><a href="#PyTorchConverter-1199"><span class="linenos">1199</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1200"><a href="#PyTorchConverter-1200"><span class="linenos">1200</span></a>
</span><span id="PyTorchConverter-1201"><a href="#PyTorchConverter-1201"><span class="linenos">1201</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1202"><a href="#PyTorchConverter-1202"><span class="linenos">1202</span></a>
</span><span id="PyTorchConverter-1203"><a href="#PyTorchConverter-1203"><span class="linenos">1203</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter-1204"><a href="#PyTorchConverter-1204"><span class="linenos">1204</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="PyTorchConverter-1205"><a href="#PyTorchConverter-1205"><span class="linenos">1205</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter-1206"><a href="#PyTorchConverter-1206"><span class="linenos">1206</span></a>
</span><span id="PyTorchConverter-1207"><a href="#PyTorchConverter-1207"><span class="linenos">1207</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter-1208"><a href="#PyTorchConverter-1208"><span class="linenos">1208</span></a>
</span><span id="PyTorchConverter-1209"><a href="#PyTorchConverter-1209"><span class="linenos">1209</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1210"><a href="#PyTorchConverter-1210"><span class="linenos">1210</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1211"><a href="#PyTorchConverter-1211"><span class="linenos">1211</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter-1212"><a href="#PyTorchConverter-1212"><span class="linenos">1212</span></a>
</span><span id="PyTorchConverter-1213"><a href="#PyTorchConverter-1213"><span class="linenos">1213</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter-1214"><a href="#PyTorchConverter-1214"><span class="linenos">1214</span></a>
</span><span id="PyTorchConverter-1215"><a href="#PyTorchConverter-1215"><span class="linenos">1215</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1216"><a href="#PyTorchConverter-1216"><span class="linenos">1216</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1217"><a href="#PyTorchConverter-1217"><span class="linenos">1217</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter-1218"><a href="#PyTorchConverter-1218"><span class="linenos">1218</span></a>
</span><span id="PyTorchConverter-1219"><a href="#PyTorchConverter-1219"><span class="linenos">1219</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter-1220"><a href="#PyTorchConverter-1220"><span class="linenos">1220</span></a>
</span><span id="PyTorchConverter-1221"><a href="#PyTorchConverter-1221"><span class="linenos">1221</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1222"><a href="#PyTorchConverter-1222"><span class="linenos">1222</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1223"><a href="#PyTorchConverter-1223"><span class="linenos">1223</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter-1224"><a href="#PyTorchConverter-1224"><span class="linenos">1224</span></a>
</span><span id="PyTorchConverter-1225"><a href="#PyTorchConverter-1225"><span class="linenos">1225</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1226"><a href="#PyTorchConverter-1226"><span class="linenos">1226</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="PyTorchConverter-1227"><a href="#PyTorchConverter-1227"><span class="linenos">1227</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1228"><a href="#PyTorchConverter-1228"><span class="linenos">1228</span></a>
</span><span id="PyTorchConverter-1229"><a href="#PyTorchConverter-1229"><span class="linenos">1229</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1230"><a href="#PyTorchConverter-1230"><span class="linenos">1230</span></a>
</span><span id="PyTorchConverter-1231"><a href="#PyTorchConverter-1231"><span class="linenos">1231</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter-1232"><a href="#PyTorchConverter-1232"><span class="linenos">1232</span></a>                                                            <span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="PyTorchConverter-1233"><a href="#PyTorchConverter-1233"><span class="linenos">1233</span></a>
</span><span id="PyTorchConverter-1234"><a href="#PyTorchConverter-1234"><span class="linenos">1234</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1235"><a href="#PyTorchConverter-1235"><span class="linenos">1235</span></a>
</span><span id="PyTorchConverter-1236"><a href="#PyTorchConverter-1236"><span class="linenos">1236</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="PyTorchConverter-1237"><a href="#PyTorchConverter-1237"><span class="linenos">1237</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter-1238"><a href="#PyTorchConverter-1238"><span class="linenos">1238</span></a>
</span><span id="PyTorchConverter-1239"><a href="#PyTorchConverter-1239"><span class="linenos">1239</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1240"><a href="#PyTorchConverter-1240"><span class="linenos">1240</span></a>
</span><span id="PyTorchConverter-1241"><a href="#PyTorchConverter-1241"><span class="linenos">1241</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to scale</span>
</span><span id="PyTorchConverter-1242"><a href="#PyTorchConverter-1242"><span class="linenos">1242</span></a>                        <span class="c1"># the axes values.</span>
</span><span id="PyTorchConverter-1243"><a href="#PyTorchConverter-1243"><span class="linenos">1243</span></a>                        <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="PyTorchConverter-1244"><a href="#PyTorchConverter-1244"><span class="linenos">1244</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="PyTorchConverter-1245"><a href="#PyTorchConverter-1245"><span class="linenos">1245</span></a>
</span><span id="PyTorchConverter-1246"><a href="#PyTorchConverter-1246"><span class="linenos">1246</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1247"><a href="#PyTorchConverter-1247"><span class="linenos">1247</span></a>
</span><span id="PyTorchConverter-1248"><a href="#PyTorchConverter-1248"><span class="linenos">1248</span></a>                        <span class="c1"># Pytorch does not support the allow_zero attribute and the corresponding reshape with 0</span>
</span><span id="PyTorchConverter-1249"><a href="#PyTorchConverter-1249"><span class="linenos">1249</span></a>                        <span class="c1"># dimensions.</span>
</span><span id="PyTorchConverter-1250"><a href="#PyTorchConverter-1250"><span class="linenos">1250</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">allow_zero</span><span class="p">:</span>
</span><span id="PyTorchConverter-1251"><a href="#PyTorchConverter-1251"><span class="linenos">1251</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;allow_zero not supported by pytorch&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1252"><a href="#PyTorchConverter-1252"><span class="linenos">1252</span></a>
</span><span id="PyTorchConverter-1253"><a href="#PyTorchConverter-1253"><span class="linenos">1253</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to add it to</span>
</span><span id="PyTorchConverter-1254"><a href="#PyTorchConverter-1254"><span class="linenos">1254</span></a>                        <span class="c1"># the shape.</span>
</span><span id="PyTorchConverter-1255"><a href="#PyTorchConverter-1255"><span class="linenos">1255</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="PyTorchConverter-1256"><a href="#PyTorchConverter-1256"><span class="linenos">1256</span></a>                        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="PyTorchConverter-1257"><a href="#PyTorchConverter-1257"><span class="linenos">1257</span></a>                            <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter-1258"><a href="#PyTorchConverter-1258"><span class="linenos">1258</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter-1259"><a href="#PyTorchConverter-1259"><span class="linenos">1259</span></a>
</span><span id="PyTorchConverter-1260"><a href="#PyTorchConverter-1260"><span class="linenos">1260</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter-1261"><a href="#PyTorchConverter-1261"><span class="linenos">1261</span></a>
</span><span id="PyTorchConverter-1262"><a href="#PyTorchConverter-1262"><span class="linenos">1262</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1263"><a href="#PyTorchConverter-1263"><span class="linenos">1263</span></a>
</span><span id="PyTorchConverter-1264"><a href="#PyTorchConverter-1264"><span class="linenos">1264</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="PyTorchConverter-1265"><a href="#PyTorchConverter-1265"><span class="linenos">1265</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter-1266"><a href="#PyTorchConverter-1266"><span class="linenos">1266</span></a>
</span><span id="PyTorchConverter-1267"><a href="#PyTorchConverter-1267"><span class="linenos">1267</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="PyTorchConverter-1268"><a href="#PyTorchConverter-1268"><span class="linenos">1268</span></a>
</span><span id="PyTorchConverter-1269"><a href="#PyTorchConverter-1269"><span class="linenos">1269</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="PyTorchConverter-1270"><a href="#PyTorchConverter-1270"><span class="linenos">1270</span></a>
</span><span id="PyTorchConverter-1271"><a href="#PyTorchConverter-1271"><span class="linenos">1271</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1272"><a href="#PyTorchConverter-1272"><span class="linenos">1272</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter-1273"><a href="#PyTorchConverter-1273"><span class="linenos">1273</span></a>
</span><span id="PyTorchConverter-1274"><a href="#PyTorchConverter-1274"><span class="linenos">1274</span></a>                    <span class="k">if</span> <span class="n">new_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1275"><a href="#PyTorchConverter-1275"><span class="linenos">1275</span></a>                        <span class="n">pytorch_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_layer</span><span class="p">)</span>
</span><span id="PyTorchConverter-1276"><a href="#PyTorchConverter-1276"><span class="linenos">1276</span></a>
</span><span id="PyTorchConverter-1277"><a href="#PyTorchConverter-1277"><span class="linenos">1277</span></a>                <span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span><span class="p">,</span> <span class="n">pytorch_layers</span><span class="p">)</span>
</span><span id="PyTorchConverter-1278"><a href="#PyTorchConverter-1278"><span class="linenos">1278</span></a>
</span><span id="PyTorchConverter-1279"><a href="#PyTorchConverter-1279"><span class="linenos">1279</span></a>            <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pytorch_network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1280"><a href="#PyTorchConverter-1280"><span class="linenos">1280</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: network to convert is not valid, the alternative representation is None&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1281"><a href="#PyTorchConverter-1281"><span class="linenos">1281</span></a>
</span><span id="PyTorchConverter-1282"><a href="#PyTorchConverter-1282"><span class="linenos">1282</span></a>            <span class="n">identifier</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter-1283"><a href="#PyTorchConverter-1283"><span class="linenos">1283</span></a>            <span class="n">alt_net</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="o">=</span><span class="n">identifier</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="o">=</span><span class="n">pytorch_network</span><span class="p">)</span>
</span><span id="PyTorchConverter-1284"><a href="#PyTorchConverter-1284"><span class="linenos">1284</span></a>
</span><span id="PyTorchConverter-1285"><a href="#PyTorchConverter-1285"><span class="linenos">1285</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span><span id="PyTorchConverter-1286"><a href="#PyTorchConverter-1286"><span class="linenos">1286</span></a>
</span><span id="PyTorchConverter-1287"><a href="#PyTorchConverter-1287"><span class="linenos">1287</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="PyTorchConverter-1288"><a href="#PyTorchConverter-1288"><span class="linenos">1288</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1289"><a href="#PyTorchConverter-1289"><span class="linenos">1289</span></a><span class="sd">        Convert the PyTorch representation of interest to the internal one.</span>
</span><span id="PyTorchConverter-1290"><a href="#PyTorchConverter-1290"><span class="linenos">1290</span></a>
</span><span id="PyTorchConverter-1291"><a href="#PyTorchConverter-1291"><span class="linenos">1291</span></a><span class="sd">        Parameters</span>
</span><span id="PyTorchConverter-1292"><a href="#PyTorchConverter-1292"><span class="linenos">1292</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter-1293"><a href="#PyTorchConverter-1293"><span class="linenos">1293</span></a><span class="sd">        alt_rep : PyTorchNetwork</span>
</span><span id="PyTorchConverter-1294"><a href="#PyTorchConverter-1294"><span class="linenos">1294</span></a><span class="sd">            The PyTorch Representation to convert.</span>
</span><span id="PyTorchConverter-1295"><a href="#PyTorchConverter-1295"><span class="linenos">1295</span></a>
</span><span id="PyTorchConverter-1296"><a href="#PyTorchConverter-1296"><span class="linenos">1296</span></a><span class="sd">        Returns</span>
</span><span id="PyTorchConverter-1297"><a href="#PyTorchConverter-1297"><span class="linenos">1297</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter-1298"><a href="#PyTorchConverter-1298"><span class="linenos">1298</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="PyTorchConverter-1299"><a href="#PyTorchConverter-1299"><span class="linenos">1299</span></a><span class="sd">            The Neural Network resulting from the conversion of PyTorch Representation.</span>
</span><span id="PyTorchConverter-1300"><a href="#PyTorchConverter-1300"><span class="linenos">1300</span></a>
</span><span id="PyTorchConverter-1301"><a href="#PyTorchConverter-1301"><span class="linenos">1301</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PyTorchConverter-1302"><a href="#PyTorchConverter-1302"><span class="linenos">1302</span></a>
</span><span id="PyTorchConverter-1303"><a href="#PyTorchConverter-1303"><span class="linenos">1303</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter-1304"><a href="#PyTorchConverter-1304"><span class="linenos">1304</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="s1">&#39;input_id&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter-1305"><a href="#PyTorchConverter-1305"><span class="linenos">1305</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="PyTorchConverter-1306"><a href="#PyTorchConverter-1306"><span class="linenos">1306</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1307"><a href="#PyTorchConverter-1307"><span class="linenos">1307</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span>
</span><span id="PyTorchConverter-1308"><a href="#PyTorchConverter-1308"><span class="linenos">1308</span></a>
</span><span id="PyTorchConverter-1309"><a href="#PyTorchConverter-1309"><span class="linenos">1309</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">input_id</span><span class="p">)</span>
</span><span id="PyTorchConverter-1310"><a href="#PyTorchConverter-1310"><span class="linenos">1310</span></a>
</span><span id="PyTorchConverter-1311"><a href="#PyTorchConverter-1311"><span class="linenos">1311</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PyTorchConverter-1312"><a href="#PyTorchConverter-1312"><span class="linenos">1312</span></a>        <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="PyTorchConverter-1313"><a href="#PyTorchConverter-1313"><span class="linenos">1313</span></a>
</span><span id="PyTorchConverter-1314"><a href="#PyTorchConverter-1314"><span class="linenos">1314</span></a>        <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1315"><a href="#PyTorchConverter-1315"><span class="linenos">1315</span></a>
</span><span id="PyTorchConverter-1316"><a href="#PyTorchConverter-1316"><span class="linenos">1316</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span><span id="PyTorchConverter-1317"><a href="#PyTorchConverter-1317"><span class="linenos">1317</span></a>
</span><span id="PyTorchConverter-1318"><a href="#PyTorchConverter-1318"><span class="linenos">1318</span></a>            <span class="c1"># Control input</span>
</span><span id="PyTorchConverter-1319"><a href="#PyTorchConverter-1319"><span class="linenos">1319</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;in_dim&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter-1320"><a href="#PyTorchConverter-1320"><span class="linenos">1320</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span>
</span><span id="PyTorchConverter-1321"><a href="#PyTorchConverter-1321"><span class="linenos">1321</span></a>
</span><span id="PyTorchConverter-1322"><a href="#PyTorchConverter-1322"><span class="linenos">1322</span></a>            <span class="k">if</span> <span class="n">layer_in_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="PyTorchConverter-1323"><a href="#PyTorchConverter-1323"><span class="linenos">1323</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Please provide input dimension for the network:&#39;</span><span class="p">)</span>
</span><span id="PyTorchConverter-1324"><a href="#PyTorchConverter-1324"><span class="linenos">1324</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="nb">input</span><span class="p">()</span>
</span><span id="PyTorchConverter-1325"><a href="#PyTorchConverter-1325"><span class="linenos">1325</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_in_dim</span><span class="p">,)</span>
</span><span id="PyTorchConverter-1326"><a href="#PyTorchConverter-1326"><span class="linenos">1326</span></a>
</span><span id="PyTorchConverter-1327"><a href="#PyTorchConverter-1327"><span class="linenos">1327</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;identifier&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter-1328"><a href="#PyTorchConverter-1328"><span class="linenos">1328</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter-1329"><a href="#PyTorchConverter-1329"><span class="linenos">1329</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1330"><a href="#PyTorchConverter-1330"><span class="linenos">1330</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Layer</span><span class="si">{</span><span class="n">node_index</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="PyTorchConverter-1331"><a href="#PyTorchConverter-1331"><span class="linenos">1331</span></a>
</span><span id="PyTorchConverter-1332"><a href="#PyTorchConverter-1332"><span class="linenos">1332</span></a>            <span class="c1"># Read node</span>
</span><span id="PyTorchConverter-1333"><a href="#PyTorchConverter-1333"><span class="linenos">1333</span></a>            <span class="n">new_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1334"><a href="#PyTorchConverter-1334"><span class="linenos">1334</span></a>
</span><span id="PyTorchConverter-1335"><a href="#PyTorchConverter-1335"><span class="linenos">1335</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
</span><span id="PyTorchConverter-1336"><a href="#PyTorchConverter-1336"><span class="linenos">1336</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1337"><a href="#PyTorchConverter-1337"><span class="linenos">1337</span></a>
</span><span id="PyTorchConverter-1338"><a href="#PyTorchConverter-1338"><span class="linenos">1338</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">):</span>
</span><span id="PyTorchConverter-1339"><a href="#PyTorchConverter-1339"><span class="linenos">1339</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter-1340"><a href="#PyTorchConverter-1340"><span class="linenos">1340</span></a>
</span><span id="PyTorchConverter-1341"><a href="#PyTorchConverter-1341"><span class="linenos">1341</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">):</span>
</span><span id="PyTorchConverter-1342"><a href="#PyTorchConverter-1342"><span class="linenos">1342</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="PyTorchConverter-1343"><a href="#PyTorchConverter-1343"><span class="linenos">1343</span></a>
</span><span id="PyTorchConverter-1344"><a href="#PyTorchConverter-1344"><span class="linenos">1344</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">):</span>
</span><span id="PyTorchConverter-1345"><a href="#PyTorchConverter-1345"><span class="linenos">1345</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter-1346"><a href="#PyTorchConverter-1346"><span class="linenos">1346</span></a>
</span><span id="PyTorchConverter-1347"><a href="#PyTorchConverter-1347"><span class="linenos">1347</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">):</span>
</span><span id="PyTorchConverter-1348"><a href="#PyTorchConverter-1348"><span class="linenos">1348</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1349"><a href="#PyTorchConverter-1349"><span class="linenos">1349</span></a>
</span><span id="PyTorchConverter-1350"><a href="#PyTorchConverter-1350"><span class="linenos">1350</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">):</span>
</span><span id="PyTorchConverter-1351"><a href="#PyTorchConverter-1351"><span class="linenos">1351</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter-1352"><a href="#PyTorchConverter-1352"><span class="linenos">1352</span></a>
</span><span id="PyTorchConverter-1353"><a href="#PyTorchConverter-1353"><span class="linenos">1353</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
</span><span id="PyTorchConverter-1354"><a href="#PyTorchConverter-1354"><span class="linenos">1354</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_features</span>
</span><span id="PyTorchConverter-1355"><a href="#PyTorchConverter-1355"><span class="linenos">1355</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1356"><a href="#PyTorchConverter-1356"><span class="linenos">1356</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1357"><a href="#PyTorchConverter-1357"><span class="linenos">1357</span></a>                <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter-1358"><a href="#PyTorchConverter-1358"><span class="linenos">1358</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1359"><a href="#PyTorchConverter-1359"><span class="linenos">1359</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1360"><a href="#PyTorchConverter-1360"><span class="linenos">1360</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter-1361"><a href="#PyTorchConverter-1361"><span class="linenos">1361</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter-1362"><a href="#PyTorchConverter-1362"><span class="linenos">1362</span></a>
</span><span id="PyTorchConverter-1363"><a href="#PyTorchConverter-1363"><span class="linenos">1363</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter-1364"><a href="#PyTorchConverter-1364"><span class="linenos">1364</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">):</span>
</span><span id="PyTorchConverter-1365"><a href="#PyTorchConverter-1365"><span class="linenos">1365</span></a>
</span><span id="PyTorchConverter-1366"><a href="#PyTorchConverter-1366"><span class="linenos">1366</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">eps</span>
</span><span id="PyTorchConverter-1367"><a href="#PyTorchConverter-1367"><span class="linenos">1367</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">momentum</span>
</span><span id="PyTorchConverter-1368"><a href="#PyTorchConverter-1368"><span class="linenos">1368</span></a>                <span class="n">track_running_stats</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">track_running_stats</span>
</span><span id="PyTorchConverter-1369"><a href="#PyTorchConverter-1369"><span class="linenos">1369</span></a>                <span class="n">affine</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">affine</span>
</span><span id="PyTorchConverter-1370"><a href="#PyTorchConverter-1370"><span class="linenos">1370</span></a>
</span><span id="PyTorchConverter-1371"><a href="#PyTorchConverter-1371"><span class="linenos">1371</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1372"><a href="#PyTorchConverter-1372"><span class="linenos">1372</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1373"><a href="#PyTorchConverter-1373"><span class="linenos">1373</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1374"><a href="#PyTorchConverter-1374"><span class="linenos">1374</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1375"><a href="#PyTorchConverter-1375"><span class="linenos">1375</span></a>
</span><span id="PyTorchConverter-1376"><a href="#PyTorchConverter-1376"><span class="linenos">1376</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="PyTorchConverter-1377"><a href="#PyTorchConverter-1377"><span class="linenos">1377</span></a>                                               <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter-1378"><a href="#PyTorchConverter-1378"><span class="linenos">1378</span></a>                                               <span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter-1379"><a href="#PyTorchConverter-1379"><span class="linenos">1379</span></a>
</span><span id="PyTorchConverter-1380"><a href="#PyTorchConverter-1380"><span class="linenos">1380</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
</span><span id="PyTorchConverter-1381"><a href="#PyTorchConverter-1381"><span class="linenos">1381</span></a>
</span><span id="PyTorchConverter-1382"><a href="#PyTorchConverter-1382"><span class="linenos">1382</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_channels</span>
</span><span id="PyTorchConverter-1383"><a href="#PyTorchConverter-1383"><span class="linenos">1383</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter-1384"><a href="#PyTorchConverter-1384"><span class="linenos">1384</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter-1385"><a href="#PyTorchConverter-1385"><span class="linenos">1385</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1386"><a href="#PyTorchConverter-1386"><span class="linenos">1386</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter-1387"><a href="#PyTorchConverter-1387"><span class="linenos">1387</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter-1388"><a href="#PyTorchConverter-1388"><span class="linenos">1388</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1389"><a href="#PyTorchConverter-1389"><span class="linenos">1389</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="PyTorchConverter-1390"><a href="#PyTorchConverter-1390"><span class="linenos">1390</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">groups</span>
</span><span id="PyTorchConverter-1391"><a href="#PyTorchConverter-1391"><span class="linenos">1391</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1392"><a href="#PyTorchConverter-1392"><span class="linenos">1392</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1393"><a href="#PyTorchConverter-1393"><span class="linenos">1393</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter-1394"><a href="#PyTorchConverter-1394"><span class="linenos">1394</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter-1395"><a href="#PyTorchConverter-1395"><span class="linenos">1395</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1396"><a href="#PyTorchConverter-1396"><span class="linenos">1396</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter-1397"><a href="#PyTorchConverter-1397"><span class="linenos">1397</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter-1398"><a href="#PyTorchConverter-1398"><span class="linenos">1398</span></a>
</span><span id="PyTorchConverter-1399"><a href="#PyTorchConverter-1399"><span class="linenos">1399</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter-1400"><a href="#PyTorchConverter-1400"><span class="linenos">1400</span></a>                                          <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter-1401"><a href="#PyTorchConverter-1401"><span class="linenos">1401</span></a>
</span><span id="PyTorchConverter-1402"><a href="#PyTorchConverter-1402"><span class="linenos">1402</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter-1403"><a href="#PyTorchConverter-1403"><span class="linenos">1403</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">):</span>
</span><span id="PyTorchConverter-1404"><a href="#PyTorchConverter-1404"><span class="linenos">1404</span></a>
</span><span id="PyTorchConverter-1405"><a href="#PyTorchConverter-1405"><span class="linenos">1405</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter-1406"><a href="#PyTorchConverter-1406"><span class="linenos">1406</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1407"><a href="#PyTorchConverter-1407"><span class="linenos">1407</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter-1408"><a href="#PyTorchConverter-1408"><span class="linenos">1408</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter-1409"><a href="#PyTorchConverter-1409"><span class="linenos">1409</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1410"><a href="#PyTorchConverter-1410"><span class="linenos">1410</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter-1411"><a href="#PyTorchConverter-1411"><span class="linenos">1411</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="PyTorchConverter-1412"><a href="#PyTorchConverter-1412"><span class="linenos">1412</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">count_include_pad</span>
</span><span id="PyTorchConverter-1413"><a href="#PyTorchConverter-1413"><span class="linenos">1413</span></a>
</span><span id="PyTorchConverter-1414"><a href="#PyTorchConverter-1414"><span class="linenos">1414</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter-1415"><a href="#PyTorchConverter-1415"><span class="linenos">1415</span></a>                                                 <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter-1416"><a href="#PyTorchConverter-1416"><span class="linenos">1416</span></a>
</span><span id="PyTorchConverter-1417"><a href="#PyTorchConverter-1417"><span class="linenos">1417</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter-1418"><a href="#PyTorchConverter-1418"><span class="linenos">1418</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">):</span>
</span><span id="PyTorchConverter-1419"><a href="#PyTorchConverter-1419"><span class="linenos">1419</span></a>
</span><span id="PyTorchConverter-1420"><a href="#PyTorchConverter-1420"><span class="linenos">1420</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter-1421"><a href="#PyTorchConverter-1421"><span class="linenos">1421</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1422"><a href="#PyTorchConverter-1422"><span class="linenos">1422</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter-1423"><a href="#PyTorchConverter-1423"><span class="linenos">1423</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter-1424"><a href="#PyTorchConverter-1424"><span class="linenos">1424</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter-1425"><a href="#PyTorchConverter-1425"><span class="linenos">1425</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter-1426"><a href="#PyTorchConverter-1426"><span class="linenos">1426</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="PyTorchConverter-1427"><a href="#PyTorchConverter-1427"><span class="linenos">1427</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="PyTorchConverter-1428"><a href="#PyTorchConverter-1428"><span class="linenos">1428</span></a>                <span class="n">return_indices</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">return_indices</span>
</span><span id="PyTorchConverter-1429"><a href="#PyTorchConverter-1429"><span class="linenos">1429</span></a>
</span><span id="PyTorchConverter-1430"><a href="#PyTorchConverter-1430"><span class="linenos">1430</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span>
</span><span id="PyTorchConverter-1431"><a href="#PyTorchConverter-1431"><span class="linenos">1431</span></a>                                             <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">return_indices</span><span class="p">)</span>
</span><span id="PyTorchConverter-1432"><a href="#PyTorchConverter-1432"><span class="linenos">1432</span></a>
</span><span id="PyTorchConverter-1433"><a href="#PyTorchConverter-1433"><span class="linenos">1433</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">):</span>
</span><span id="PyTorchConverter-1434"><a href="#PyTorchConverter-1434"><span class="linenos">1434</span></a>
</span><span id="PyTorchConverter-1435"><a href="#PyTorchConverter-1435"><span class="linenos">1435</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="PyTorchConverter-1436"><a href="#PyTorchConverter-1436"><span class="linenos">1436</span></a>
</span><span id="PyTorchConverter-1437"><a href="#PyTorchConverter-1437"><span class="linenos">1437</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">):</span>
</span><span id="PyTorchConverter-1438"><a href="#PyTorchConverter-1438"><span class="linenos">1438</span></a>
</span><span id="PyTorchConverter-1439"><a href="#PyTorchConverter-1439"><span class="linenos">1439</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter-1440"><a href="#PyTorchConverter-1440"><span class="linenos">1440</span></a>
</span><span id="PyTorchConverter-1441"><a href="#PyTorchConverter-1441"><span class="linenos">1441</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">):</span>
</span><span id="PyTorchConverter-1442"><a href="#PyTorchConverter-1442"><span class="linenos">1442</span></a>
</span><span id="PyTorchConverter-1443"><a href="#PyTorchConverter-1443"><span class="linenos">1443</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="PyTorchConverter-1444"><a href="#PyTorchConverter-1444"><span class="linenos">1444</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="PyTorchConverter-1445"><a href="#PyTorchConverter-1445"><span class="linenos">1445</span></a>
</span><span id="PyTorchConverter-1446"><a href="#PyTorchConverter-1446"><span class="linenos">1446</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">):</span>
</span><span id="PyTorchConverter-1447"><a href="#PyTorchConverter-1447"><span class="linenos">1447</span></a>
</span><span id="PyTorchConverter-1448"><a href="#PyTorchConverter-1448"><span class="linenos">1448</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="PyTorchConverter-1449"><a href="#PyTorchConverter-1449"><span class="linenos">1449</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter-1450"><a href="#PyTorchConverter-1450"><span class="linenos">1450</span></a>
</span><span id="PyTorchConverter-1451"><a href="#PyTorchConverter-1451"><span class="linenos">1451</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">):</span>
</span><span id="PyTorchConverter-1452"><a href="#PyTorchConverter-1452"><span class="linenos">1452</span></a>
</span><span id="PyTorchConverter-1453"><a href="#PyTorchConverter-1453"><span class="linenos">1453</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter-1454"><a href="#PyTorchConverter-1454"><span class="linenos">1454</span></a>
</span><span id="PyTorchConverter-1455"><a href="#PyTorchConverter-1455"><span class="linenos">1455</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">):</span>
</span><span id="PyTorchConverter-1456"><a href="#PyTorchConverter-1456"><span class="linenos">1456</span></a>
</span><span id="PyTorchConverter-1457"><a href="#PyTorchConverter-1457"><span class="linenos">1457</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="PyTorchConverter-1458"><a href="#PyTorchConverter-1458"><span class="linenos">1458</span></a>
</span><span id="PyTorchConverter-1459"><a href="#PyTorchConverter-1459"><span class="linenos">1459</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="PyTorchConverter-1460"><a href="#PyTorchConverter-1460"><span class="linenos">1460</span></a>                <span class="k">pass</span>
</span><span id="PyTorchConverter-1461"><a href="#PyTorchConverter-1461"><span class="linenos">1461</span></a>
</span><span id="PyTorchConverter-1462"><a href="#PyTorchConverter-1462"><span class="linenos">1462</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter-1463"><a href="#PyTorchConverter-1463"><span class="linenos">1463</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter-1464"><a href="#PyTorchConverter-1464"><span class="linenos">1464</span></a>
</span><span id="PyTorchConverter-1465"><a href="#PyTorchConverter-1465"><span class="linenos">1465</span></a>            <span class="k">if</span> <span class="n">new_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter-1466"><a href="#PyTorchConverter-1466"><span class="linenos">1466</span></a>                <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="PyTorchConverter-1467"><a href="#PyTorchConverter-1467"><span class="linenos">1467</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
</span><span id="PyTorchConverter-1468"><a href="#PyTorchConverter-1468"><span class="linenos">1468</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="PyTorchConverter-1469"><a href="#PyTorchConverter-1469"><span class="linenos">1469</span></a>
</span><span id="PyTorchConverter-1470"><a href="#PyTorchConverter-1470"><span class="linenos">1470</span></a>        <span class="k">return</span> <span class="n">network</span>
</span></pre></div>


            <div class="docstring"><p>A class used to represent the conversion strategy for PyTorch models.</p>

<h2 id="methods">Methods</h2>

<p>from_neural_network(NeuralNetwork)
    Convert the neural network of interest to a PyTorchNetwork model.
to_neural_network(PyTorchNetwork)
    Convert the PyTorchNetwork of interest to our internal representation of a Neural Network.</p>
</div>


                            <div id="PyTorchConverter.from_neural_network" class="classattr">
                                        <input id="PyTorchConverter.from_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">from_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">network</span><span class="p">:</span> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span></span><span class="return-annotation">) -> <span class="n"><a href="#PyTorchNetwork">PyTorchNetwork</a></span>:</span></span>

                <label class="view-source-button" for="PyTorchConverter.from_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PyTorchConverter.from_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PyTorchConverter.from_neural_network-1024"><a href="#PyTorchConverter.from_neural_network-1024"><span class="linenos">1024</span></a>    <span class="k">def</span> <span class="nf">from_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PyTorchNetwork</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1025"><a href="#PyTorchConverter.from_neural_network-1025"><span class="linenos">1025</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1026"><a href="#PyTorchConverter.from_neural_network-1026"><span class="linenos">1026</span></a><span class="sd">        Convert the neural network of interest to a PyTorch representation.</span>
</span><span id="PyTorchConverter.from_neural_network-1027"><a href="#PyTorchConverter.from_neural_network-1027"><span class="linenos">1027</span></a>
</span><span id="PyTorchConverter.from_neural_network-1028"><a href="#PyTorchConverter.from_neural_network-1028"><span class="linenos">1028</span></a><span class="sd">        Parameters</span>
</span><span id="PyTorchConverter.from_neural_network-1029"><a href="#PyTorchConverter.from_neural_network-1029"><span class="linenos">1029</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter.from_neural_network-1030"><a href="#PyTorchConverter.from_neural_network-1030"><span class="linenos">1030</span></a><span class="sd">        network : NeuralNetwork</span>
</span><span id="PyTorchConverter.from_neural_network-1031"><a href="#PyTorchConverter.from_neural_network-1031"><span class="linenos">1031</span></a><span class="sd">            The neural network to convert.</span>
</span><span id="PyTorchConverter.from_neural_network-1032"><a href="#PyTorchConverter.from_neural_network-1032"><span class="linenos">1032</span></a>
</span><span id="PyTorchConverter.from_neural_network-1033"><a href="#PyTorchConverter.from_neural_network-1033"><span class="linenos">1033</span></a><span class="sd">        Returns</span>
</span><span id="PyTorchConverter.from_neural_network-1034"><a href="#PyTorchConverter.from_neural_network-1034"><span class="linenos">1034</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter.from_neural_network-1035"><a href="#PyTorchConverter.from_neural_network-1035"><span class="linenos">1035</span></a><span class="sd">        PyTorchNetwork</span>
</span><span id="PyTorchConverter.from_neural_network-1036"><a href="#PyTorchConverter.from_neural_network-1036"><span class="linenos">1036</span></a><span class="sd">            The PyTorch representation resulting from the conversion of the original network.</span>
</span><span id="PyTorchConverter.from_neural_network-1037"><a href="#PyTorchConverter.from_neural_network-1037"><span class="linenos">1037</span></a>
</span><span id="PyTorchConverter.from_neural_network-1038"><a href="#PyTorchConverter.from_neural_network-1038"><span class="linenos">1038</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1039"><a href="#PyTorchConverter.from_neural_network-1039"><span class="linenos">1039</span></a>
</span><span id="PyTorchConverter.from_neural_network-1040"><a href="#PyTorchConverter.from_neural_network-1040"><span class="linenos">1040</span></a>        <span class="n">alt_net</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.from_neural_network-1041"><a href="#PyTorchConverter.from_neural_network-1041"><span class="linenos">1041</span></a>        <span class="n">pytorch_network</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.from_neural_network-1042"><a href="#PyTorchConverter.from_neural_network-1042"><span class="linenos">1042</span></a>        <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1043"><a href="#PyTorchConverter.from_neural_network-1043"><span class="linenos">1043</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="ow">and</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1044"><a href="#PyTorchConverter.from_neural_network-1044"><span class="linenos">1044</span></a>                <span class="n">alt_net</span> <span class="o">=</span> <span class="n">alt_rep</span>
</span><span id="PyTorchConverter.from_neural_network-1045"><a href="#PyTorchConverter.from_neural_network-1045"><span class="linenos">1045</span></a>
</span><span id="PyTorchConverter.from_neural_network-1046"><a href="#PyTorchConverter.from_neural_network-1046"><span class="linenos">1046</span></a>        <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1047"><a href="#PyTorchConverter.from_neural_network-1047"><span class="linenos">1047</span></a>
</span><span id="PyTorchConverter.from_neural_network-1048"><a href="#PyTorchConverter.from_neural_network-1048"><span class="linenos">1048</span></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">network</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1049"><a href="#PyTorchConverter.from_neural_network-1049"><span class="linenos">1049</span></a>
</span><span id="PyTorchConverter.from_neural_network-1050"><a href="#PyTorchConverter.from_neural_network-1050"><span class="linenos">1050</span></a>                <span class="k">for</span> <span class="n">alt_rep</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">alt_rep_cache</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1051"><a href="#PyTorchConverter.from_neural_network-1051"><span class="linenos">1051</span></a>
</span><span id="PyTorchConverter.from_neural_network-1052"><a href="#PyTorchConverter.from_neural_network-1052"><span class="linenos">1052</span></a>                    <span class="k">if</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">up_to_date</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1053"><a href="#PyTorchConverter.from_neural_network-1053"><span class="linenos">1053</span></a>
</span><span id="PyTorchConverter.from_neural_network-1054"><a href="#PyTorchConverter.from_neural_network-1054"><span class="linenos">1054</span></a>                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1055"><a href="#PyTorchConverter.from_neural_network-1055"><span class="linenos">1055</span></a>                            <span class="n">onnx_cv</span> <span class="o">=</span> <span class="n">ONNXConverter</span><span class="p">()</span>
</span><span id="PyTorchConverter.from_neural_network-1056"><a href="#PyTorchConverter.from_neural_network-1056"><span class="linenos">1056</span></a>                            <span class="n">network</span> <span class="o">=</span> <span class="n">onnx_cv</span><span class="o">.</span><span class="n">to_neural_network</span><span class="p">(</span><span class="n">alt_rep</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1057"><a href="#PyTorchConverter.from_neural_network-1057"><span class="linenos">1057</span></a>
</span><span id="PyTorchConverter.from_neural_network-1058"><a href="#PyTorchConverter.from_neural_network-1058"><span class="linenos">1058</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1059"><a href="#PyTorchConverter.from_neural_network-1059"><span class="linenos">1059</span></a>                            <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter.from_neural_network-1060"><a href="#PyTorchConverter.from_neural_network-1060"><span class="linenos">1060</span></a>                        <span class="k">break</span>
</span><span id="PyTorchConverter.from_neural_network-1061"><a href="#PyTorchConverter.from_neural_network-1061"><span class="linenos">1061</span></a>
</span><span id="PyTorchConverter.from_neural_network-1062"><a href="#PyTorchConverter.from_neural_network-1062"><span class="linenos">1062</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1063"><a href="#PyTorchConverter.from_neural_network-1063"><span class="linenos">1063</span></a>                <span class="n">pytorch_layers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="PyTorchConverter.from_neural_network-1064"><a href="#PyTorchConverter.from_neural_network-1064"><span class="linenos">1064</span></a>                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">network</span><span class="o">.</span><span class="n">nodes</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
</span><span id="PyTorchConverter.from_neural_network-1065"><a href="#PyTorchConverter.from_neural_network-1065"><span class="linenos">1065</span></a>
</span><span id="PyTorchConverter.from_neural_network-1066"><a href="#PyTorchConverter.from_neural_network-1066"><span class="linenos">1066</span></a>                    <span class="n">new_layer</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.from_neural_network-1067"><a href="#PyTorchConverter.from_neural_network-1067"><span class="linenos">1067</span></a>                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1068"><a href="#PyTorchConverter.from_neural_network-1068"><span class="linenos">1068</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1069"><a href="#PyTorchConverter.from_neural_network-1069"><span class="linenos">1069</span></a>
</span><span id="PyTorchConverter.from_neural_network-1070"><a href="#PyTorchConverter.from_neural_network-1070"><span class="linenos">1070</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1071"><a href="#PyTorchConverter.from_neural_network-1071"><span class="linenos">1071</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1072"><a href="#PyTorchConverter.from_neural_network-1072"><span class="linenos">1072</span></a>
</span><span id="PyTorchConverter.from_neural_network-1073"><a href="#PyTorchConverter.from_neural_network-1073"><span class="linenos">1073</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1074"><a href="#PyTorchConverter.from_neural_network-1074"><span class="linenos">1074</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1075"><a href="#PyTorchConverter.from_neural_network-1075"><span class="linenos">1075</span></a>
</span><span id="PyTorchConverter.from_neural_network-1076"><a href="#PyTorchConverter.from_neural_network-1076"><span class="linenos">1076</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1077"><a href="#PyTorchConverter.from_neural_network-1077"><span class="linenos">1077</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1078"><a href="#PyTorchConverter.from_neural_network-1078"><span class="linenos">1078</span></a>
</span><span id="PyTorchConverter.from_neural_network-1079"><a href="#PyTorchConverter.from_neural_network-1079"><span class="linenos">1079</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1080"><a href="#PyTorchConverter.from_neural_network-1080"><span class="linenos">1080</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1081"><a href="#PyTorchConverter.from_neural_network-1081"><span class="linenos">1081</span></a>
</span><span id="PyTorchConverter.from_neural_network-1082"><a href="#PyTorchConverter.from_neural_network-1082"><span class="linenos">1082</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1083"><a href="#PyTorchConverter.from_neural_network-1083"><span class="linenos">1083</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1084"><a href="#PyTorchConverter.from_neural_network-1084"><span class="linenos">1084</span></a>
</span><span id="PyTorchConverter.from_neural_network-1085"><a href="#PyTorchConverter.from_neural_network-1085"><span class="linenos">1085</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1086"><a href="#PyTorchConverter.from_neural_network-1086"><span class="linenos">1086</span></a>
</span><span id="PyTorchConverter.from_neural_network-1087"><a href="#PyTorchConverter.from_neural_network-1087"><span class="linenos">1087</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1088"><a href="#PyTorchConverter.from_neural_network-1088"><span class="linenos">1088</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter.from_neural_network-1089"><a href="#PyTorchConverter.from_neural_network-1089"><span class="linenos">1089</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1090"><a href="#PyTorchConverter.from_neural_network-1090"><span class="linenos">1090</span></a>                            <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter.from_neural_network-1091"><a href="#PyTorchConverter.from_neural_network-1091"><span class="linenos">1091</span></a>
</span><span id="PyTorchConverter.from_neural_network-1092"><a href="#PyTorchConverter.from_neural_network-1092"><span class="linenos">1092</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1093"><a href="#PyTorchConverter.from_neural_network-1093"><span class="linenos">1093</span></a>                                                 <span class="n">in_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">out_features</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1094"><a href="#PyTorchConverter.from_neural_network-1094"><span class="linenos">1094</span></a>                                                 <span class="n">bias</span><span class="o">=</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1095"><a href="#PyTorchConverter.from_neural_network-1095"><span class="linenos">1095</span></a>
</span><span id="PyTorchConverter.from_neural_network-1096"><a href="#PyTorchConverter.from_neural_network-1096"><span class="linenos">1096</span></a>                        <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1097"><a href="#PyTorchConverter.from_neural_network-1097"><span class="linenos">1097</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight</span>
</span><span id="PyTorchConverter.from_neural_network-1098"><a href="#PyTorchConverter.from_neural_network-1098"><span class="linenos">1098</span></a>
</span><span id="PyTorchConverter.from_neural_network-1099"><a href="#PyTorchConverter.from_neural_network-1099"><span class="linenos">1099</span></a>                        <span class="k">if</span> <span class="n">has_bias</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1100"><a href="#PyTorchConverter.from_neural_network-1100"><span class="linenos">1100</span></a>                            <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1101"><a href="#PyTorchConverter.from_neural_network-1101"><span class="linenos">1101</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">bias</span>
</span><span id="PyTorchConverter.from_neural_network-1102"><a href="#PyTorchConverter.from_neural_network-1102"><span class="linenos">1102</span></a>
</span><span id="PyTorchConverter.from_neural_network-1103"><a href="#PyTorchConverter.from_neural_network-1103"><span class="linenos">1103</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1104"><a href="#PyTorchConverter.from_neural_network-1104"><span class="linenos">1104</span></a>
</span><span id="PyTorchConverter.from_neural_network-1105"><a href="#PyTorchConverter.from_neural_network-1105"><span class="linenos">1105</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1106"><a href="#PyTorchConverter.from_neural_network-1106"><span class="linenos">1106</span></a>
</span><span id="PyTorchConverter.from_neural_network-1107"><a href="#PyTorchConverter.from_neural_network-1107"><span class="linenos">1107</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1108"><a href="#PyTorchConverter.from_neural_network-1108"><span class="linenos">1108</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1109"><a href="#PyTorchConverter.from_neural_network-1109"><span class="linenos">1109</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1110"><a href="#PyTorchConverter.from_neural_network-1110"><span class="linenos">1110</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1111"><a href="#PyTorchConverter.from_neural_network-1111"><span class="linenos">1111</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1112"><a href="#PyTorchConverter.from_neural_network-1112"><span class="linenos">1112</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1113"><a href="#PyTorchConverter.from_neural_network-1113"><span class="linenos">1113</span></a>
</span><span id="PyTorchConverter.from_neural_network-1114"><a href="#PyTorchConverter.from_neural_network-1114"><span class="linenos">1114</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1115"><a href="#PyTorchConverter.from_neural_network-1115"><span class="linenos">1115</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1116"><a href="#PyTorchConverter.from_neural_network-1116"><span class="linenos">1116</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1117"><a href="#PyTorchConverter.from_neural_network-1117"><span class="linenos">1117</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1118"><a href="#PyTorchConverter.from_neural_network-1118"><span class="linenos">1118</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1119"><a href="#PyTorchConverter.from_neural_network-1119"><span class="linenos">1119</span></a>
</span><span id="PyTorchConverter.from_neural_network-1120"><a href="#PyTorchConverter.from_neural_network-1120"><span class="linenos">1120</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1121"><a href="#PyTorchConverter.from_neural_network-1121"><span class="linenos">1121</span></a>
</span><span id="PyTorchConverter.from_neural_network-1122"><a href="#PyTorchConverter.from_neural_network-1122"><span class="linenos">1122</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1123"><a href="#PyTorchConverter.from_neural_network-1123"><span class="linenos">1123</span></a>                                                          <span class="n">num_features</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1124"><a href="#PyTorchConverter.from_neural_network-1124"><span class="linenos">1124</span></a>                                                          <span class="n">eps</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">momentum</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1125"><a href="#PyTorchConverter.from_neural_network-1125"><span class="linenos">1125</span></a>                                                          <span class="n">affine</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1126"><a href="#PyTorchConverter.from_neural_network-1126"><span class="linenos">1126</span></a>                                                          <span class="n">track_running_stats</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1127"><a href="#PyTorchConverter.from_neural_network-1127"><span class="linenos">1127</span></a>
</span><span id="PyTorchConverter.from_neural_network-1128"><a href="#PyTorchConverter.from_neural_network-1128"><span class="linenos">1128</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1129"><a href="#PyTorchConverter.from_neural_network-1129"><span class="linenos">1129</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support batchnorm layer for input with more than&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1130"><a href="#PyTorchConverter.from_neural_network-1130"><span class="linenos">1130</span></a>                                            <span class="s2">&quot;4 or less than 1 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1131"><a href="#PyTorchConverter.from_neural_network-1131"><span class="linenos">1131</span></a>
</span><span id="PyTorchConverter.from_neural_network-1132"><a href="#PyTorchConverter.from_neural_network-1132"><span class="linenos">1132</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1133"><a href="#PyTorchConverter.from_neural_network-1133"><span class="linenos">1133</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1134"><a href="#PyTorchConverter.from_neural_network-1134"><span class="linenos">1134</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_mean</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1135"><a href="#PyTorchConverter.from_neural_network-1135"><span class="linenos">1135</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">running_var</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1136"><a href="#PyTorchConverter.from_neural_network-1136"><span class="linenos">1136</span></a>
</span><span id="PyTorchConverter.from_neural_network-1137"><a href="#PyTorchConverter.from_neural_network-1137"><span class="linenos">1137</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1138"><a href="#PyTorchConverter.from_neural_network-1138"><span class="linenos">1138</span></a>
</span><span id="PyTorchConverter.from_neural_network-1139"><a href="#PyTorchConverter.from_neural_network-1139"><span class="linenos">1139</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter.from_neural_network-1140"><a href="#PyTorchConverter.from_neural_network-1140"><span class="linenos">1140</span></a>                        <span class="c1"># symmetric. Padding mode is not supported in our representation therefore we let it be</span>
</span><span id="PyTorchConverter.from_neural_network-1141"><a href="#PyTorchConverter.from_neural_network-1141"><span class="linenos">1141</span></a>                        <span class="c1"># set to the default value.</span>
</span><span id="PyTorchConverter.from_neural_network-1142"><a href="#PyTorchConverter.from_neural_network-1142"><span class="linenos">1142</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter.from_neural_network-1143"><a href="#PyTorchConverter.from_neural_network-1143"><span class="linenos">1143</span></a>
</span><span id="PyTorchConverter.from_neural_network-1144"><a href="#PyTorchConverter.from_neural_network-1144"><span class="linenos">1144</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1145"><a href="#PyTorchConverter.from_neural_network-1145"><span class="linenos">1145</span></a>
</span><span id="PyTorchConverter.from_neural_network-1146"><a href="#PyTorchConverter.from_neural_network-1146"><span class="linenos">1146</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1147"><a href="#PyTorchConverter.from_neural_network-1147"><span class="linenos">1147</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1148"><a href="#PyTorchConverter.from_neural_network-1148"><span class="linenos">1148</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1149"><a href="#PyTorchConverter.from_neural_network-1149"><span class="linenos">1149</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1150"><a href="#PyTorchConverter.from_neural_network-1150"><span class="linenos">1150</span></a>
</span><span id="PyTorchConverter.from_neural_network-1151"><a href="#PyTorchConverter.from_neural_network-1151"><span class="linenos">1151</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1152"><a href="#PyTorchConverter.from_neural_network-1152"><span class="linenos">1152</span></a>
</span><span id="PyTorchConverter.from_neural_network-1153"><a href="#PyTorchConverter.from_neural_network-1153"><span class="linenos">1153</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1154"><a href="#PyTorchConverter.from_neural_network-1154"><span class="linenos">1154</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1155"><a href="#PyTorchConverter.from_neural_network-1155"><span class="linenos">1155</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1156"><a href="#PyTorchConverter.from_neural_network-1156"><span class="linenos">1156</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1157"><a href="#PyTorchConverter.from_neural_network-1157"><span class="linenos">1157</span></a>
</span><span id="PyTorchConverter.from_neural_network-1158"><a href="#PyTorchConverter.from_neural_network-1158"><span class="linenos">1158</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1159"><a href="#PyTorchConverter.from_neural_network-1159"><span class="linenos">1159</span></a>
</span><span id="PyTorchConverter.from_neural_network-1160"><a href="#PyTorchConverter.from_neural_network-1160"><span class="linenos">1160</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1161"><a href="#PyTorchConverter.from_neural_network-1161"><span class="linenos">1161</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1162"><a href="#PyTorchConverter.from_neural_network-1162"><span class="linenos">1162</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1163"><a href="#PyTorchConverter.from_neural_network-1163"><span class="linenos">1163</span></a>                                                     <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1164"><a href="#PyTorchConverter.from_neural_network-1164"><span class="linenos">1164</span></a>
</span><span id="PyTorchConverter.from_neural_network-1165"><a href="#PyTorchConverter.from_neural_network-1165"><span class="linenos">1165</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1166"><a href="#PyTorchConverter.from_neural_network-1166"><span class="linenos">1166</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1167"><a href="#PyTorchConverter.from_neural_network-1167"><span class="linenos">1167</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1168"><a href="#PyTorchConverter.from_neural_network-1168"><span class="linenos">1168</span></a>
</span><span id="PyTorchConverter.from_neural_network-1169"><a href="#PyTorchConverter.from_neural_network-1169"><span class="linenos">1169</span></a>                        <span class="n">new_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1170"><a href="#PyTorchConverter.from_neural_network-1170"><span class="linenos">1170</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">has_bias</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1171"><a href="#PyTorchConverter.from_neural_network-1171"><span class="linenos">1171</span></a>                            <span class="n">new_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1172"><a href="#PyTorchConverter.from_neural_network-1172"><span class="linenos">1172</span></a>
</span><span id="PyTorchConverter.from_neural_network-1173"><a href="#PyTorchConverter.from_neural_network-1173"><span class="linenos">1173</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1174"><a href="#PyTorchConverter.from_neural_network-1174"><span class="linenos">1174</span></a>
</span><span id="PyTorchConverter.from_neural_network-1175"><a href="#PyTorchConverter.from_neural_network-1175"><span class="linenos">1175</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter.from_neural_network-1176"><a href="#PyTorchConverter.from_neural_network-1176"><span class="linenos">1176</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="PyTorchConverter.from_neural_network-1177"><a href="#PyTorchConverter.from_neural_network-1177"><span class="linenos">1177</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter.from_neural_network-1178"><a href="#PyTorchConverter.from_neural_network-1178"><span class="linenos">1178</span></a>
</span><span id="PyTorchConverter.from_neural_network-1179"><a href="#PyTorchConverter.from_neural_network-1179"><span class="linenos">1179</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1180"><a href="#PyTorchConverter.from_neural_network-1180"><span class="linenos">1180</span></a>
</span><span id="PyTorchConverter.from_neural_network-1181"><a href="#PyTorchConverter.from_neural_network-1181"><span class="linenos">1181</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1182"><a href="#PyTorchConverter.from_neural_network-1182"><span class="linenos">1182</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1183"><a href="#PyTorchConverter.from_neural_network-1183"><span class="linenos">1183</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1184"><a href="#PyTorchConverter.from_neural_network-1184"><span class="linenos">1184</span></a>
</span><span id="PyTorchConverter.from_neural_network-1185"><a href="#PyTorchConverter.from_neural_network-1185"><span class="linenos">1185</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1186"><a href="#PyTorchConverter.from_neural_network-1186"><span class="linenos">1186</span></a>
</span><span id="PyTorchConverter.from_neural_network-1187"><a href="#PyTorchConverter.from_neural_network-1187"><span class="linenos">1187</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1188"><a href="#PyTorchConverter.from_neural_network-1188"><span class="linenos">1188</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1189"><a href="#PyTorchConverter.from_neural_network-1189"><span class="linenos">1189</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1190"><a href="#PyTorchConverter.from_neural_network-1190"><span class="linenos">1190</span></a>
</span><span id="PyTorchConverter.from_neural_network-1191"><a href="#PyTorchConverter.from_neural_network-1191"><span class="linenos">1191</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1192"><a href="#PyTorchConverter.from_neural_network-1192"><span class="linenos">1192</span></a>
</span><span id="PyTorchConverter.from_neural_network-1193"><a href="#PyTorchConverter.from_neural_network-1193"><span class="linenos">1193</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1194"><a href="#PyTorchConverter.from_neural_network-1194"><span class="linenos">1194</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1195"><a href="#PyTorchConverter.from_neural_network-1195"><span class="linenos">1195</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1196"><a href="#PyTorchConverter.from_neural_network-1196"><span class="linenos">1196</span></a>
</span><span id="PyTorchConverter.from_neural_network-1197"><a href="#PyTorchConverter.from_neural_network-1197"><span class="linenos">1197</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1198"><a href="#PyTorchConverter.from_neural_network-1198"><span class="linenos">1198</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support AvgPool layer for input with more than&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1199"><a href="#PyTorchConverter.from_neural_network-1199"><span class="linenos">1199</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1200"><a href="#PyTorchConverter.from_neural_network-1200"><span class="linenos">1200</span></a>
</span><span id="PyTorchConverter.from_neural_network-1201"><a href="#PyTorchConverter.from_neural_network-1201"><span class="linenos">1201</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1202"><a href="#PyTorchConverter.from_neural_network-1202"><span class="linenos">1202</span></a>
</span><span id="PyTorchConverter.from_neural_network-1203"><a href="#PyTorchConverter.from_neural_network-1203"><span class="linenos">1203</span></a>                        <span class="c1"># Pytorch support only symmetric padding, therefore we assume that the padding given is</span>
</span><span id="PyTorchConverter.from_neural_network-1204"><a href="#PyTorchConverter.from_neural_network-1204"><span class="linenos">1204</span></a>                        <span class="c1"># symmetric.</span>
</span><span id="PyTorchConverter.from_neural_network-1205"><a href="#PyTorchConverter.from_neural_network-1205"><span class="linenos">1205</span></a>                        <span class="n">padding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>
</span><span id="PyTorchConverter.from_neural_network-1206"><a href="#PyTorchConverter.from_neural_network-1206"><span class="linenos">1206</span></a>
</span><span id="PyTorchConverter.from_neural_network-1207"><a href="#PyTorchConverter.from_neural_network-1207"><span class="linenos">1207</span></a>                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1208"><a href="#PyTorchConverter.from_neural_network-1208"><span class="linenos">1208</span></a>
</span><span id="PyTorchConverter.from_neural_network-1209"><a href="#PyTorchConverter.from_neural_network-1209"><span class="linenos">1209</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1210"><a href="#PyTorchConverter.from_neural_network-1210"><span class="linenos">1210</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1211"><a href="#PyTorchConverter.from_neural_network-1211"><span class="linenos">1211</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1212"><a href="#PyTorchConverter.from_neural_network-1212"><span class="linenos">1212</span></a>
</span><span id="PyTorchConverter.from_neural_network-1213"><a href="#PyTorchConverter.from_neural_network-1213"><span class="linenos">1213</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1214"><a href="#PyTorchConverter.from_neural_network-1214"><span class="linenos">1214</span></a>
</span><span id="PyTorchConverter.from_neural_network-1215"><a href="#PyTorchConverter.from_neural_network-1215"><span class="linenos">1215</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1216"><a href="#PyTorchConverter.from_neural_network-1216"><span class="linenos">1216</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1217"><a href="#PyTorchConverter.from_neural_network-1217"><span class="linenos">1217</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1218"><a href="#PyTorchConverter.from_neural_network-1218"><span class="linenos">1218</span></a>
</span><span id="PyTorchConverter.from_neural_network-1219"><a href="#PyTorchConverter.from_neural_network-1219"><span class="linenos">1219</span></a>                        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1220"><a href="#PyTorchConverter.from_neural_network-1220"><span class="linenos">1220</span></a>
</span><span id="PyTorchConverter.from_neural_network-1221"><a href="#PyTorchConverter.from_neural_network-1221"><span class="linenos">1221</span></a>                            <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1222"><a href="#PyTorchConverter.from_neural_network-1222"><span class="linenos">1222</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1223"><a href="#PyTorchConverter.from_neural_network-1223"><span class="linenos">1223</span></a>                                                        <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">return_indices</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">ceil_mode</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1224"><a href="#PyTorchConverter.from_neural_network-1224"><span class="linenos">1224</span></a>
</span><span id="PyTorchConverter.from_neural_network-1225"><a href="#PyTorchConverter.from_neural_network-1225"><span class="linenos">1225</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1226"><a href="#PyTorchConverter.from_neural_network-1226"><span class="linenos">1226</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Pytorch does not support Conv layer for input with more than&quot;</span>
</span><span id="PyTorchConverter.from_neural_network-1227"><a href="#PyTorchConverter.from_neural_network-1227"><span class="linenos">1227</span></a>                                            <span class="s2">&quot;4 or less than 2 dimension excluding the batch dimension&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1228"><a href="#PyTorchConverter.from_neural_network-1228"><span class="linenos">1228</span></a>
</span><span id="PyTorchConverter.from_neural_network-1229"><a href="#PyTorchConverter.from_neural_network-1229"><span class="linenos">1229</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1230"><a href="#PyTorchConverter.from_neural_network-1230"><span class="linenos">1230</span></a>
</span><span id="PyTorchConverter.from_neural_network-1231"><a href="#PyTorchConverter.from_neural_network-1231"><span class="linenos">1231</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span>
</span><span id="PyTorchConverter.from_neural_network-1232"><a href="#PyTorchConverter.from_neural_network-1232"><span class="linenos">1232</span></a>                                                            <span class="n">layer</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1233"><a href="#PyTorchConverter.from_neural_network-1233"><span class="linenos">1233</span></a>
</span><span id="PyTorchConverter.from_neural_network-1234"><a href="#PyTorchConverter.from_neural_network-1234"><span class="linenos">1234</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1235"><a href="#PyTorchConverter.from_neural_network-1235"><span class="linenos">1235</span></a>
</span><span id="PyTorchConverter.from_neural_network-1236"><a href="#PyTorchConverter.from_neural_network-1236"><span class="linenos">1236</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="PyTorchConverter.from_neural_network-1237"><a href="#PyTorchConverter.from_neural_network-1237"><span class="linenos">1237</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1238"><a href="#PyTorchConverter.from_neural_network-1238"><span class="linenos">1238</span></a>
</span><span id="PyTorchConverter.from_neural_network-1239"><a href="#PyTorchConverter.from_neural_network-1239"><span class="linenos">1239</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1240"><a href="#PyTorchConverter.from_neural_network-1240"><span class="linenos">1240</span></a>
</span><span id="PyTorchConverter.from_neural_network-1241"><a href="#PyTorchConverter.from_neural_network-1241"><span class="linenos">1241</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to scale</span>
</span><span id="PyTorchConverter.from_neural_network-1242"><a href="#PyTorchConverter.from_neural_network-1242"><span class="linenos">1242</span></a>                        <span class="c1"># the axes values.</span>
</span><span id="PyTorchConverter.from_neural_network-1243"><a href="#PyTorchConverter.from_neural_network-1243"><span class="linenos">1243</span></a>                        <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="PyTorchConverter.from_neural_network-1244"><a href="#PyTorchConverter.from_neural_network-1244"><span class="linenos">1244</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1245"><a href="#PyTorchConverter.from_neural_network-1245"><span class="linenos">1245</span></a>
</span><span id="PyTorchConverter.from_neural_network-1246"><a href="#PyTorchConverter.from_neural_network-1246"><span class="linenos">1246</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1247"><a href="#PyTorchConverter.from_neural_network-1247"><span class="linenos">1247</span></a>
</span><span id="PyTorchConverter.from_neural_network-1248"><a href="#PyTorchConverter.from_neural_network-1248"><span class="linenos">1248</span></a>                        <span class="c1"># Pytorch does not support the allow_zero attribute and the corresponding reshape with 0</span>
</span><span id="PyTorchConverter.from_neural_network-1249"><a href="#PyTorchConverter.from_neural_network-1249"><span class="linenos">1249</span></a>                        <span class="c1"># dimensions.</span>
</span><span id="PyTorchConverter.from_neural_network-1250"><a href="#PyTorchConverter.from_neural_network-1250"><span class="linenos">1250</span></a>                        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">allow_zero</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1251"><a href="#PyTorchConverter.from_neural_network-1251"><span class="linenos">1251</span></a>                            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;allow_zero not supported by pytorch&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1252"><a href="#PyTorchConverter.from_neural_network-1252"><span class="linenos">1252</span></a>
</span><span id="PyTorchConverter.from_neural_network-1253"><a href="#PyTorchConverter.from_neural_network-1253"><span class="linenos">1253</span></a>                        <span class="c1"># Our representation does not consider batch dimension, therefore we need to add it to</span>
</span><span id="PyTorchConverter.from_neural_network-1254"><a href="#PyTorchConverter.from_neural_network-1254"><span class="linenos">1254</span></a>                        <span class="c1"># the shape.</span>
</span><span id="PyTorchConverter.from_neural_network-1255"><a href="#PyTorchConverter.from_neural_network-1255"><span class="linenos">1255</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="PyTorchConverter.from_neural_network-1256"><a href="#PyTorchConverter.from_neural_network-1256"><span class="linenos">1256</span></a>                        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1257"><a href="#PyTorchConverter.from_neural_network-1257"><span class="linenos">1257</span></a>                            <span class="n">shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1258"><a href="#PyTorchConverter.from_neural_network-1258"><span class="linenos">1258</span></a>                        <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1259"><a href="#PyTorchConverter.from_neural_network-1259"><span class="linenos">1259</span></a>
</span><span id="PyTorchConverter.from_neural_network-1260"><a href="#PyTorchConverter.from_neural_network-1260"><span class="linenos">1260</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1261"><a href="#PyTorchConverter.from_neural_network-1261"><span class="linenos">1261</span></a>
</span><span id="PyTorchConverter.from_neural_network-1262"><a href="#PyTorchConverter.from_neural_network-1262"><span class="linenos">1262</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1263"><a href="#PyTorchConverter.from_neural_network-1263"><span class="linenos">1263</span></a>
</span><span id="PyTorchConverter.from_neural_network-1264"><a href="#PyTorchConverter.from_neural_network-1264"><span class="linenos">1264</span></a>                        <span class="c1"># We need to scale the axis by one since our representation does not support the batch dimension</span>
</span><span id="PyTorchConverter.from_neural_network-1265"><a href="#PyTorchConverter.from_neural_network-1265"><span class="linenos">1265</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1266"><a href="#PyTorchConverter.from_neural_network-1266"><span class="linenos">1266</span></a>
</span><span id="PyTorchConverter.from_neural_network-1267"><a href="#PyTorchConverter.from_neural_network-1267"><span class="linenos">1267</span></a>                    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">):</span>
</span><span id="PyTorchConverter.from_neural_network-1268"><a href="#PyTorchConverter.from_neural_network-1268"><span class="linenos">1268</span></a>
</span><span id="PyTorchConverter.from_neural_network-1269"><a href="#PyTorchConverter.from_neural_network-1269"><span class="linenos">1269</span></a>                        <span class="n">new_layer</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1270"><a href="#PyTorchConverter.from_neural_network-1270"><span class="linenos">1270</span></a>
</span><span id="PyTorchConverter.from_neural_network-1271"><a href="#PyTorchConverter.from_neural_network-1271"><span class="linenos">1271</span></a>                    <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1272"><a href="#PyTorchConverter.from_neural_network-1272"><span class="linenos">1272</span></a>                        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter.from_neural_network-1273"><a href="#PyTorchConverter.from_neural_network-1273"><span class="linenos">1273</span></a>
</span><span id="PyTorchConverter.from_neural_network-1274"><a href="#PyTorchConverter.from_neural_network-1274"><span class="linenos">1274</span></a>                    <span class="k">if</span> <span class="n">new_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1275"><a href="#PyTorchConverter.from_neural_network-1275"><span class="linenos">1275</span></a>                        <span class="n">pytorch_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_layer</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1276"><a href="#PyTorchConverter.from_neural_network-1276"><span class="linenos">1276</span></a>
</span><span id="PyTorchConverter.from_neural_network-1277"><a href="#PyTorchConverter.from_neural_network-1277"><span class="linenos">1277</span></a>                <span class="n">pytorch_network</span> <span class="o">=</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">network</span><span class="o">.</span><span class="n">input_id</span><span class="p">,</span> <span class="n">pytorch_layers</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1278"><a href="#PyTorchConverter.from_neural_network-1278"><span class="linenos">1278</span></a>
</span><span id="PyTorchConverter.from_neural_network-1279"><a href="#PyTorchConverter.from_neural_network-1279"><span class="linenos">1279</span></a>            <span class="k">if</span> <span class="n">alt_net</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">pytorch_network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.from_neural_network-1280"><a href="#PyTorchConverter.from_neural_network-1280"><span class="linenos">1280</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: network to convert is not valid, the alternative representation is None&quot;</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1281"><a href="#PyTorchConverter.from_neural_network-1281"><span class="linenos">1281</span></a>
</span><span id="PyTorchConverter.from_neural_network-1282"><a href="#PyTorchConverter.from_neural_network-1282"><span class="linenos">1282</span></a>            <span class="n">identifier</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter.from_neural_network-1283"><a href="#PyTorchConverter.from_neural_network-1283"><span class="linenos">1283</span></a>            <span class="n">alt_net</span> <span class="o">=</span> <span class="n">PyTorchNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="o">=</span><span class="n">identifier</span><span class="p">,</span> <span class="n">pytorch_network</span><span class="o">=</span><span class="n">pytorch_network</span><span class="p">)</span>
</span><span id="PyTorchConverter.from_neural_network-1284"><a href="#PyTorchConverter.from_neural_network-1284"><span class="linenos">1284</span></a>
</span><span id="PyTorchConverter.from_neural_network-1285"><a href="#PyTorchConverter.from_neural_network-1285"><span class="linenos">1285</span></a>        <span class="k">return</span> <span class="n">alt_net</span>
</span></pre></div>


            <div class="docstring"><p>Convert the neural network of interest to a PyTorch representation.</p>

<h2 id="parameters">Parameters</h2>

<p>network : NeuralNetwork
    The neural network to convert.</p>

<h2 id="returns">Returns</h2>

<p>PyTorchNetwork
    The PyTorch representation resulting from the conversion of the original network.</p>
</div>


                            </div>
                            <div id="PyTorchConverter.to_neural_network" class="classattr">
                                        <input id="PyTorchConverter.to_neural_network-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">to_neural_network</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">alt_rep</span><span class="p">:</span> <span class="n"><a href="#PyTorchNetwork">PyTorchNetwork</a></span></span><span class="return-annotation">) -> <span class="n"><a href="../networks.html#NeuralNetwork">pynever.networks.NeuralNetwork</a></span>:</span></span>

                <label class="view-source-button" for="PyTorchConverter.to_neural_network-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PyTorchConverter.to_neural_network"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PyTorchConverter.to_neural_network-1287"><a href="#PyTorchConverter.to_neural_network-1287"><span class="linenos">1287</span></a>    <span class="k">def</span> <span class="nf">to_neural_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alt_rep</span><span class="p">:</span> <span class="n">PyTorchNetwork</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">networks</span><span class="o">.</span><span class="n">NeuralNetwork</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1288"><a href="#PyTorchConverter.to_neural_network-1288"><span class="linenos">1288</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PyTorchConverter.to_neural_network-1289"><a href="#PyTorchConverter.to_neural_network-1289"><span class="linenos">1289</span></a><span class="sd">        Convert the PyTorch representation of interest to the internal one.</span>
</span><span id="PyTorchConverter.to_neural_network-1290"><a href="#PyTorchConverter.to_neural_network-1290"><span class="linenos">1290</span></a>
</span><span id="PyTorchConverter.to_neural_network-1291"><a href="#PyTorchConverter.to_neural_network-1291"><span class="linenos">1291</span></a><span class="sd">        Parameters</span>
</span><span id="PyTorchConverter.to_neural_network-1292"><a href="#PyTorchConverter.to_neural_network-1292"><span class="linenos">1292</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter.to_neural_network-1293"><a href="#PyTorchConverter.to_neural_network-1293"><span class="linenos">1293</span></a><span class="sd">        alt_rep : PyTorchNetwork</span>
</span><span id="PyTorchConverter.to_neural_network-1294"><a href="#PyTorchConverter.to_neural_network-1294"><span class="linenos">1294</span></a><span class="sd">            The PyTorch Representation to convert.</span>
</span><span id="PyTorchConverter.to_neural_network-1295"><a href="#PyTorchConverter.to_neural_network-1295"><span class="linenos">1295</span></a>
</span><span id="PyTorchConverter.to_neural_network-1296"><a href="#PyTorchConverter.to_neural_network-1296"><span class="linenos">1296</span></a><span class="sd">        Returns</span>
</span><span id="PyTorchConverter.to_neural_network-1297"><a href="#PyTorchConverter.to_neural_network-1297"><span class="linenos">1297</span></a><span class="sd">        ----------</span>
</span><span id="PyTorchConverter.to_neural_network-1298"><a href="#PyTorchConverter.to_neural_network-1298"><span class="linenos">1298</span></a><span class="sd">        NeuralNetwork</span>
</span><span id="PyTorchConverter.to_neural_network-1299"><a href="#PyTorchConverter.to_neural_network-1299"><span class="linenos">1299</span></a><span class="sd">            The Neural Network resulting from the conversion of PyTorch Representation.</span>
</span><span id="PyTorchConverter.to_neural_network-1300"><a href="#PyTorchConverter.to_neural_network-1300"><span class="linenos">1300</span></a>
</span><span id="PyTorchConverter.to_neural_network-1301"><a href="#PyTorchConverter.to_neural_network-1301"><span class="linenos">1301</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PyTorchConverter.to_neural_network-1302"><a href="#PyTorchConverter.to_neural_network-1302"><span class="linenos">1302</span></a>
</span><span id="PyTorchConverter.to_neural_network-1303"><a href="#PyTorchConverter.to_neural_network-1303"><span class="linenos">1303</span></a>        <span class="n">identifier</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter.to_neural_network-1304"><a href="#PyTorchConverter.to_neural_network-1304"><span class="linenos">1304</span></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="s1">&#39;input_id&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1305"><a href="#PyTorchConverter.to_neural_network-1305"><span class="linenos">1305</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">input_id</span>
</span><span id="PyTorchConverter.to_neural_network-1306"><a href="#PyTorchConverter.to_neural_network-1306"><span class="linenos">1306</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1307"><a href="#PyTorchConverter.to_neural_network-1307"><span class="linenos">1307</span></a>            <span class="n">input_id</span> <span class="o">=</span> <span class="s1">&#39;X&#39;</span>
</span><span id="PyTorchConverter.to_neural_network-1308"><a href="#PyTorchConverter.to_neural_network-1308"><span class="linenos">1308</span></a>
</span><span id="PyTorchConverter.to_neural_network-1309"><a href="#PyTorchConverter.to_neural_network-1309"><span class="linenos">1309</span></a>        <span class="n">network</span> <span class="o">=</span> <span class="n">networks</span><span class="o">.</span><span class="n">SequentialNetwork</span><span class="p">(</span><span class="n">identifier</span><span class="p">,</span> <span class="n">input_id</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1310"><a href="#PyTorchConverter.to_neural_network-1310"><span class="linenos">1310</span></a>
</span><span id="PyTorchConverter.to_neural_network-1311"><a href="#PyTorchConverter.to_neural_network-1311"><span class="linenos">1311</span></a>        <span class="n">node_index</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="PyTorchConverter.to_neural_network-1312"><a href="#PyTorchConverter.to_neural_network-1312"><span class="linenos">1312</span></a>        <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1313"><a href="#PyTorchConverter.to_neural_network-1313"><span class="linenos">1313</span></a>
</span><span id="PyTorchConverter.to_neural_network-1314"><a href="#PyTorchConverter.to_neural_network-1314"><span class="linenos">1314</span></a>        <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.to_neural_network-1315"><a href="#PyTorchConverter.to_neural_network-1315"><span class="linenos">1315</span></a>
</span><span id="PyTorchConverter.to_neural_network-1316"><a href="#PyTorchConverter.to_neural_network-1316"><span class="linenos">1316</span></a>        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">alt_rep</span><span class="o">.</span><span class="n">pytorch_network</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span><span id="PyTorchConverter.to_neural_network-1317"><a href="#PyTorchConverter.to_neural_network-1317"><span class="linenos">1317</span></a>
</span><span id="PyTorchConverter.to_neural_network-1318"><a href="#PyTorchConverter.to_neural_network-1318"><span class="linenos">1318</span></a>            <span class="c1"># Control input</span>
</span><span id="PyTorchConverter.to_neural_network-1319"><a href="#PyTorchConverter.to_neural_network-1319"><span class="linenos">1319</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;in_dim&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1320"><a href="#PyTorchConverter.to_neural_network-1320"><span class="linenos">1320</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span>
</span><span id="PyTorchConverter.to_neural_network-1321"><a href="#PyTorchConverter.to_neural_network-1321"><span class="linenos">1321</span></a>
</span><span id="PyTorchConverter.to_neural_network-1322"><a href="#PyTorchConverter.to_neural_network-1322"><span class="linenos">1322</span></a>            <span class="k">if</span> <span class="n">layer_in_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1323"><a href="#PyTorchConverter.to_neural_network-1323"><span class="linenos">1323</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Please provide input dimension for the network:&#39;</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1324"><a href="#PyTorchConverter.to_neural_network-1324"><span class="linenos">1324</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="nb">input</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1325"><a href="#PyTorchConverter.to_neural_network-1325"><span class="linenos">1325</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer_in_dim</span><span class="p">,)</span>
</span><span id="PyTorchConverter.to_neural_network-1326"><a href="#PyTorchConverter.to_neural_network-1326"><span class="linenos">1326</span></a>
</span><span id="PyTorchConverter.to_neural_network-1327"><a href="#PyTorchConverter.to_neural_network-1327"><span class="linenos">1327</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="s1">&#39;identifier&#39;</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1328"><a href="#PyTorchConverter.to_neural_network-1328"><span class="linenos">1328</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">identifier</span>
</span><span id="PyTorchConverter.to_neural_network-1329"><a href="#PyTorchConverter.to_neural_network-1329"><span class="linenos">1329</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1330"><a href="#PyTorchConverter.to_neural_network-1330"><span class="linenos">1330</span></a>                <span class="n">layer_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Layer</span><span class="si">{</span><span class="n">node_index</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="PyTorchConverter.to_neural_network-1331"><a href="#PyTorchConverter.to_neural_network-1331"><span class="linenos">1331</span></a>
</span><span id="PyTorchConverter.to_neural_network-1332"><a href="#PyTorchConverter.to_neural_network-1332"><span class="linenos">1332</span></a>            <span class="c1"># Read node</span>
</span><span id="PyTorchConverter.to_neural_network-1333"><a href="#PyTorchConverter.to_neural_network-1333"><span class="linenos">1333</span></a>            <span class="n">new_node</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.to_neural_network-1334"><a href="#PyTorchConverter.to_neural_network-1334"><span class="linenos">1334</span></a>
</span><span id="PyTorchConverter.to_neural_network-1335"><a href="#PyTorchConverter.to_neural_network-1335"><span class="linenos">1335</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1336"><a href="#PyTorchConverter.to_neural_network-1336"><span class="linenos">1336</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1337"><a href="#PyTorchConverter.to_neural_network-1337"><span class="linenos">1337</span></a>
</span><span id="PyTorchConverter.to_neural_network-1338"><a href="#PyTorchConverter.to_neural_network-1338"><span class="linenos">1338</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">ELU</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1339"><a href="#PyTorchConverter.to_neural_network-1339"><span class="linenos">1339</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1340"><a href="#PyTorchConverter.to_neural_network-1340"><span class="linenos">1340</span></a>
</span><span id="PyTorchConverter.to_neural_network-1341"><a href="#PyTorchConverter.to_neural_network-1341"><span class="linenos">1341</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1342"><a href="#PyTorchConverter.to_neural_network-1342"><span class="linenos">1342</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LeakyReLUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">negative_slope</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1343"><a href="#PyTorchConverter.to_neural_network-1343"><span class="linenos">1343</span></a>
</span><span id="PyTorchConverter.to_neural_network-1344"><a href="#PyTorchConverter.to_neural_network-1344"><span class="linenos">1344</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">CELU</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1345"><a href="#PyTorchConverter.to_neural_network-1345"><span class="linenos">1345</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">CELUNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1346"><a href="#PyTorchConverter.to_neural_network-1346"><span class="linenos">1346</span></a>
</span><span id="PyTorchConverter.to_neural_network-1347"><a href="#PyTorchConverter.to_neural_network-1347"><span class="linenos">1347</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1348"><a href="#PyTorchConverter.to_neural_network-1348"><span class="linenos">1348</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SigmoidNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1349"><a href="#PyTorchConverter.to_neural_network-1349"><span class="linenos">1349</span></a>
</span><span id="PyTorchConverter.to_neural_network-1350"><a href="#PyTorchConverter.to_neural_network-1350"><span class="linenos">1350</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Tanh</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1351"><a href="#PyTorchConverter.to_neural_network-1351"><span class="linenos">1351</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">TanhNode</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">identifier</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1352"><a href="#PyTorchConverter.to_neural_network-1352"><span class="linenos">1352</span></a>
</span><span id="PyTorchConverter.to_neural_network-1353"><a href="#PyTorchConverter.to_neural_network-1353"><span class="linenos">1353</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1354"><a href="#PyTorchConverter.to_neural_network-1354"><span class="linenos">1354</span></a>                <span class="n">out_features</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_features</span>
</span><span id="PyTorchConverter.to_neural_network-1355"><a href="#PyTorchConverter.to_neural_network-1355"><span class="linenos">1355</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1356"><a href="#PyTorchConverter.to_neural_network-1356"><span class="linenos">1356</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.to_neural_network-1357"><a href="#PyTorchConverter.to_neural_network-1357"><span class="linenos">1357</span></a>                <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter.to_neural_network-1358"><a href="#PyTorchConverter.to_neural_network-1358"><span class="linenos">1358</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1359"><a href="#PyTorchConverter.to_neural_network-1359"><span class="linenos">1359</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1360"><a href="#PyTorchConverter.to_neural_network-1360"><span class="linenos">1360</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter.to_neural_network-1361"><a href="#PyTorchConverter.to_neural_network-1361"><span class="linenos">1361</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FullyConnectedNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1362"><a href="#PyTorchConverter.to_neural_network-1362"><span class="linenos">1362</span></a>
</span><span id="PyTorchConverter.to_neural_network-1363"><a href="#PyTorchConverter.to_neural_network-1363"><span class="linenos">1363</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter.to_neural_network-1364"><a href="#PyTorchConverter.to_neural_network-1364"><span class="linenos">1364</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1365"><a href="#PyTorchConverter.to_neural_network-1365"><span class="linenos">1365</span></a>
</span><span id="PyTorchConverter.to_neural_network-1366"><a href="#PyTorchConverter.to_neural_network-1366"><span class="linenos">1366</span></a>                <span class="n">eps</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">eps</span>
</span><span id="PyTorchConverter.to_neural_network-1367"><a href="#PyTorchConverter.to_neural_network-1367"><span class="linenos">1367</span></a>                <span class="n">momentum</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">momentum</span>
</span><span id="PyTorchConverter.to_neural_network-1368"><a href="#PyTorchConverter.to_neural_network-1368"><span class="linenos">1368</span></a>                <span class="n">track_running_stats</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">track_running_stats</span>
</span><span id="PyTorchConverter.to_neural_network-1369"><a href="#PyTorchConverter.to_neural_network-1369"><span class="linenos">1369</span></a>                <span class="n">affine</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">affine</span>
</span><span id="PyTorchConverter.to_neural_network-1370"><a href="#PyTorchConverter.to_neural_network-1370"><span class="linenos">1370</span></a>
</span><span id="PyTorchConverter.to_neural_network-1371"><a href="#PyTorchConverter.to_neural_network-1371"><span class="linenos">1371</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1372"><a href="#PyTorchConverter.to_neural_network-1372"><span class="linenos">1372</span></a>                <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1373"><a href="#PyTorchConverter.to_neural_network-1373"><span class="linenos">1373</span></a>                <span class="n">running_mean</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1374"><a href="#PyTorchConverter.to_neural_network-1374"><span class="linenos">1374</span></a>                <span class="n">running_var</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">running_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1375"><a href="#PyTorchConverter.to_neural_network-1375"><span class="linenos">1375</span></a>
</span><span id="PyTorchConverter.to_neural_network-1376"><a href="#PyTorchConverter.to_neural_network-1376"><span class="linenos">1376</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">BatchNormNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span>
</span><span id="PyTorchConverter.to_neural_network-1377"><a href="#PyTorchConverter.to_neural_network-1377"><span class="linenos">1377</span></a>                                               <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">affine</span><span class="p">,</span>
</span><span id="PyTorchConverter.to_neural_network-1378"><a href="#PyTorchConverter.to_neural_network-1378"><span class="linenos">1378</span></a>                                               <span class="n">track_running_stats</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1379"><a href="#PyTorchConverter.to_neural_network-1379"><span class="linenos">1379</span></a>
</span><span id="PyTorchConverter.to_neural_network-1380"><a href="#PyTorchConverter.to_neural_network-1380"><span class="linenos">1380</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1381"><a href="#PyTorchConverter.to_neural_network-1381"><span class="linenos">1381</span></a>
</span><span id="PyTorchConverter.to_neural_network-1382"><a href="#PyTorchConverter.to_neural_network-1382"><span class="linenos">1382</span></a>                <span class="n">out_channels</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">out_channels</span>
</span><span id="PyTorchConverter.to_neural_network-1383"><a href="#PyTorchConverter.to_neural_network-1383"><span class="linenos">1383</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter.to_neural_network-1384"><a href="#PyTorchConverter.to_neural_network-1384"><span class="linenos">1384</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter.to_neural_network-1385"><a href="#PyTorchConverter.to_neural_network-1385"><span class="linenos">1385</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1386"><a href="#PyTorchConverter.to_neural_network-1386"><span class="linenos">1386</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1387"><a href="#PyTorchConverter.to_neural_network-1387"><span class="linenos">1387</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1388"><a href="#PyTorchConverter.to_neural_network-1388"><span class="linenos">1388</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1389"><a href="#PyTorchConverter.to_neural_network-1389"><span class="linenos">1389</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="PyTorchConverter.to_neural_network-1390"><a href="#PyTorchConverter.to_neural_network-1390"><span class="linenos">1390</span></a>                <span class="n">groups</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">groups</span>
</span><span id="PyTorchConverter.to_neural_network-1391"><a href="#PyTorchConverter.to_neural_network-1391"><span class="linenos">1391</span></a>                <span class="n">weight</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1392"><a href="#PyTorchConverter.to_neural_network-1392"><span class="linenos">1392</span></a>                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1393"><a href="#PyTorchConverter.to_neural_network-1393"><span class="linenos">1393</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="PyTorchConverter.to_neural_network-1394"><a href="#PyTorchConverter.to_neural_network-1394"><span class="linenos">1394</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PyTorchConverter.to_neural_network-1395"><a href="#PyTorchConverter.to_neural_network-1395"><span class="linenos">1395</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1396"><a href="#PyTorchConverter.to_neural_network-1396"><span class="linenos">1396</span></a>                    <span class="n">has_bias</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="PyTorchConverter.to_neural_network-1397"><a href="#PyTorchConverter.to_neural_network-1397"><span class="linenos">1397</span></a>                    <span class="n">bias</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="PyTorchConverter.to_neural_network-1398"><a href="#PyTorchConverter.to_neural_network-1398"><span class="linenos">1398</span></a>
</span><span id="PyTorchConverter.to_neural_network-1399"><a href="#PyTorchConverter.to_neural_network-1399"><span class="linenos">1399</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ConvNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
</span><span id="PyTorchConverter.to_neural_network-1400"><a href="#PyTorchConverter.to_neural_network-1400"><span class="linenos">1400</span></a>                                          <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">has_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1401"><a href="#PyTorchConverter.to_neural_network-1401"><span class="linenos">1401</span></a>
</span><span id="PyTorchConverter.to_neural_network-1402"><a href="#PyTorchConverter.to_neural_network-1402"><span class="linenos">1402</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter.to_neural_network-1403"><a href="#PyTorchConverter.to_neural_network-1403"><span class="linenos">1403</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1404"><a href="#PyTorchConverter.to_neural_network-1404"><span class="linenos">1404</span></a>
</span><span id="PyTorchConverter.to_neural_network-1405"><a href="#PyTorchConverter.to_neural_network-1405"><span class="linenos">1405</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter.to_neural_network-1406"><a href="#PyTorchConverter.to_neural_network-1406"><span class="linenos">1406</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1407"><a href="#PyTorchConverter.to_neural_network-1407"><span class="linenos">1407</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1408"><a href="#PyTorchConverter.to_neural_network-1408"><span class="linenos">1408</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1409"><a href="#PyTorchConverter.to_neural_network-1409"><span class="linenos">1409</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1410"><a href="#PyTorchConverter.to_neural_network-1410"><span class="linenos">1410</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter.to_neural_network-1411"><a href="#PyTorchConverter.to_neural_network-1411"><span class="linenos">1411</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="PyTorchConverter.to_neural_network-1412"><a href="#PyTorchConverter.to_neural_network-1412"><span class="linenos">1412</span></a>                <span class="n">count_include_pad</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">count_include_pad</span>
</span><span id="PyTorchConverter.to_neural_network-1413"><a href="#PyTorchConverter.to_neural_network-1413"><span class="linenos">1413</span></a>
</span><span id="PyTorchConverter.to_neural_network-1414"><a href="#PyTorchConverter.to_neural_network-1414"><span class="linenos">1414</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">AveragePoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
</span><span id="PyTorchConverter.to_neural_network-1415"><a href="#PyTorchConverter.to_neural_network-1415"><span class="linenos">1415</span></a>                                                 <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1416"><a href="#PyTorchConverter.to_neural_network-1416"><span class="linenos">1416</span></a>
</span><span id="PyTorchConverter.to_neural_network-1417"><a href="#PyTorchConverter.to_neural_network-1417"><span class="linenos">1417</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">)</span> <span class="ow">or</span> \
</span><span id="PyTorchConverter.to_neural_network-1418"><a href="#PyTorchConverter.to_neural_network-1418"><span class="linenos">1418</span></a>                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1419"><a href="#PyTorchConverter.to_neural_network-1419"><span class="linenos">1419</span></a>
</span><span id="PyTorchConverter.to_neural_network-1420"><a href="#PyTorchConverter.to_neural_network-1420"><span class="linenos">1420</span></a>                <span class="n">stride</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">stride</span>
</span><span id="PyTorchConverter.to_neural_network-1421"><a href="#PyTorchConverter.to_neural_network-1421"><span class="linenos">1421</span></a>                <span class="n">temp_padding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1422"><a href="#PyTorchConverter.to_neural_network-1422"><span class="linenos">1422</span></a>                <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">padding</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1423"><a href="#PyTorchConverter.to_neural_network-1423"><span class="linenos">1423</span></a>                    <span class="n">temp_padding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1424"><a href="#PyTorchConverter.to_neural_network-1424"><span class="linenos">1424</span></a>                <span class="n">padding</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">temp_padding</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1425"><a href="#PyTorchConverter.to_neural_network-1425"><span class="linenos">1425</span></a>                <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel_size</span>
</span><span id="PyTorchConverter.to_neural_network-1426"><a href="#PyTorchConverter.to_neural_network-1426"><span class="linenos">1426</span></a>                <span class="n">ceil_mode</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">ceil_mode</span>
</span><span id="PyTorchConverter.to_neural_network-1427"><a href="#PyTorchConverter.to_neural_network-1427"><span class="linenos">1427</span></a>                <span class="n">dilation</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">dilation</span>
</span><span id="PyTorchConverter.to_neural_network-1428"><a href="#PyTorchConverter.to_neural_network-1428"><span class="linenos">1428</span></a>                <span class="n">return_indices</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">return_indices</span>
</span><span id="PyTorchConverter.to_neural_network-1429"><a href="#PyTorchConverter.to_neural_network-1429"><span class="linenos">1429</span></a>
</span><span id="PyTorchConverter.to_neural_network-1430"><a href="#PyTorchConverter.to_neural_network-1430"><span class="linenos">1430</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">MaxPoolNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span>
</span><span id="PyTorchConverter.to_neural_network-1431"><a href="#PyTorchConverter.to_neural_network-1431"><span class="linenos">1431</span></a>                                             <span class="n">ceil_mode</span><span class="p">,</span> <span class="n">return_indices</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1432"><a href="#PyTorchConverter.to_neural_network-1432"><span class="linenos">1432</span></a>
</span><span id="PyTorchConverter.to_neural_network-1433"><a href="#PyTorchConverter.to_neural_network-1433"><span class="linenos">1433</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1434"><a href="#PyTorchConverter.to_neural_network-1434"><span class="linenos">1434</span></a>
</span><span id="PyTorchConverter.to_neural_network-1435"><a href="#PyTorchConverter.to_neural_network-1435"><span class="linenos">1435</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">LRNNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1436"><a href="#PyTorchConverter.to_neural_network-1436"><span class="linenos">1436</span></a>
</span><span id="PyTorchConverter.to_neural_network-1437"><a href="#PyTorchConverter.to_neural_network-1437"><span class="linenos">1437</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Softmax</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1438"><a href="#PyTorchConverter.to_neural_network-1438"><span class="linenos">1438</span></a>
</span><span id="PyTorchConverter.to_neural_network-1439"><a href="#PyTorchConverter.to_neural_network-1439"><span class="linenos">1439</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">SoftMaxNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1440"><a href="#PyTorchConverter.to_neural_network-1440"><span class="linenos">1440</span></a>
</span><span id="PyTorchConverter.to_neural_network-1441"><a href="#PyTorchConverter.to_neural_network-1441"><span class="linenos">1441</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Unsqueeze</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1442"><a href="#PyTorchConverter.to_neural_network-1442"><span class="linenos">1442</span></a>
</span><span id="PyTorchConverter.to_neural_network-1443"><a href="#PyTorchConverter.to_neural_network-1443"><span class="linenos">1443</span></a>                <span class="n">axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">e</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">axes</span><span class="p">])</span>
</span><span id="PyTorchConverter.to_neural_network-1444"><a href="#PyTorchConverter.to_neural_network-1444"><span class="linenos">1444</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">UnsqueezeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1445"><a href="#PyTorchConverter.to_neural_network-1445"><span class="linenos">1445</span></a>
</span><span id="PyTorchConverter.to_neural_network-1446"><a href="#PyTorchConverter.to_neural_network-1446"><span class="linenos">1446</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Reshape</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1447"><a href="#PyTorchConverter.to_neural_network-1447"><span class="linenos">1447</span></a>
</span><span id="PyTorchConverter.to_neural_network-1448"><a href="#PyTorchConverter.to_neural_network-1448"><span class="linenos">1448</span></a>                <span class="n">shape</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="PyTorchConverter.to_neural_network-1449"><a href="#PyTorchConverter.to_neural_network-1449"><span class="linenos">1449</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">ReshapeNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1450"><a href="#PyTorchConverter.to_neural_network-1450"><span class="linenos">1450</span></a>
</span><span id="PyTorchConverter.to_neural_network-1451"><a href="#PyTorchConverter.to_neural_network-1451"><span class="linenos">1451</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Flatten</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1452"><a href="#PyTorchConverter.to_neural_network-1452"><span class="linenos">1452</span></a>
</span><span id="PyTorchConverter.to_neural_network-1453"><a href="#PyTorchConverter.to_neural_network-1453"><span class="linenos">1453</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">FlattenNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1454"><a href="#PyTorchConverter.to_neural_network-1454"><span class="linenos">1454</span></a>
</span><span id="PyTorchConverter.to_neural_network-1455"><a href="#PyTorchConverter.to_neural_network-1455"><span class="linenos">1455</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Dropout</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1456"><a href="#PyTorchConverter.to_neural_network-1456"><span class="linenos">1456</span></a>
</span><span id="PyTorchConverter.to_neural_network-1457"><a href="#PyTorchConverter.to_neural_network-1457"><span class="linenos">1457</span></a>                <span class="n">new_node</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">DropoutNode</span><span class="p">(</span><span class="n">layer_id</span><span class="p">,</span> <span class="n">layer_in_dim</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1458"><a href="#PyTorchConverter.to_neural_network-1458"><span class="linenos">1458</span></a>
</span><span id="PyTorchConverter.to_neural_network-1459"><a href="#PyTorchConverter.to_neural_network-1459"><span class="linenos">1459</span></a>            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">pyt_l</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
</span><span id="PyTorchConverter.to_neural_network-1460"><a href="#PyTorchConverter.to_neural_network-1460"><span class="linenos">1460</span></a>                <span class="k">pass</span>
</span><span id="PyTorchConverter.to_neural_network-1461"><a href="#PyTorchConverter.to_neural_network-1461"><span class="linenos">1461</span></a>
</span><span id="PyTorchConverter.to_neural_network-1462"><a href="#PyTorchConverter.to_neural_network-1462"><span class="linenos">1462</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1463"><a href="#PyTorchConverter.to_neural_network-1463"><span class="linenos">1463</span></a>                <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span><span id="PyTorchConverter.to_neural_network-1464"><a href="#PyTorchConverter.to_neural_network-1464"><span class="linenos">1464</span></a>
</span><span id="PyTorchConverter.to_neural_network-1465"><a href="#PyTorchConverter.to_neural_network-1465"><span class="linenos">1465</span></a>            <span class="k">if</span> <span class="n">new_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PyTorchConverter.to_neural_network-1466"><a href="#PyTorchConverter.to_neural_network-1466"><span class="linenos">1466</span></a>                <span class="n">node_index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="PyTorchConverter.to_neural_network-1467"><a href="#PyTorchConverter.to_neural_network-1467"><span class="linenos">1467</span></a>                <span class="n">network</span><span class="o">.</span><span class="n">add_node</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
</span><span id="PyTorchConverter.to_neural_network-1468"><a href="#PyTorchConverter.to_neural_network-1468"><span class="linenos">1468</span></a>                <span class="n">layer_in_dim</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_last_node</span><span class="p">()</span><span class="o">.</span><span class="n">out_dim</span>
</span><span id="PyTorchConverter.to_neural_network-1469"><a href="#PyTorchConverter.to_neural_network-1469"><span class="linenos">1469</span></a>
</span><span id="PyTorchConverter.to_neural_network-1470"><a href="#PyTorchConverter.to_neural_network-1470"><span class="linenos">1470</span></a>        <span class="k">return</span> <span class="n">network</span>
</span></pre></div>


            <div class="docstring"><p>Convert the PyTorch representation of interest to the internal one.</p>

<h2 id="parameters">Parameters</h2>

<p>alt_rep : PyTorchNetwork
    The PyTorch Representation to convert.</p>

<h2 id="returns">Returns</h2>

<p>NeuralNetwork
    The Neural Network resulting from the conversion of PyTorch Representation.</p>
</div>


                            </div>
                </section>
                <section id="load_network_path">
                            <input id="load_network_path-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">load_network_path</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">path</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="n">Optional</span><span class="p">[</span><span class="n"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="load_network_path-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#load_network_path"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="load_network_path-1473"><a href="#load_network_path-1473"><span class="linenos">1473</span></a><span class="k">def</span> <span class="nf">load_network_path</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AlternativeRepresentation</span><span class="p">]:</span>
</span><span id="load_network_path-1474"><a href="#load_network_path-1474"><span class="linenos">1474</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="load_network_path-1475"><a href="#load_network_path-1475"><span class="linenos">1475</span></a><span class="sd">    Method to load a network from a path in an Alternative Representation.</span>
</span><span id="load_network_path-1476"><a href="#load_network_path-1476"><span class="linenos">1476</span></a>
</span><span id="load_network_path-1477"><a href="#load_network_path-1477"><span class="linenos">1477</span></a><span class="sd">    Parameters</span>
</span><span id="load_network_path-1478"><a href="#load_network_path-1478"><span class="linenos">1478</span></a><span class="sd">    ----------</span>
</span><span id="load_network_path-1479"><a href="#load_network_path-1479"><span class="linenos">1479</span></a><span class="sd">    path : str</span>
</span><span id="load_network_path-1480"><a href="#load_network_path-1480"><span class="linenos">1480</span></a><span class="sd">        Path to the network.</span>
</span><span id="load_network_path-1481"><a href="#load_network_path-1481"><span class="linenos">1481</span></a>
</span><span id="load_network_path-1482"><a href="#load_network_path-1482"><span class="linenos">1482</span></a><span class="sd">    Returns</span>
</span><span id="load_network_path-1483"><a href="#load_network_path-1483"><span class="linenos">1483</span></a><span class="sd">    -------</span>
</span><span id="load_network_path-1484"><a href="#load_network_path-1484"><span class="linenos">1484</span></a><span class="sd">    Optional[AlternativeRepresentation]</span>
</span><span id="load_network_path-1485"><a href="#load_network_path-1485"><span class="linenos">1485</span></a><span class="sd">        The AlternativeRepresentation object if the network is supported, None otherwise.</span>
</span><span id="load_network_path-1486"><a href="#load_network_path-1486"><span class="linenos">1486</span></a>
</span><span id="load_network_path-1487"><a href="#load_network_path-1487"><span class="linenos">1487</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="load_network_path-1488"><a href="#load_network_path-1488"><span class="linenos">1488</span></a>
</span><span id="load_network_path-1489"><a href="#load_network_path-1489"><span class="linenos">1489</span></a>    <span class="n">extension</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="load_network_path-1490"><a href="#load_network_path-1490"><span class="linenos">1490</span></a>    <span class="n">net_id</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;.</span><span class="si">{</span><span class="n">extension</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
</span><span id="load_network_path-1491"><a href="#load_network_path-1491"><span class="linenos">1491</span></a>
</span><span id="load_network_path-1492"><a href="#load_network_path-1492"><span class="linenos">1492</span></a>    <span class="k">if</span> <span class="n">extension</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="s1">&#39;pth&#39;</span><span class="p">]:</span>
</span><span id="load_network_path-1493"><a href="#load_network_path-1493"><span class="linenos">1493</span></a>        <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span><span id="load_network_path-1494"><a href="#load_network_path-1494"><span class="linenos">1494</span></a>        <span class="k">return</span> <span class="n">PyTorchNetwork</span><span class="p">(</span><span class="n">net_id</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="load_network_path-1495"><a href="#load_network_path-1495"><span class="linenos">1495</span></a>    <span class="k">elif</span> <span class="n">extension</span> <span class="o">==</span> <span class="s1">&#39;onnx&#39;</span><span class="p">:</span>
</span><span id="load_network_path-1496"><a href="#load_network_path-1496"><span class="linenos">1496</span></a>        <span class="n">model_proto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span><span id="load_network_path-1497"><a href="#load_network_path-1497"><span class="linenos">1497</span></a>        <span class="k">return</span> <span class="n">ONNXNetwork</span><span class="p">(</span><span class="n">net_id</span><span class="p">,</span> <span class="n">model_proto</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span id="load_network_path-1498"><a href="#load_network_path-1498"><span class="linenos">1498</span></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="load_network_path-1499"><a href="#load_network_path-1499"><span class="linenos">1499</span></a>        <span class="k">return</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><p>Method to load a network from a path in an Alternative Representation.</p>

<h2 id="parameters">Parameters</h2>

<p>path : str
    Path to the network.</p>

<h2 id="returns">Returns</h2>

<p>Optional[AlternativeRepresentation]
    The AlternativeRepresentation object if the network is supported, None otherwise.</p>
</div>


                </section>
                <section id="save_network_path">
                            <input id="save_network_path-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">save_network_path</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">network</span><span class="p">:</span> <span class="n"><a href="#AlternativeRepresentation">AlternativeRepresentation</a></span>,</span><span class="param">	<span class="n">path</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="save_network_path-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#save_network_path"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="save_network_path-1502"><a href="#save_network_path-1502"><span class="linenos">1502</span></a><span class="k">def</span> <span class="nf">save_network_path</span><span class="p">(</span><span class="n">network</span><span class="p">:</span> <span class="n">AlternativeRepresentation</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="save_network_path-1503"><a href="#save_network_path-1503"><span class="linenos">1503</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="save_network_path-1504"><a href="#save_network_path-1504"><span class="linenos">1504</span></a><span class="sd">    Method to save a network to file from an AlternativeRepresentation</span>
</span><span id="save_network_path-1505"><a href="#save_network_path-1505"><span class="linenos">1505</span></a>
</span><span id="save_network_path-1506"><a href="#save_network_path-1506"><span class="linenos">1506</span></a><span class="sd">    Parameters</span>
</span><span id="save_network_path-1507"><a href="#save_network_path-1507"><span class="linenos">1507</span></a><span class="sd">    ----------</span>
</span><span id="save_network_path-1508"><a href="#save_network_path-1508"><span class="linenos">1508</span></a><span class="sd">    network : AlternativeRepresentation</span>
</span><span id="save_network_path-1509"><a href="#save_network_path-1509"><span class="linenos">1509</span></a><span class="sd">        The network to save.</span>
</span><span id="save_network_path-1510"><a href="#save_network_path-1510"><span class="linenos">1510</span></a><span class="sd">    path : str</span>
</span><span id="save_network_path-1511"><a href="#save_network_path-1511"><span class="linenos">1511</span></a><span class="sd">        Path to save the network.</span>
</span><span id="save_network_path-1512"><a href="#save_network_path-1512"><span class="linenos">1512</span></a>
</span><span id="save_network_path-1513"><a href="#save_network_path-1513"><span class="linenos">1513</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="save_network_path-1514"><a href="#save_network_path-1514"><span class="linenos">1514</span></a>
</span><span id="save_network_path-1515"><a href="#save_network_path-1515"><span class="linenos">1515</span></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">PyTorchNetwork</span><span class="p">):</span>
</span><span id="save_network_path-1516"><a href="#save_network_path-1516"><span class="linenos">1516</span></a>        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">pytorch_network</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</span><span id="save_network_path-1517"><a href="#save_network_path-1517"><span class="linenos">1517</span></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">ONNXNetwork</span><span class="p">):</span>
</span><span id="save_network_path-1518"><a href="#save_network_path-1518"><span class="linenos">1518</span></a>        <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">onnx_network</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Method to save a network to file from an AlternativeRepresentation</p>

<h2 id="parameters">Parameters</h2>

<p>network : AlternativeRepresentation
    The network to save.
path : str
    Path to save the network.</p>
</div>


                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>